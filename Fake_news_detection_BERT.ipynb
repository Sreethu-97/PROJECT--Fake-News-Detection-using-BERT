{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "KmBk4IYMl0E4",
        "outputId": "8d52939c-a170-4246-e973-4924162cba59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# paramters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "1VtCstJkl8o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/newdatasetwithcoviddata.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7SheFof2ELWR",
        "outputId": "888c5e0b-1efd-48f1-b78e-41d6fee2b337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1592978e-f892-4728-ba90-2676e3e5e7ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why don t we do it in the road to perdition ad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the lead time time between diagnosis w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>covid and ppe some of us will die</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>covid antibodies can disappear after months st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lab made coronavirus triggers debate the scien...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1592978e-f892-4728-ba90-2676e3e5e7ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1592978e-f892-4728-ba90-2676e3e5e7ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1592978e-f892-4728-ba90-2676e3e5e7ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  why don t we do it in the road to perdition ad...      0\n",
              "1  what is the lead time time between diagnosis w...      1\n",
              "2                  covid and ppe some of us will die      1\n",
              "3  covid antibodies can disappear after months st...      1\n",
              "4  lab made coronavirus triggers debate the scien...      0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(100000)"
      ],
      "metadata": {
        "id": "NJxaPjPiINau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "upDiqDPWIO_n",
        "outputId": "41339ef6-aded-47a4-9dab-8a69fadb77d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "id": "uBIUlgiaIU7t",
        "outputId": "30ba6d0e-7d1a-4efa-942c-e297dfb4617b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.82169\n",
              "0    0.17831\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.4, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "EFJ1NZJ_FzwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text"
      ],
      "metadata": {
        "id": "LqnFtm2BIkhU",
        "outputId": "e7062a5e-219b-497e-b7d0-adf8e52ca846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61262     mental health an emerging crisis of covid pand...\n",
              "142746    some patients could show covid symptoms after ...\n",
              "8626              trump clinton obama created isis politics\n",
              "72843     we also request all customers to wear a mask w...\n",
              "31292     zerohedge era stato bannato da tw per quest ar...\n",
              "                                ...                        \n",
              "88712     my question is how the hell can you be a carri...\n",
              "50859     food and drug administration fda director gene...\n",
              "118751    as we reopen the afsc we need your funding hel...\n",
              "159153    can the people who claim the numbers are being...\n",
              "28638     buyers get a lot of advice on how to get ready...\n",
              "Name: text, Length: 20000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_text))\n",
        "print(type(test_labels))"
      ],
      "metadata": {
        "id": "VnbxqUlXF1Ma",
        "outputId": "76316c94-f979-4842-fcdc-1b0e10e669d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "55-FB-f_pX_a",
        "outputId": "e08ecf35-39e3-4c68-fac4-cd5d6237cc55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model for fake news detection\", \"fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "metadata": {
        "id": "MiNnRTEgGNZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "metadata": {
        "id": "w12bTtezGfr1",
        "outputId": "7f51278e-66dd-4389-c1f8-7208ad2cbcc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 2005, 8275, 2739, 10788, 102], [101, 2986, 1011, 8694, 1037, 14324, 2944, 102, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "id": "CYh8g_qUGkm_",
        "outputId": "28f733f3-9e79-492e-e7cc-80f223fcd19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e2056d50>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 25"
      ],
      "metadata": {
        "id": "aGHlT4ibGqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "j5GMJUCQGxj4",
        "outputId": "4060ca4c-4951-49e1-94cd-6d99ae69a0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "J-iz_XMyHB3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a batch size\n",
        "batch_size = 2\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "j_b0eN5ZHMSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "9pj9bi-rHSXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "hLUJi2EzoVWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "IQ0MREUgo8II"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Fake news detection : BERT",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}