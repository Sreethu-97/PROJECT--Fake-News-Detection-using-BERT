{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " FAKE NEWS DETECTION USING BERT 1__epoch=50",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18c3b697852c42b68f7fc47a13bdf823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e15c28c60ea3447e964bdd2a90249739",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33710a3809844655b973e3ade06d71cd",
              "IPY_MODEL_0acf014250da4db291c625a6f135adc9",
              "IPY_MODEL_195f2cfe2d98414b95f3df068d307519"
            ]
          }
        },
        "e15c28c60ea3447e964bdd2a90249739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33710a3809844655b973e3ade06d71cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_633d8f38d2b146b5889cb2d97b93ddab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6c7ad8de4c74232ac9e989fd5eadcbe"
          }
        },
        "0acf014250da4db291c625a6f135adc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77d93a69365b4cfc8cb28e8c7578b0d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84f15780dade49b9bcd0bed6b03f29ab"
          }
        },
        "195f2cfe2d98414b95f3df068d307519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98a6f9f2e28e483e98470d910dbe2f05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 10.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_746a619173fc4e22b128a5deb6cdd15c"
          }
        },
        "633d8f38d2b146b5889cb2d97b93ddab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6c7ad8de4c74232ac9e989fd5eadcbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77d93a69365b4cfc8cb28e8c7578b0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84f15780dade49b9bcd0bed6b03f29ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98a6f9f2e28e483e98470d910dbe2f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "746a619173fc4e22b128a5deb6cdd15c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "440952bec5af49a89bd0aca28966882a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed4fffa2132a4bfaa010cd306c7e60ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_664989f8f9164ca985e3dc6930c7419f",
              "IPY_MODEL_653a44d14a8b46fcb9f0f7cdab48a539",
              "IPY_MODEL_495c817c27c34669aa42ca4692e73799"
            ]
          }
        },
        "ed4fffa2132a4bfaa010cd306c7e60ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "664989f8f9164ca985e3dc6930c7419f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b876e758a017492da6d0cc770d309d36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccfa897244ed4ccb8c467d37ef550238"
          }
        },
        "653a44d14a8b46fcb9f0f7cdab48a539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfbc645bcdb0493881f2dfae4d5ac8a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7d64460f84d4d53a9b1bf1d6c16f4b3"
          }
        },
        "495c817c27c34669aa42ca4692e73799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_607d985414da4ff68f3ca208aaaecc5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:13&lt;00:00, 33.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb0bdb85ac3d456da213ad1c2a02a6ce"
          }
        },
        "b876e758a017492da6d0cc770d309d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccfa897244ed4ccb8c467d37ef550238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfbc645bcdb0493881f2dfae4d5ac8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7d64460f84d4d53a9b1bf1d6c16f4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "607d985414da4ff68f3ca208aaaecc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb0bdb85ac3d456da213ad1c2a02a6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33eb9628fd264207a9311b380de29de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f1e024700094cc293b6c2bdaacb5c72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_199eb966d7b94e8bbb33de4dc8024621",
              "IPY_MODEL_5136cfd0d9b64f6782a954e8863e4436",
              "IPY_MODEL_4bb463a46e9b47d79757c8a761f546a8"
            ]
          }
        },
        "4f1e024700094cc293b6c2bdaacb5c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "199eb966d7b94e8bbb33de4dc8024621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2de0fb1218d2495fbb6bd7c73f37356d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66be86e0960a44f59f1dfd1f78f1cd46"
          }
        },
        "5136cfd0d9b64f6782a954e8863e4436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_962bf50029984b678ad48addea1bba84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7afd739387c44155ac40c7fdae80b83d"
          }
        },
        "4bb463a46e9b47d79757c8a761f546a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c47c0c425ed741ce8fa9b26494ed0e7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 629B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b52ab3d29bcc47a99a66e05f273678b6"
          }
        },
        "2de0fb1218d2495fbb6bd7c73f37356d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66be86e0960a44f59f1dfd1f78f1cd46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "962bf50029984b678ad48addea1bba84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7afd739387c44155ac40c7fdae80b83d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c47c0c425ed741ce8fa9b26494ed0e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b52ab3d29bcc47a99a66e05f273678b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2baa0457fb8d4514a8348a65e18aa5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f34f498194994874b7e454fc9347ac67",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d311f57b19d74112b00329d8064b506e",
              "IPY_MODEL_9b5c48438edf4f75834b0fa5be16a614",
              "IPY_MODEL_0499b26109c44e8ea9641f0f52a0c507"
            ]
          }
        },
        "f34f498194994874b7e454fc9347ac67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d311f57b19d74112b00329d8064b506e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df638e820f484dfca0465234daef02b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54529afc6b8c4f89992be81b79768560"
          }
        },
        "9b5c48438edf4f75834b0fa5be16a614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8714ec7bbdf44949b60723c64a84650e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17be716e17304c5e90b0b6234f654014"
          }
        },
        "0499b26109c44e8ea9641f0f52a0c507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b35a5c37dc2a492fb70eeb40c8f36b6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 983kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90d71182e6da471980db42ed8236a5e7"
          }
        },
        "df638e820f484dfca0465234daef02b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54529afc6b8c4f89992be81b79768560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8714ec7bbdf44949b60723c64a84650e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17be716e17304c5e90b0b6234f654014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b35a5c37dc2a492fb70eeb40c8f36b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90d71182e6da471980db42ed8236a5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f24afb0a1e1f46449e382c3e663bd043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a716a44c6d6436686e1f481fae02fe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d800ff36521c406fbddc247d6df4b48b",
              "IPY_MODEL_ca25ecca120c4aeabfd9f9d7e159c3d6",
              "IPY_MODEL_dd218bedbee74886a9642f080f7faff4"
            ]
          }
        },
        "5a716a44c6d6436686e1f481fae02fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d800ff36521c406fbddc247d6df4b48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdc06fd5f47a42d1ac967c5e274dd08c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf0b1f29bcf949e6925aab13c037d713"
          }
        },
        "ca25ecca120c4aeabfd9f9d7e159c3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e4e13b95d9b4867bbb7b0a94adee3aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cca32d9562a34286be7648f2700fb4b6"
          }
        },
        "dd218bedbee74886a9642f080f7faff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a73c85208a1460bade876c3f8efaaf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 729kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36a55bacdec24e7cbc667f0545a7cf9d"
          }
        },
        "fdc06fd5f47a42d1ac967c5e274dd08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf0b1f29bcf949e6925aab13c037d713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e4e13b95d9b4867bbb7b0a94adee3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cca32d9562a34286be7648f2700fb4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a73c85208a1460bade876c3f8efaaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36a55bacdec24e7cbc667f0545a7cf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ADOBMoR0yF",
        "outputId": "36b8e900-ecb3-4d6a-e17f-138e2c013077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 23.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 35.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# paramters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "O6cr_6FGSNzT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/newdatasetwithcoviddata.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3pTmZk9lSRMs",
        "outputId": "4812777d-710e-4be5-9a68-ed8240d34eb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a817576-c6c7-49eb-a6d1-db693e7d3a3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why don t we do it in the road to perdition ad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the lead time time between diagnosis w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>covid and ppe some of us will die</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>covid antibodies can disappear after months st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lab made coronavirus triggers debate the scien...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a817576-c6c7-49eb-a6d1-db693e7d3a3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a817576-c6c7-49eb-a6d1-db693e7d3a3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a817576-c6c7-49eb-a6d1-db693e7d3a3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  why don t we do it in the road to perdition ad...      0\n",
              "1  what is the lead time time between diagnosis w...      1\n",
              "2                  covid and ppe some of us will die      1\n",
              "3  covid antibodies can disappear after months st...      1\n",
              "4  lab made coronavirus triggers debate the scien...      0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(100000)"
      ],
      "metadata": {
        "id": "qlHYcOjsSvOJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGEjroXMT3-M",
        "outputId": "e86a36f2-9d69-4eea-ce44-130e23ae440e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3965JoQT6nX",
        "outputId": "4c2378a4-ef69-4e17-d826-93081f4891ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.82248\n",
              "0    0.17752\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.4, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "jxjuxIY6T-Gs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyEVt-_dUAl3",
        "outputId": "7402fdfe-a573-406b-bbf9-20ce063ef4e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24815     digital contact tracing tools could bolster ou...\n",
              "61987     new polo shirt sponsor for the dev squad \\n\\na...\n",
              "63624     myth \\nthe outbreak began because people ate b...\n",
              "82437     study identifies potential approach to treat s...\n",
              "68413     mars is buying out warren buffett to take full...\n",
              "                                ...                        \n",
              "98000     new york gazette ™ how leftists critical race ...\n",
              "72368     how many people did gov cuomo kill with his co...\n",
              "118603    antiviral remdesivir prevents disease progress...\n",
              "95178     female veterans\\nare seeking input from those ...\n",
              "27524     uae joins ’one world together at home’ global ...\n",
              "Name: text, Length: 20000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_text))\n",
        "print(type(test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1l1BaQuUFvl",
        "outputId": "011fd97c-78c6-4ebe-da01-f3647e5f2e63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "18c3b697852c42b68f7fc47a13bdf823",
            "e15c28c60ea3447e964bdd2a90249739",
            "33710a3809844655b973e3ade06d71cd",
            "0acf014250da4db291c625a6f135adc9",
            "195f2cfe2d98414b95f3df068d307519",
            "633d8f38d2b146b5889cb2d97b93ddab",
            "c6c7ad8de4c74232ac9e989fd5eadcbe",
            "77d93a69365b4cfc8cb28e8c7578b0d7",
            "84f15780dade49b9bcd0bed6b03f29ab",
            "98a6f9f2e28e483e98470d910dbe2f05",
            "746a619173fc4e22b128a5deb6cdd15c",
            "440952bec5af49a89bd0aca28966882a",
            "ed4fffa2132a4bfaa010cd306c7e60ce",
            "664989f8f9164ca985e3dc6930c7419f",
            "653a44d14a8b46fcb9f0f7cdab48a539",
            "495c817c27c34669aa42ca4692e73799",
            "b876e758a017492da6d0cc770d309d36",
            "ccfa897244ed4ccb8c467d37ef550238",
            "cfbc645bcdb0493881f2dfae4d5ac8a3",
            "a7d64460f84d4d53a9b1bf1d6c16f4b3",
            "607d985414da4ff68f3ca208aaaecc5a",
            "cb0bdb85ac3d456da213ad1c2a02a6ce",
            "33eb9628fd264207a9311b380de29de8",
            "4f1e024700094cc293b6c2bdaacb5c72",
            "199eb966d7b94e8bbb33de4dc8024621",
            "5136cfd0d9b64f6782a954e8863e4436",
            "4bb463a46e9b47d79757c8a761f546a8",
            "2de0fb1218d2495fbb6bd7c73f37356d",
            "66be86e0960a44f59f1dfd1f78f1cd46",
            "962bf50029984b678ad48addea1bba84",
            "7afd739387c44155ac40c7fdae80b83d",
            "c47c0c425ed741ce8fa9b26494ed0e7e",
            "b52ab3d29bcc47a99a66e05f273678b6",
            "2baa0457fb8d4514a8348a65e18aa5a6",
            "f34f498194994874b7e454fc9347ac67",
            "d311f57b19d74112b00329d8064b506e",
            "9b5c48438edf4f75834b0fa5be16a614",
            "0499b26109c44e8ea9641f0f52a0c507",
            "df638e820f484dfca0465234daef02b8",
            "54529afc6b8c4f89992be81b79768560",
            "8714ec7bbdf44949b60723c64a84650e",
            "17be716e17304c5e90b0b6234f654014",
            "b35a5c37dc2a492fb70eeb40c8f36b6a",
            "90d71182e6da471980db42ed8236a5e7",
            "f24afb0a1e1f46449e382c3e663bd043",
            "5a716a44c6d6436686e1f481fae02fe6",
            "d800ff36521c406fbddc247d6df4b48b",
            "ca25ecca120c4aeabfd9f9d7e159c3d6",
            "dd218bedbee74886a9642f080f7faff4",
            "fdc06fd5f47a42d1ac967c5e274dd08c",
            "bf0b1f29bcf949e6925aab13c037d713",
            "1e4e13b95d9b4867bbb7b0a94adee3aa",
            "cca32d9562a34286be7648f2700fb4b6",
            "6a73c85208a1460bade876c3f8efaaf3",
            "36a55bacdec24e7cbc667f0545a7cf9d"
          ]
        },
        "id": "YBjc0gA3UKDk",
        "outputId": "349cb947-826c-46c6-c99e-64e0de204212"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18c3b697852c42b68f7fc47a13bdf823",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "440952bec5af49a89bd0aca28966882a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33eb9628fd264207a9311b380de29de8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2baa0457fb8d4514a8348a65e18aa5a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f24afb0a1e1f46449e382c3e663bd043",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sample data\n",
        "text = [\"this is a bert model for fake news detection\", \"will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "metadata": {
        "id": "KaUz4D1gUQcr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKjBITZiUUfp",
        "outputId": "e8ed938d-6fd6-42d1-c6b4-cf44c4cb75c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 2005, 8275, 2739, 10788, 102], [101, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "T8OEu9pMUXGL",
        "outputId": "64bfddac-e64e-407c-c959-665e4d6199db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6c58f36b10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 25"
      ],
      "metadata": {
        "id": "-J_aIoyHUaV7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUbC8F8kUe_V",
        "outputId": "665d4b20-ccc8-4822-bce9-f06abd733a22"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "iaxrtiqRUlUV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "mUVs0IRKUo_0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "ZNZI3iLQUsvf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "oPkQz-0AUw_k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Luog3urSU2OT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "KjWFe0nUU5eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2883e2fb-0687-4db3-e395-8750eaad6d4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight='balanced',classes= np.unique(train_labels),y= train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMh8-vkwU8lc",
        "outputId": "ec6f00fe-1c48-422e-b48c-4456db6a104f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.81663694 0.60791505]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "xtQGLTxYVVpn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        " #returns the loss and predictions\n",
        "  return avg_loss, total_preds\n"
      ],
      "metadata": {
        "id": "fbmFMpcoVgHE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "gd-oOoD0VokJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA92rG3pVr1t",
        "outputId": "1ffb1f16-f0de-49d6-f8ed-fe4a90d9a4e5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.517\n",
            "Validation Loss: 0.462\n",
            "\n",
            " Epoch 2 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.463\n",
            "Validation Loss: 0.428\n",
            "\n",
            " Epoch 3 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.449\n",
            "Validation Loss: 0.401\n",
            "\n",
            " Epoch 4 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.435\n",
            "Validation Loss: 0.429\n",
            "\n",
            " Epoch 5 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.431\n",
            "Validation Loss: 0.387\n",
            "\n",
            " Epoch 6 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.425\n",
            "Validation Loss: 0.411\n",
            "\n",
            " Epoch 7 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.423\n",
            "Validation Loss: 0.372\n",
            "\n",
            " Epoch 8 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.416\n",
            "Validation Loss: 0.384\n",
            "\n",
            " Epoch 9 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.414\n",
            "Validation Loss: 0.370\n",
            "\n",
            " Epoch 10 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.410\n",
            "Validation Loss: 0.371\n",
            "\n",
            " Epoch 11 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.407\n",
            "Validation Loss: 0.398\n",
            "\n",
            " Epoch 12 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.403\n",
            "Validation Loss: 0.374\n",
            "\n",
            " Epoch 13 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.398\n",
            "Validation Loss: 0.348\n",
            "\n",
            " Epoch 14 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.401\n",
            "Validation Loss: 0.350\n",
            "\n",
            " Epoch 15 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.396\n",
            "Validation Loss: 0.341\n",
            "\n",
            " Epoch 16 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.395\n",
            "Validation Loss: 0.378\n",
            "\n",
            " Epoch 17 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.389\n",
            "Validation Loss: 0.343\n",
            "\n",
            " Epoch 18 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.389\n",
            "Validation Loss: 0.383\n",
            "\n",
            " Epoch 19 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.384\n",
            "Validation Loss: 0.336\n",
            "\n",
            " Epoch 20 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.383\n",
            "Validation Loss: 0.359\n",
            "\n",
            " Epoch 21 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.384\n",
            "Validation Loss: 0.353\n",
            "\n",
            " Epoch 22 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.382\n",
            "Validation Loss: 0.349\n",
            "\n",
            " Epoch 23 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.377\n",
            "Validation Loss: 0.351\n",
            "\n",
            " Epoch 24 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.375\n",
            "Validation Loss: 0.331\n",
            "\n",
            " Epoch 25 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.375\n",
            "Validation Loss: 0.341\n",
            "\n",
            " Epoch 26 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.375\n",
            "Validation Loss: 0.344\n",
            "\n",
            " Epoch 27 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.371\n",
            "Validation Loss: 0.327\n",
            "\n",
            " Epoch 28 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.373\n",
            "Validation Loss: 0.337\n",
            "\n",
            " Epoch 29 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.371\n",
            "Validation Loss: 0.355\n",
            "\n",
            " Epoch 30 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.366\n",
            "Validation Loss: 0.327\n",
            "\n",
            " Epoch 31 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.367\n",
            "Validation Loss: 0.332\n",
            "\n",
            " Epoch 32 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.367\n",
            "Validation Loss: 0.354\n",
            "\n",
            " Epoch 33 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.368\n",
            "Validation Loss: 0.328\n",
            "\n",
            " Epoch 34 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.364\n",
            "Validation Loss: 0.325\n",
            "\n",
            " Epoch 35 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.364\n",
            "Validation Loss: 0.320\n",
            "\n",
            " Epoch 36 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.360\n",
            "Validation Loss: 0.313\n",
            "\n",
            " Epoch 37 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.358\n",
            "Validation Loss: 0.321\n",
            "\n",
            " Epoch 38 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.361\n",
            "Validation Loss: 0.322\n",
            "\n",
            " Epoch 39 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.369\n",
            "Validation Loss: 0.324\n",
            "\n",
            " Epoch 40 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.362\n",
            "Validation Loss: 0.326\n",
            "\n",
            " Epoch 41 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.356\n",
            "Validation Loss: 0.327\n",
            "\n",
            " Epoch 42 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.360\n",
            "Validation Loss: 0.313\n",
            "\n",
            " Epoch 43 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.354\n",
            "Validation Loss: 0.321\n",
            "\n",
            " Epoch 44 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.359\n",
            "Validation Loss: 0.324\n",
            "\n",
            " Epoch 45 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.359\n",
            "Validation Loss: 0.320\n",
            "\n",
            " Epoch 46 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.355\n",
            "Validation Loss: 0.314\n",
            "\n",
            " Epoch 47 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.353\n",
            "Validation Loss: 0.317\n",
            "\n",
            " Epoch 48 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.357\n",
            "Validation Loss: 0.324\n",
            "\n",
            " Epoch 49 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.354\n",
            "Validation Loss: 0.323\n",
            "\n",
            " Epoch 50 / 50\n",
            "  Batch    50  of  1,875.\n",
            "  Batch   100  of  1,875.\n",
            "  Batch   150  of  1,875.\n",
            "  Batch   200  of  1,875.\n",
            "  Batch   250  of  1,875.\n",
            "  Batch   300  of  1,875.\n",
            "  Batch   350  of  1,875.\n",
            "  Batch   400  of  1,875.\n",
            "  Batch   450  of  1,875.\n",
            "  Batch   500  of  1,875.\n",
            "  Batch   550  of  1,875.\n",
            "  Batch   600  of  1,875.\n",
            "  Batch   650  of  1,875.\n",
            "  Batch   700  of  1,875.\n",
            "  Batch   750  of  1,875.\n",
            "  Batch   800  of  1,875.\n",
            "  Batch   850  of  1,875.\n",
            "  Batch   900  of  1,875.\n",
            "  Batch   950  of  1,875.\n",
            "  Batch 1,000  of  1,875.\n",
            "  Batch 1,050  of  1,875.\n",
            "  Batch 1,100  of  1,875.\n",
            "  Batch 1,150  of  1,875.\n",
            "  Batch 1,200  of  1,875.\n",
            "  Batch 1,250  of  1,875.\n",
            "  Batch 1,300  of  1,875.\n",
            "  Batch 1,350  of  1,875.\n",
            "  Batch 1,400  of  1,875.\n",
            "  Batch 1,450  of  1,875.\n",
            "  Batch 1,500  of  1,875.\n",
            "  Batch 1,550  of  1,875.\n",
            "  Batch 1,600  of  1,875.\n",
            "  Batch 1,650  of  1,875.\n",
            "  Batch 1,700  of  1,875.\n",
            "  Batch 1,750  of  1,875.\n",
            "  Batch 1,800  of  1,875.\n",
            "  Batch 1,850  of  1,875.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    625.\n",
            "  Batch   100  of    625.\n",
            "  Batch   150  of    625.\n",
            "  Batch   200  of    625.\n",
            "  Batch   250  of    625.\n",
            "  Batch   300  of    625.\n",
            "  Batch   350  of    625.\n",
            "  Batch   400  of    625.\n",
            "  Batch   450  of    625.\n",
            "  Batch   500  of    625.\n",
            "  Batch   550  of    625.\n",
            "  Batch   600  of    625.\n",
            "\n",
            "Training Loss: 0.353\n",
            "Validation Loss: 0.312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "bgeH7FhYVwFS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_losses)), train_losses, label='Train')\n",
        "plt.plot(range(len(valid_losses)), valid_losses, label='Valid')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "J7oZ_iGaVzWo",
        "outputId": "fc24e97a-cfb2-4864-cfc5-428d2de97e1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de6-mVR4V2KE",
        "outputId": "1fd9123b-c0e4-40b1-972d-60dfbc28b3d3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azureml-core\n",
            "  Downloading azureml_core-1.38.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 4.9 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-containerregistry<9.0.0,>=8.2.0\n",
            "  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n",
            "\u001b[K     |████████████████████████████████| 928 kB 10.9 MB/s \n",
            "\u001b[?25hCollecting humanfriendly<11.0,>=4.7\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging<22.0,>=20.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (21.3)\n",
            "Collecting knack~=0.8.2\n",
            "  Downloading knack-0.8.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2.8.2)\n",
            "Collecting docker<6.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting azure-core<1.22\n",
            "  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2018.9)\n",
            "Collecting adal<=1.2.7,>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pkginfo\n",
            "  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 10.0 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
            "\u001b[K     |████████████████████████████████| 412 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting msal<2.0.0,>=1.15.0\n",
            "  Downloading msal-1.16.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting msal-extensions<0.4,>=0.3.0\n",
            "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2.23.0)\n",
            "Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n",
            "  Downloading azure_mgmt_storage-19.0.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 36.0 MB/s \n",
            "\u001b[?25hCollecting msrestazure<=0.6.4,>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<=1.26.7,>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (1.24.3)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contextlib2<22.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (0.5.5)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting argcomplete<2.0\n",
            "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
            "Collecting ndg-httpsclient<=0.5.1\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting azure-mgmt-resource<21.0.0,>=15.0.0\n",
            "  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting paramiko<3.0.0,>=2.0.8\n",
            "  Downloading paramiko-2.9.2-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting pyopenssl<22.0.0\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete<2.0->azureml-core) (4.10.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-core<1.22->azureml-core) (1.15.0)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0->azureml-core) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0->azureml-core) (2.21)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete<2.0->azureml-core) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete<2.0->azureml-core) (3.7.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from knack~=0.8.2->azureml-core) (0.8.9)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from knack~=0.8.2->azureml-core) (6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from knack~=0.8.2->azureml-core) (2.6.1)\n",
            "Collecting portalocker<3,>=1.0\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core) (2021.10.8)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 598 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core) (0.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=20.0->azureml-core) (3.0.7)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 480 kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.5.1->azureml-core) (3.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (1.7.1)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: PyJWT, isodate, cryptography, msrest, azure-core, adal, websocket-client, pyopenssl, pynacl, portalocker, msrestazure, msal, jmespath, jeepney, colorama, bcrypt, backports.weakref, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, ndg-httpsclient, msal-extensions, knack, jsonpickle, humanfriendly, docker, backports.tempfile, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, azureml-core\n",
            "Successfully installed PyJWT-2.3.0 SecretStorage-3.3.1 adal-1.2.7 argcomplete-1.12.3 azure-common-1.1.28 azure-core-1.21.1 azure-graphrbac-0.61.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.0.0 azureml-core-1.38.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.0 colorama-0.4.4 cryptography-36.0.1 docker-5.0.3 humanfriendly-10.0 isodate-0.6.1 jeepney-0.7.1 jmespath-0.10.0 jsonpickle-2.1.0 knack-0.8.2 msal-1.16.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 paramiko-2.9.2 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.3.2 pynacl-1.5.0 pyopenssl-21.0.0 websocket-client-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import json\n",
        "# import torch.optim as optim\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from transformers import DistilBertTokenizer\n",
        "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (classification_report, f1_score, recall_score, precision_score, \n",
        "                             precision_recall_curve, confusion_matrix, matthews_corrcoef)\n",
        "import matplotlib.pyplot as plt\n",
        "from azureml.core import Workspace, Run, Dataset\n",
        "from azureml.core.model import Model\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "test_model = BERT_Arch(bert)\n",
        "test_model = test_model.to(device)\n",
        "test_model.load_state_dict(torch.load('saved_weights.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3mOXwtunlST",
        "outputId": "ce90f5cc-65f5-4d3b-df9c-5d5a10794773"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/shorttextpreprocessedtest.csv')\n",
        "df.dropna(inplace=True)\n",
        "# print(df.head())\n",
        "\n",
        "test_text = df.text\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "max_seq_len = 25\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "\n",
        "with torch.no_grad():\n",
        "  pred_proba = test_model(test_seq.to(device), test_mask.to(device))\n",
        "  pred_proba = pred_proba.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(pred_proba, axis = 1)\n",
        "\n",
        "print([preds.tolist(), pred_proba.tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chN9lLekn3WL",
        "outputId": "60976141-eba0-4016-88f2-20624b6db8e8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1], [[-0.09677442908287048, -2.3833694458007812], [-0.2567923963069916, -1.4851373434066772], [-0.014474392868578434, -4.242604732513428], [-1.063866138458252, -0.4233015477657318], [-0.11335902661085129, -2.233339786529541], [-0.08005297929048538, -2.564826726913452], [-0.9408884048461914, -0.4947570562362671], [-0.03260103985667229, -3.439666509628296], [-0.21028225123882294, -1.662603735923767], [-0.33217230439186096, -1.2635945081710815], [-0.06949751079082489, -2.701011896133423], [-0.06296075135469437, -2.796558141708374], [-0.4273664057254791, -1.0561981201171875], [-0.6229961514472961, -0.7685933113098145], [-1.6665427684783936, -0.20936265587806702], [-0.015158222056925297, -4.196781635284424], [-0.1591564267873764, -1.9163906574249268], [-1.3168537616729736, -0.31194353103637695], [-0.4596291780471802, -0.9983628988265991], [-4.276629447937012, -0.013986782170832157], [-0.04393550381064415, -3.146918773651123], [-0.04916629567742348, -3.0370283126831055], [-0.5063282251358032, -0.9230749607086182], [-0.1300084888935089, -2.1044557094573975], [-0.279554158449173, -1.4110822677612305], [-0.9271334409713745, -0.5036618709564209], [-0.16239838302135468, -1.8978030681610107], [-0.054018568247556686, -2.9453158378601074], [-0.486721932888031, -0.9535720348358154], [-0.2290392965078354, -1.586196780204773], [-0.10896281898021698, -2.270735263824463], [-0.014336911961436272, -4.252076625823975], [-0.10024076700210571, -2.349881649017334], [-0.34877920150756836, -1.222642183303833], [-0.02972056157886982, -3.5307397842407227], [-0.27733752131462097, -1.4179861545562744], [-0.30153965950012207, -1.3458378314971924], [-0.9108760356903076, -0.5144518613815308], [-0.07444646954536438, -2.634667158126831], [-0.06896958500146866, -2.708376169204712], [-0.0072693610563874245, -4.9277262687683105], [-0.3703528344631195, -1.172766923904419], [-0.08419623225927353, -2.5164084434509277], [-2.268709182739258, -0.1091962680220604], [-0.03747939318418503, -3.302645683288574], [-0.357980877161026, -1.200932264328003], [-0.23691612482070923, -1.5561692714691162], [-0.164256751537323, -1.8873286247253418], [-0.08451484888792038, -2.5127875804901123], [-0.0739617869257927, -2.6409590244293213], [-0.20631186664104462, -1.6797493696212769], [-0.893653392791748, -0.5262070894241333], [-0.43396416306495667, -1.043940782546997], [-0.06101745739579201, -2.8269481658935547], [-0.15065337717533112, -1.9671550989151], [-0.13606218993663788, -2.0619029998779297], [-0.10025565326213837, -2.349741220474243], [-0.22401387989521027, -1.6059640645980835], [-0.5713003873825073, -0.8319277167320251], [-0.4131152331829071, -1.0834853649139404], [-0.08754037320613861, -2.4791064262390137], [-0.1751440316438675, -1.82844078540802], [-0.5522414445877075, -0.8572157621383667], [-0.3460511565208435, -1.229209542274475], [-0.4659923315048218, -0.9875507950782776], [-0.2718212604522705, -1.4354445934295654], [-0.05116444453597069, -2.9981839656829834], [-0.27418801188468933, -1.4279046058654785], [-0.04516447335481644, -3.119940996170044], [-0.1280280500650406, -2.118837356567383], [-0.05828201025724411, -2.8714616298675537], [-0.20551034808158875, -1.6832549571990967], [-0.0806848406791687, -2.557276487350464], [-0.1406288743019104, -2.0311217308044434], [-2.019094944000244, -0.1424575001001358], [-0.08472877740859985, -2.5103657245635986], [-0.021216576918959618, -3.8635621070861816], [-0.41812241077423096, -1.0737684965133667], [-0.07633326947689056, -2.610570192337036], [-1.6576367616653442, -0.2114483267068863], [-0.6530938148498535, -0.7348719835281372], [-0.11600995808839798, -2.2115237712860107], [-0.11378052085638046, -2.22983455657959], [-0.017166247591376305, -4.0733819007873535], [-0.5973064303398132, -0.7991565465927124], [-0.17317388951778412, -1.8387964963912964], [-0.5601173043251038, -0.8466296195983887], [-0.31482362747192383, -1.309028148651123], [-0.529376745223999, -0.8890936970710754], [-0.01631808839738369, -4.123626708984375], [-0.2659955322742462, -1.4543272256851196], [-0.10253854840993881, -2.32834792137146], [-0.27277669310569763, -1.4323917627334595], [-0.9542696475982666, -0.48628467321395874], [-0.16167303919792175, -1.9019267559051514], [-0.11821654438972473, -2.19376277923584], [-0.05968879908323288, -2.8483071327209473], [-0.04075660929083824, -3.2204461097717285], [-0.19390545785427094, -1.7357712984085083], [-0.2485438734292984, -1.5138353109359741], [-0.27077028155326843, -1.438816785812378], [-0.5367264747619629, -0.8786553740501404], [-0.6400713920593262, -0.7491987943649292], [-0.10339386016130447, -2.3204615116119385], [-1.062084674835205, -0.4242417514324188], [-0.10493206977844238, -2.3064491748809814], [-0.22723349928855896, -1.5932432413101196], [-0.47648781538009644, -0.9701148867607117], [-0.145644411444664, -1.9985253810882568], [-0.01373306941241026, -4.294804573059082], [-0.05677875131368637, -2.89684796333313], [-0.2610931992530823, -1.470585584640503], [-0.3648310601711273, -1.1851967573165894], [-0.008497391827404499, -4.7722368240356445], [-0.04107655584812164, -3.2127861976623535], [-0.41423892974853516, -1.0812921524047852], [-0.013107565231621265, -4.341115474700928], [-0.20198838412761688, -1.6988396644592285], [-0.018632972612977028, -3.9921271800994873], [-0.15137825906276703, -1.9627081155776978], [-0.0302424319088459, -3.5135931968688965], [-1.1153675317764282, -0.3971915543079376], [-0.21155263483524323, -1.657193660736084], [-0.023475216701626778, -3.7635254859924316], [-0.14897075295448303, -1.977565884590149], [-0.27987030148506165, -1.410102367401123], [-1.5214855670928955, -0.2463957816362381], [-0.025885947048664093, -3.6669692993164062], [-0.08381963521242142, -2.520705223083496], [-0.12755490839481354, -2.1223082542419434], [-0.15117914974689484, -1.9639273881912231], [-0.47004857659339905, -0.9807543754577637], [-0.011931009590625763, -4.434577465057373], [-0.19752433896064758, -1.719030737876892], [-0.4011431038379669, -1.1073126792907715], [-0.014665422961115837, -4.229584693908691], [-0.405452698469162, -1.0986371040344238], [-0.5790393948554993, -0.8219729661941528], [-0.5659084320068359, -0.8389687538146973], [-0.043794941157102585, -3.150054693222046], [-0.07449493557214737, -2.634040594100952], [-0.0526064932346344, -2.9711034297943115], [-0.3011307716369629, -1.3470005989074707], [-0.10343051701784134, -2.320124864578247], [-0.46997934579849243, -0.980869710445404], [-0.6793807744979858, -0.7071058750152588], [-0.5035220384597778, -0.9273470044136047], [-0.47670966386795044, -0.9697515368461609], [-0.5905929803848267, -0.8074333667755127], [-0.37219348549842834, -1.1686726808547974], [-0.047077033668756485, -3.0794150829315186], [-0.013783510774374008, -4.291163444519043], [-0.020671173930168152, -3.889331102371216], [-0.3693062663078308, -1.1751060485839844], [-0.11612799763679504, -2.210564613342285], [-0.09688436985015869, -2.382288932800293], [-0.07741474360227585, -2.597036123275757], [-0.09401214867830276, -2.4109697341918945], [-0.3206942677497864, -1.2933326959609985], [-0.10400867462158203, -2.3148350715637207], [-0.2223827987909317, -1.612486720085144], [-0.3073800504207611, -1.3294267654418945], [-0.07045730948448181, -2.6877694129943848], [-0.03772084042429924, -3.2963449954986572], [-0.48392727971076965, -0.958045482635498], [-0.04698377475142479, -3.0813522338867188], [-0.6046647429466248, -0.7902255058288574], [-0.04311135783791542, -3.165447235107422], [-0.03666139766573906, -3.3243048191070557], [-0.09103217720985413, -2.4417130947113037], [-0.25566816329956055, -1.488986849784851], [-0.471780002117157, -0.9778755903244019], [-0.13850849866867065, -2.045278549194336], [-2.3864102363586426, -0.09646597504615784], [-0.03854462131857872, -3.275149345397949], [-0.8773912191390991, -0.5376256108283997], [-0.21967092156410217, -1.623450517654419], [-0.5686085224151611, -0.8354321122169495], [-0.7865151762962341, -0.6077571511268616], [-0.18388409912586212, -1.7839832305908203], [-0.14351700246334076, -2.012202501296997], [-0.08070177584886551, -2.557075023651123], [-0.29920315742492676, -1.3525066375732422], [-0.1646326631307602, -1.8852256536483765], [-0.4585132300853729, -1.000278353691101], [-0.12394656985998154, -2.149237632751465], [-0.12960247695446014, -2.1073849201202393], [-0.6106796264648438, -0.7830318212509155], [-0.0544033981859684, -2.9384078979492188], [-0.10292838513851166, -2.32474422454834], [-0.04362742602825165, -3.153804063796997], [-0.13599851727485657, -2.062340259552002], [-0.31261348724365234, -1.315025806427002], [-0.24513693153858185, -1.5260040760040283], [-0.01815827377140522, -4.017692565917969], [-0.37658029794692993, -1.1590123176574707], [-0.4961777627468109, -0.9386727809906006], [-0.5640000700950623, -0.8414818048477173], [-0.17880579829216003, -1.809525966644287], [-0.16451960802078247, -1.8858575820922852], [-0.1825604885816574, -1.7905654907226562], [-0.033736709505319595, -3.405989170074463], [-0.022402197122573853, -3.809774398803711], [-0.018140947446227074, -4.018641471862793], [-0.5821517705917358, -0.8180186748504639], [-0.14534932374954224, -2.0004096031188965], [-0.1146242544054985, -2.2228610515594482], [-0.6245091557502747, -0.7668458223342896], [-0.30506718158721924, -1.3358820676803589], [-0.361311674118042, -1.1932365894317627], [-0.8402824401855469, -0.564909815788269], [-0.07543856650590897, -2.6219193935394287], [-0.1135883629322052, -2.2314305305480957], [-0.5857144594192505, -0.8135263919830322], [-0.2901000380516052, -1.379075527191162], [-0.3014063239097595, -1.3462169170379639], [-0.2109392136335373, -1.6598013639450073], [-0.017634976655244827, -4.046677112579346], [-1.4683953523635864, -0.2617476284503937], [-0.3629662096500397, -1.1894452571868896], [-0.06572318077087402, -2.7549850940704346], [-0.2969718277454376, -1.3589317798614502], [-0.8913149237632751, -0.5278295278549194], [-0.268392950296402, -1.4464999437332153], [-0.9974260330200195, -0.46017616987228394], [-0.04261786490678787, -3.176713705062866], [-1.1574088335037231, -0.37731435894966125], [-0.18314003944396973, -1.7876769304275513], [-0.6988658905029297, -0.6874609589576721], [-0.013508342206478119, -4.311192989349365], [-0.04095309600234032, -3.215733289718628], [-0.40026232600212097, -1.1090996265411377], [-0.026971017941832542, -3.6264488697052], [-0.15142425894737244, -1.9624269008636475], [-0.4635406732559204, -0.9916945695877075], [-0.12572719156742096, -2.135845899581909], [-0.5224188566207886, -0.8991488814353943], [-0.7480648159980774, -0.641089141368866], [-0.17578129470348358, -1.8251183032989502], [-0.32312846183776855, -1.2869229316711426], [-0.3780943751335144, -1.1557092666625977], [-0.07672351598739624, -2.605663776397705], [-0.8617270588874817, -0.54892897605896], [-0.27047234773635864, -1.4397754669189453], [-0.38459932804107666, -1.1416972875595093], [-0.4352095127105713, -1.041653037071228], [-0.3845994174480438, -1.1416971683502197], [-0.44183453917503357, -1.0296162366867065], [-0.9971165060997009, -0.460357129573822], [-0.22039921581745148, -1.6204911470413208], [-0.03799011558294296, -3.2893645763397217], [-0.15373367071151733, -1.948415756225586], [-0.3319447338581085, -1.2641723155975342], [-0.11829587817192078, -2.1931312084198], [-0.14705635607242584, -1.9895668029785156], [-0.5295072197914124, -0.8889068961143494], [-0.16318832337856293, -1.893334984779358], [-1.3059861660003662, -0.31595152616500854], [-0.25151124596595764, -1.5033888816833496], [-0.016165612265467644, -4.132938861846924], [-1.3631168603897095, -0.2955287992954254], [-0.21120350062847137, -1.6586769819259644], [-0.449384480714798, -1.0161683559417725], [-0.190249502658844, -1.7530357837677002], [-0.25249725580215454, -1.499948263168335], [-0.24066567420959473, -1.542267084121704], [-0.3292299807071686, -1.271101474761963], [-0.16558793187141418, -1.8799047470092773], [-0.09878582507371902, -2.3637876510620117], [-0.1151525229215622, -2.2185213565826416], [-0.7203174233436584, -0.6666957139968872], [-0.3296656608581543, -1.2699849605560303], [-0.060745224356651306, -2.8312854766845703], [-0.332405149936676, -1.2630038261413574], [-0.2549205720424652, -1.491557240486145], [-0.07500103861093521, -2.627518892288208], [-0.5403475761413574, -0.8735803961753845], [-0.6233084201812744, -0.7682321071624756], [-0.476389080286026, -0.9702767133712769], [-0.43688467144966125, -1.0385881662368774], [-0.05132945626974106, -2.9950459003448486], [-0.18748699128627777, -1.7663253545761108], [-0.01739448867738247, -4.06028938293457], [-0.14667430520057678, -1.991981863975525], [-0.5434495210647583, -0.8692675828933716], [-0.5916687250137329, -0.8060988187789917], [-0.14162182807922363, -2.0245707035064697], [-1.8990696668624878, -0.16217531263828278], [-0.7485659122467041, -0.6406390070915222], [-0.5064700841903687, -0.9228598475456238], [-0.026517441496253014, -3.6431798934936523], [-0.2125142514705658, -1.6531225442886353], [-0.4443216919898987, -1.0251550674438477], [-0.3206954598426819, -1.2933292388916016], [-1.0951709747314453, -0.4071902632713318], [-0.03878030925989151, -3.2691712379455566], [-0.11544857919216156, -2.2160985469818115], [-0.14934886991977692, -1.975215196609497], [-0.16298608481884003, -1.8944767713546753], [-0.3304695785045624, -1.267929196357727], [-1.0397803783416748, -0.43623214960098267], [-0.22485898435115814, -1.6026055812835693], [-0.544154703617096, -0.8682917952537537], [-0.28234270215034485, -1.4024858474731445], [-0.21148614585399628, -1.6574759483337402], [-0.04893304780125618, -3.041668176651001], [-0.15823662281036377, -1.9217392206192017], [-0.14364619553089142, -2.0113658905029297], [-0.007156334351748228, -4.94333553314209], [-0.034609731286764145, -3.380876064300537], [-0.1579887866973877, -1.9231860637664795], [-0.011152432300150394, -4.501665115356445], [-0.12978215515613556, -2.1060874462127686], [-0.21918196976184845, -1.6254431009292603], [-0.06948516517877579, -2.701184034347534], [-0.2054576277732849, -1.683485984802246], [-0.3711773455142975, -1.170930027961731], [-0.13351213932037354, -2.079576015472412], [-0.1900031715631485, -1.7542121410369873], [-0.26667141914367676, -1.4521124362945557], [-0.05877570062875748, -2.8632712364196777], [-0.494503378868103, -0.9412848949432373], [-0.004342768341302872, -5.441422939300537], [-0.13755713403224945, -2.051706075668335], [-0.1768117994070053, -1.8197729587554932], [-0.20399907231330872, -1.6899057626724243], [-0.25178882479667664, -1.5024187564849854], [-1.342172384262085, -0.3028329014778137], [-0.03395693749189377, -3.3995919227600098], [-0.04816742613911629, -3.057060480117798], [-0.011586751788854599, -4.463684558868408], [-0.047280244529247284, -3.075209140777588], [-0.13359235227108002, -2.079015016555786], [-0.4401698112487793, -1.0326197147369385], [-0.41191738843917847, -1.0858311653137207], [-0.7328042387962341, -0.6550030708312988], [-0.707303524017334, -0.6791884303092957], [-0.26177141070365906, -1.468315839767456], [-0.024379456415772438, -3.726177453994751], [-0.3556225001811981, -1.2064329385757446], [-0.12254028767347336, -2.1599597930908203], [-0.13362333178520203, -2.078798532485962], [-0.7740365266799927, -0.6183141469955444], [-0.0662529319524765, -2.747218370437622], [-0.009044983424246311, -4.710064888000488], [-0.0838075801730156, -2.5208427906036377], [-0.05508416146039963, -2.926309585571289], [-0.23620466887950897, -1.5588351488113403], [-0.028123529627919197, -3.5851755142211914], [-0.03403736650943756, -3.3972666263580322], [-0.006258887238800526, -5.076871871948242], [-0.03687018156051636, -3.318730115890503], [-0.17715215682983398, -1.8180148601531982], [-1.4294025897979736, -0.27371594309806824], [-0.3239060044288635, -1.2848870754241943], [-0.07451872527599335, -2.633732795715332], [-0.011467259377241135, -4.473987579345703], [-0.31289440393447876, -1.314260721206665], [-0.032598383724689484, -3.4397475719451904], [-0.6862589716911316, -0.7000831365585327], [-0.01215126272290945, -4.416393280029297], [-0.038880184292793274, -3.2666478157043457], [-0.3907187283039093, -1.1287739276885986], [-0.5877460241317749, -0.8109809160232544], [-1.4346435070037842, -0.27207157015800476], [-0.11993982642889023, -2.18013596534729], [-0.11858856678009033, -2.1908035278320312], [-0.03450274467468262, -3.383918046951294], [-0.5019070506095886, -0.9298195242881775], [-0.022733312100172043, -3.7952704429626465], [-0.08797235041856766, -2.4743969440460205], [-0.23328633606433868, -1.5698654651641846], [-0.0915161669254303, -2.436648368835449], [-0.12392908334732056, -2.1493701934814453], [-1.0110357999801636, -0.4523082375526428], [-0.04311923310160637, -3.165266990661621], [-0.03807469457387924, -3.2871811389923096], [-0.1909123659133911, -1.7498786449432373], [-0.6723356246948242, -0.7144011855125427], [-0.15815113484859467, -1.9222381114959717], [-0.05377436429262161, -2.9497251510620117], [-0.11258739978075027, -2.239790916442871], [-0.6162847876548767, -0.7764129042625427], [-0.16914428770542145, -1.86038339138031], [-0.1942691206932068, -1.7340736389160156], [-1.1717894077301025, -0.37079140543937683], [-0.18449847400188446, -1.7809454202651978], [-0.09941049665212631, -2.357790946960449], [-0.72242671251297, -0.6647006273269653], [-0.1455904096364975, -1.9988703727722168], [-0.3082912266254425, -1.3268990516662598], [-0.45050573348999023, -1.014195203781128], [-0.7865257263183594, -0.6077483296394348], [-0.391497939825058, -1.1271460056304932], [-0.24624799191951752, -1.522014856338501], [-0.02704017423093319, -3.623922824859619], [-0.013916482217609882, -4.281630039215088], [-0.6019055843353271, -0.7935574054718018], [-0.26544442772865295, -1.456138014793396], [-0.07763813436031342, -2.594264507293701], [-0.30370116233825684, -1.339721441268921], [-0.10165935754776001, -2.336526870727539], [-0.2899327278137207, -1.3795726299285889], [-0.6255242824554443, -0.765676736831665], [-0.04884007200598717, -3.0435256958007812], [-0.0036108787171542645, -5.625624179840088], [-0.28493979573249817, -1.394566535949707], [-0.004342768341302872, -5.441422939300537], [-0.30038008093833923, -1.3491400480270386], [-0.5221884250640869, -0.8994849920272827], [-0.0053439149633049965, -5.2344651222229], [-0.05964432656764984, -2.849029541015625], [-0.026912417262792587, -3.6285924911499023], [-0.017895663157105446, -4.032134532928467], [-0.35057079792022705, -1.2183624505996704], [-0.2903584837913513, -1.3783080577850342], [-0.01590811088681221, -4.148868560791016], [-0.10766107589006424, -2.2821149826049805], [-0.37228959798812866, -1.1684598922729492], [-0.7030947208404541, -0.6832976937294006], [-0.2633262574672699, -1.4631370306015015], [-0.010052765719592571, -4.604923725128174], [-0.2809039354324341, -1.4069088697433472], [-0.0008224442135542631, -7.103588581085205], [-0.3056434988975525, -1.33426833152771], [-0.4324602484703064, -1.0467145442962646], [-0.1650702953338623, -1.8827836513519287], [-0.746580958366394, -0.6424242854118347], [-0.3038327097892761, -1.339350938796997], [-0.0716773197054863, -2.671205997467041], [-0.1446099579334259, -2.0051488876342773], [-0.31795406341552734, -1.30061674118042], [-0.05905892327427864, -2.8586032390594482], [-0.39926213026046753, -1.1111350059509277], [-0.444240927696228, -1.025299072265625], [-0.2388250082731247, -1.5490612983703613], [-0.19394347071647644, -1.735593557357788], [-0.544550359249115, -0.8677448034286499], [-0.041490525007247925, -3.202963352203369], [-0.7235564589500427, -0.6636353135108948], [-1.0922601222991943, -0.40865641832351685], [-0.33534955978393555, -1.2555750608444214], [-0.015537872910499573, -4.172234535217285], [-0.011871756985783577, -4.439520359039307], [-0.25630778074264526, -1.4867944717407227], [-0.02268798090517521, -3.797243356704712], [-0.14675851166248322, -1.9914488792419434], [-0.17702503502368927, -1.8186712265014648], [-0.38634851574897766, -1.1379783153533936], [-0.26815667748451233, -1.447267770767212], [-0.4509474039077759, -1.013419508934021], [-0.17258210480213165, -1.8419322967529297], [-0.18817923963069916, -1.762974739074707], [-0.20964360237121582, -1.6653375625610352], [-0.23708796501159668, -1.5555272102355957], [-0.12836655974388123, -2.1163620948791504], [-0.528281569480896, -0.8906651139259338], [-0.10285062342882156, -2.325462579727173], [-0.1042608991265297, -2.3125362396240234], [-0.27903059124946594, -1.412706971168518], [-0.012118169106543064, -4.419105529785156], [-0.3939385414123535, -1.1220719814300537], [-0.014964466914534569, -4.209547519683838], [-0.13433949649333954, -2.073803186416626], [-0.5946668386459351, -0.8023961186408997], [-0.03883511945605278, -3.2677855491638184], [-0.16781632602214813, -1.8676201105117798], [-1.0701532363891602, -0.42000430822372437], [-1.0996776819229126, -0.40493282675743103], [-0.4653891324996948, -0.9885677099227905], [-0.9634507298469543, -0.48057758808135986], [-0.3945876955986023, -1.120728611946106], [-0.1447538435459137, -2.0042245388031006], [-0.16251562535762787, -1.8971388339996338], [-0.13574834167957306, -2.064059257507324], [-0.0038342783227562904, -5.56567907333374], [-0.0037506725639104843, -5.587679862976074], [-0.09078726917505264, -2.444286823272705], [-1.0411990880966187, -0.43545711040496826], [-0.21176041662693024, -1.6563124656677246], [-0.4389491379261017, -1.034830927848816], [-0.018906384706497192, -3.977694272994995], [-0.1657213717699051, -1.8791639804840088], [-0.4303506910800934, -1.0506253242492676], [-0.1807614266872406, -1.7995970249176025], [-0.023569762706756592, -3.759554624557495], [-0.22117255628108978, -1.6173611879348755], [-0.5147595405578613, -0.9104187488555908], [-0.5757116079330444, -0.8262320756912231], [-0.12074879556894302, -2.17380952835083], [-0.09588766098022461, -2.392138719558716], [-0.22807569801807404, -1.589949131011963], [-0.25933852791786194, -1.4764894247055054], [-0.039290595799684525, -3.256350040435791], [-0.18336175382137299, -1.7865747213363647], [-0.11744844913482666, -2.1999053955078125], [-0.09473446756601334, -2.4036710262298584], [-0.09330254793167114, -2.418195962905884], [-0.17217104136943817, -1.844117283821106], [-1.0493476390838623, -0.4310385286808014], [-0.05626232549548149, -2.905728816986084], [-0.09424726665019989, -2.4085874557495117], [-0.030723106116056442, -3.4980621337890625], [-0.7839174866676331, -0.6099348664283752], [-0.3433098793029785, -1.235870599746704], [-0.05472736060619354, -2.932630777359009], [-0.817622721195221, -0.5824647545814514], [-0.9222560524940491, -0.5068683624267578], [-0.09618254005908966, -2.3892130851745605], [-0.7267827391624451, -0.660606324672699], [-0.10009420663118362, -2.351273536682129], [-0.8819556832313538, -0.5343886613845825], [-0.645597517490387, -0.7430712580680847], [-0.4194408357143402, -1.0712333917617798], [-0.03837301582098007, -3.2795262336730957], [-0.15508627891540527, -1.9403146505355835], [-0.7197809815406799, -0.6672043204307556], [-0.014076118357479572, -4.2703046798706055], [-0.155130073428154, -1.940053939819336], [-0.10629557073116302, -2.294208526611328], [-0.323257714509964, -1.2865841388702393], [-0.07576341181993484, -2.6177823543548584], [-0.1455904096364975, -1.9988703727722168], [-0.3393273651599884, -1.245660424232483], [-0.41007548570632935, -1.0894546508789062], [-0.18256187438964844, -1.7905585765838623], [-0.7548655271530151, -0.6350175142288208], [-0.29413697123527527, -1.3671760559082031], [-0.3187776803970337, -1.2984198331832886], [-0.14235897362232208, -2.0197389125823975], [-0.405842125415802, -1.0978586673736572], [-0.2522927522659302, -1.5006605386734009], [-0.15405398607254028, -1.9464902877807617], [-0.25280967354774475, -1.4988614320755005], [-1.151738166809082, -0.3799245059490204], [-0.35599732398986816, -1.20555579662323], [-0.22729988396167755, -1.592983365058899], [-0.05073191225528717, -3.0064589977264404], [-0.08008994907140732, -2.564382553100586], [-0.5700992345809937, -0.8334888219833374], [-0.05293533578515053, -2.965035915374756], [-0.06834954023361206, -2.7171008586883545], [-0.04762936756014824, -3.0680253505706787], [-0.6862297654151917, -0.7001128196716309], [-0.36770081520080566, -1.178708791732788], [-0.3105026185512543, -1.3208004236221313], [-0.08323867619037628, -2.527374267578125], [-0.1058998629450798, -2.297744035720825], [-0.3257748484611511, -1.2800180912017822], [-0.9154875874519348, -0.5113614201545715], [-0.24519000947475433, -1.5258129835128784], [-0.09548477083444595, -2.396151065826416], [-0.16842684149742126, -1.8642858266830444], [-0.3460511565208435, -1.229209542274475], [-0.5345708727836609, -0.8816976547241211], [-0.4088461995124817, -1.0918843746185303], [-0.047668810933828354, -3.0672171115875244], [-0.28110384941101074, -1.4062929153442383], [-0.261743426322937, -1.4684091806411743], [-0.23034422099590302, -1.581142783164978], [-0.42797499895095825, -1.0550577640533447], [-0.030268916860222816, -3.512728452682495], [-0.06424359977245331, -2.777022123336792], [-0.014112673699855804, -4.267730712890625], [-0.6540220379829407, -0.7338656783103943], [-0.1152564212679863, -2.21766996383667], [-0.6685090661048889, -0.7184076309204102], [-0.016971591860055923, -4.084689140319824], [-0.2992912828922272, -1.3522542715072632], [-0.24513553082942963, -1.5260093212127686], [-0.3661895990371704, -1.1821178197860718], [-1.7082515954971313, -0.19989381730556488], [-0.16403570771217346, -1.8885680437088013], [-0.2592134177684784, -1.476912260055542], [-0.38221096992492676, -1.1468086242675781], [-0.44444549083709717, -1.0249334573745728], [-0.01313062570989132, -4.339365005493164], [-0.15212216973304749, -1.9581681489944458], [-0.03501015529036522, -3.3695714473724365], [-0.3023071885108948, -1.3436598777770996], [-0.3953722417354584, -1.11910879611969], [-0.4992344081401825, -0.9339333772659302], [-0.214280903339386, -1.645695686340332], [-0.023185230791568756, -3.775810718536377], [-0.02825843170285225, -3.580461025238037], [-0.1515907347202301, -1.9614089727401733], [-1.1834944486618042, -0.3655813932418823], [-0.2646269202232361, -1.458831548690796], [-0.010435893200337887, -4.567712783813477], [-0.016940532252192497, -4.086503505706787], [-0.6957612037658691, -0.6905399560928345], [-0.016735751181840897, -4.0985636711120605], [-0.09426494687795639, -2.408407688140869], [-0.16239838302135468, -1.8978030681610107], [-0.10386824607849121, -2.31611704826355], [-0.7900832891464233, -0.6047828793525696], [-0.035770613700151443, -3.348459243774414], [-0.43880173563957214, -1.0350985527038574], [-0.6650487780570984, -0.722058117389679], [-0.1680118441581726, -1.8665506839752197], [-0.26828157901763916, -1.4468618631362915], [-0.1320350617170334, -2.089979410171509], [-1.2697199583053589, -0.32976922392845154], [-0.12608003616333008, -2.133216142654419], [-0.2109392136335373, -1.6598013639450073], [-0.5703203678131104, -0.8332010507583618], [-0.3050439953804016, -1.3359472751617432], [-1.0887703895568848, -0.41042256355285645], [-0.34933483600616455, -1.221312165260315], [-0.11726325750350952, -2.201392412185669], [-2.755121946334839, -0.06571391969919205], [-0.11287622898817062, -2.237370729446411], [-1.0318372249603271, -0.4406028091907501], [-0.05779336392879486, -2.8796396255493164], [-0.26182782649993896, -1.4681273698806763], [-0.47940486669540405, -0.9653542637825012], [-0.05657464638352394, -2.900348424911499], [-0.7770569324493408, -0.6157363653182983], [-0.1429871767759323, -2.015641927719116], [-0.22305580973625183, -1.6097888946533203], [-0.272113174200058, -1.434510588645935], [-1.6168949604034424, -0.22128798067569733], [-0.739594042301178, -0.6487622261047363], [-0.731073260307312, -0.6566070914268494], [-0.06466161459684372, -2.7707431316375732], [-0.15191593766212463, -1.959424614906311], [-0.032940447330474854, -3.429478406906128], [-0.3788513243198395, -1.1540640592575073], [-0.9691364765167236, -0.47708553075790405], [-0.16239838302135468, -1.8978030681610107], [-0.1567804515361786, -1.9302754402160645], [-0.0070455437526106834, -4.958881855010986], [-0.009263865649700165, -4.686267852783203], [-0.49827098846435547, -0.9354233145713806], [-0.3902602791786194, -1.1297335624694824], [-0.19690001010894775, -1.72189462184906], [-0.2237856537103653, -1.6068737506866455], [-0.7681329250335693, -0.623394250869751], [-0.5781216025352478, -0.8231443762779236], [-0.19551126658916473, -1.72830069065094], [-0.13797758519649506, -2.0488595962524414], [-0.028406988829374313, -3.575291872024536], [-0.03200685605406761, -3.4577646255493164], [-0.8383312821388245, -0.5663939118385315], [-0.323254257440567, -1.2865933179855347], [-0.0037759689148515463, -5.580989360809326], [-0.536488950252533, -0.8789900541305542], [-4.448103427886963, -0.01176973432302475], [-0.27032098174095154, -1.440263032913208], [-0.8849284648895264, -0.5322940349578857], [-0.1717732548713684, -1.8462374210357666], [-0.04592863842844963, -3.103543519973755], [-0.5488619208335876, -0.8618187308311462], [-0.2334204763174057, -1.5693548917770386], [-0.1885528862476349, -1.7611720561981201], [-0.03909538313746452, -3.2612342834472656], [-0.5940430164337158, -0.8031644821166992], [-0.24040447175502777, -1.5432276725769043], [-0.41592541337013245, -1.0780143737792969], [-0.12197179347276688, -2.1643316745758057], [-0.258314847946167, -1.4799549579620361], [-1.212383508682251, -0.3530919551849365], [-0.35115522146224976, -1.21697199344635], [-0.33019527792930603, -1.268630027770996], [-0.01866152137517929, -3.990610361099243], [-0.08963995426893234, -2.456439256668091], [-1.2612582445144653, -0.3330942690372467], [-0.509544849395752, -0.9182150363922119], [-0.9212636351585388, -0.5075240135192871], [-0.022555705159902573, -3.8030216693878174], [-0.004342768341302872, -5.441422939300537], [-0.10802526772022247, -2.278916835784912], [-0.5608534216880798, -0.8456501364707947], [-0.10326151549816132, -2.321676731109619], [-0.25926604866981506, -1.4767345190048218], [-0.3068026006221771, -1.3310329914093018], [-2.6887760162353516, -0.07038398087024689], [-0.40106114745140076, -1.1074788570404053], [-1.072715401649475, -0.4186694622039795], [-0.26703712344169617, -1.4509170055389404], [-0.004342768341302872, -5.441422939300537], [-0.9624912142753601, -0.48117005825042725], [-0.5510801672935486, -0.8587931990623474], [-0.02764253132045269, -3.6021888256073], [-0.602214515209198, -0.7931832671165466], [-0.707303524017334, -0.6791884303092957], [-0.08699348568916321, -2.4851036071777344], [-0.1753598302602768, -1.8273144960403442], [-0.24560169875621796, -1.5243327617645264], [-0.005305970553308725, -5.241565227508545], [-0.39992818236351013, -1.1097791194915771], [-0.048019275069236755, -3.0600674152374268], [-0.7294735908508301, -0.6580942273139954], [-0.19223353266716003, -1.743621826171875], [-1.4037165641784668, -0.2819414734840393], [-0.07605799287557602, -2.6140475273132324], [-0.15017379820346832, -1.970109462738037], [-0.16239838302135468, -1.8978030681610107], [-0.18480244278907776, -1.7794462442398071], [-0.30718401074409485, -1.3299717903137207], [-0.48709815740585327, -0.9529722929000854], [-0.22590519487857819, -1.5984666347503662], [-0.9669317007064819, -0.47843581438064575], [-0.02901778742671013, -3.5543198585510254], [-0.05715902894735336, -2.8903615474700928], [-0.19978955388069153, -1.7087225914001465], [-0.35435280203819275, -1.2094120979309082], [-0.23898957669734955, -1.5484514236450195], [-0.28009843826293945, -1.4093966484069824], [-1.549269676208496, -0.2387687712907791], [-0.3953947126865387, -1.1190624237060547], [-1.3579895496368408, -0.2972978353500366], [-0.08045607805252075, -2.560002326965332], [-1.1258533000946045, -0.392117977142334], [-0.4302748739719391, -1.0507662296295166], [-0.39774206280708313, -1.1142396926879883], [-0.39825722575187683, -1.1131857633590698], [-0.20987634360790253, -1.6643403768539429], [-0.5174553990364075, -0.9064276814460754], [-0.16268767416477203, -1.8961642980575562], [-0.37958094477653503, -1.1524816751480103], [-0.00824393704533577, -4.8023905754089355], [-0.2607642710208893, -1.4716888666152954], [-0.020252114161849022, -3.9096038341522217], [-0.6952872276306152, -0.6910117268562317], [-0.2747093141078949, -1.426254153251648], [-0.29683107137680054, -1.3593392372131348], [-0.13373513519763947, -2.0780162811279297], [-0.06735438853502274, -2.7312750816345215], [-0.1116655096411705, -2.24756121635437], [-0.07464740425348282, -2.632070541381836], [-0.01642726920545101, -4.117018222808838], [-0.029582500457763672, -3.5353260040283203], [-0.22463741898536682, -1.6034847497940063], [-0.35854634642601013, -1.1996197700500488], [-0.06210150197148323, -2.809875011444092], [-0.14755409955978394, -1.9864304065704346], [-0.1495097428560257, -1.9742177724838257], [-0.6475533246994019, -0.7409195303916931], [-0.15154248476028442, -1.9617035388946533], [-0.1300084888935089, -2.1044559478759766], [-0.24696239829063416, -1.5194605588912964], [-0.24318192899227142, -1.5330734252929688], [-0.3120476305484772, -1.316569447517395], [-0.17905789613723755, -1.808239221572876], [-0.3797483742237091, -1.1521189212799072], [-0.11645888537168503, -2.207881450653076], [-0.5690847635269165, -0.8348104953765869], [-0.08512287586927414, -2.505918264389038], [-0.005022883880883455, -5.296250820159912], [-0.22032156586647034, -1.6208062171936035], [-0.24416883289813995, -1.529496669769287], [-1.5753356218338013, -0.23185403645038605], [-0.26136043667793274, -1.4696904420852661], [-1.6287977695465088, -0.21836157143115997], [-0.08544328063726425, -2.5023205280303955], [-0.35669106245040894, -1.203935146331787], [-0.03685777261853218, -3.3190624713897705], [-0.15670320391654968, -1.9307301044464111], [-0.2721385955810547, -1.434429407119751], [-0.11410260945558548, -2.227165937423706], [-0.6895041465759277, -0.6968035697937012], [-0.12945930659770966, -2.1084201335906982], [-0.31216689944267273, -1.3162438869476318], [-0.2016880363225937, -1.7001827955245972], [-0.14179770648479462, -2.0234150886535645], [-0.7375278472900391, -0.6506527662277222], [-0.30903664231300354, -1.3248378038406372], [-1.9952144622802734, -0.14616458117961884], [-0.5982851982116699, -0.7979601621627808], [-0.5588669776916504, -0.8482971787452698], [-0.1016114354133606, -2.3369743824005127], [-0.3501788079738617, -1.2192965745925903], [-0.21375080943107605, -1.6479170322418213], [-0.03034212440252304, -3.510350227355957], [-0.007825195789337158, -4.8543171882629395], [-0.17527709901332855, -1.827746033668518], [-0.5908920764923096, -0.807062029838562], [-0.9019536972045898, -0.5204992294311523], [-0.4186412990093231, -1.0727696418762207], [-0.4622914791107178, -0.9938166737556458], [-1.4773331880569458, -0.2590888738632202], [-0.27471765875816345, -1.4262276887893677], [-0.2638620138168335, -1.4613608121871948], [-0.04895234480500221, -3.0412840843200684], [-0.06939697265625, -2.7024099826812744], [-0.04728979617357254, -3.075012445449829], [-0.16468170285224915, -1.8849515914916992], [-0.570124089717865, -0.8334564566612244], [-0.40575140714645386, -1.0980398654937744], [-2.4497601985931396, -0.09026861190795898], [-0.10823861509561539, -2.277048110961914], [-0.08005297929048538, -2.564826726913452], [-0.010409939102828503, -4.570198059082031], [-0.04893770068883896, -3.041576862335205], [-0.028338855132460594, -3.5776586532592773], [-0.003844253486022353, -5.563083648681641], [-0.5508297681808472, -0.8591339588165283], [-0.25065210461616516, -1.506399154663086], [-0.2318461835384369, -1.575365662574768], [-0.23909038305282593, -1.5480782985687256], [-0.11490803211927414, -2.220527410507202], [-0.3666554391384125, -1.181065320968628], [-1.7363942861557007, -0.19377219676971436], [-0.5592634081840515, -0.8477680087089539], [-0.42556577920913696, -1.0595839023590088], [-0.6897646188735962, -0.6965410709381104], [-0.5925030708312988, -0.8050659894943237], [-0.055868856608867645, -2.9125521183013916], [-0.06842702627182007, -2.716006278991699], [-1.011514663696289, -0.4520344138145447], [-0.3555365204811096, -1.2066341638565063], [-0.23735445737838745, -1.5545318126678467], [-0.1455904096364975, -1.9988703727722168], [-0.1307247430086136, -2.0993118286132812], [-0.23445986211299896, -1.5654113292694092], [-0.6273266077041626, -0.7636072039604187], [-0.17627273499965668, -1.8225648403167725], [-0.3298318088054657, -1.269559621810913], [-0.28227007389068604, -1.4027081727981567], [-0.3817361295223236, -1.147829294204712], [-0.048994798213243484, -3.0404388904571533], [-0.062151242047548294, -2.8090999126434326], [-0.496787965297699, -0.9377238750457764], [-0.02994503080844879, -3.523326873779297], [-0.3794223964214325, -1.1528252363204956], [-0.07571755349636078, -2.618365526199341], [-0.5598537921905518, -0.8469807505607605], [-0.08557756245136261, -2.5008158683776855], [-1.7190465927124023, -0.197520911693573], [-0.10169273614883423, -2.336214542388916], [-0.2284587174654007, -1.5884552001953125], [-0.5948907136917114, -0.802120566368103], [-0.128066748380661, -2.118553400039673], [-0.03103761188685894, -3.4880359172821045], [-0.1962035745382309, -1.7251009941101074], [-0.6773695945739746, -0.7091777920722961], [-0.030900657176971436, -3.492387533187866], [-0.005743666552007198, -5.162521839141846], [-0.09865503013134003, -2.3650479316711426], [-0.13016675412654877, -2.103316307067871], [-1.2986983060836792, -0.3186730444431305], [-0.41598260402679443, -1.0779035091400146], [-0.09723585098981857, -2.378840208053589], [-0.220801442861557, -1.618861436843872], [-0.4015955626964569, -1.1063966751098633], [-2.8192992210388184, -0.06150072067975998], [-0.784648597240448, -0.609320878982544], [-0.908239483833313, -0.5162293910980225], [-0.004342768341302872, -5.441422939300537], [-0.3641052544116974, -1.18684720993042], [-0.5490543842315674, -0.8615554571151733], [-0.27239927649497986, -1.4335963726043701], [-0.3521772027015686, -1.2145469188690186], [-0.3149900734424591, -1.3085784912109375], [-0.05993280187249184, -2.844348669052124], [-0.061518993228673935, -2.8190109729766846], [-0.06164856627583504, -2.816972017288208], [-0.06926483660936356, -2.704249858856201], [-0.03757986053824425, -3.3000190258026123], [-0.9584043622016907, -0.4837040305137634], [-0.4029141962528229, -1.1037336587905884], [-0.07374631613492966, -2.643770217895508], [-0.01769295148551464, -4.043420314788818], [-0.16905540227890015, -1.8608660697937012], [-0.4404270052909851, -1.0321547985076904], [-1.6004347801208496, -0.22540710866451263], [-0.6223946809768677, -0.7692892551422119], [-0.17164453864097595, -1.8469246625900269], [-0.05039520189166069, -3.0129506587982178], [-0.02319280058145523, -3.7754898071289062], [-0.42574575543403625, -1.0592447519302368], [-0.03470749035477638, -3.3781023025512695], [-0.1206076368689537, -2.174910545349121], [-0.09099996089935303, -2.442051887512207], [-2.387014150619507, -0.09640481323003769], [-0.4826887249946594, -0.9600386619567871], [-0.030144579708576202, -3.516785144805908], [-0.029012462124228477, -3.5545003414154053], [-0.17752106487751007, -1.8161135911941528], [-0.32166677713394165, -1.2907650470733643], [-0.2286810576915741, -1.5875895023345947], [-0.6201852560043335, -0.7718544602394104], [-1.9068251848220825, -0.16081592440605164], [-0.09256864339113235, -2.425731658935547], [-0.03600718453526497, -3.341987371444702], [-0.3276125490665436, -1.2752619981765747], [-0.14332985877990723, -2.013416051864624], [-0.9060056209564209, -0.5177416801452637], [-0.5871627330780029, -0.8117107152938843], [-0.017765795812010765, -4.039350509643555], [-0.6884254813194275, -0.697891354560852], [-0.14385217428207397, -2.01003360748291], [-0.39876285195350647, -1.1121530532836914], [-0.2703401744365692, -1.4402010440826416], [-0.0033702023793011904, -5.694457054138184], [-1.9137754440307617, -0.15960834920406342], [-0.06410373747348785, -2.779132843017578], [-0.23982445895671844, -1.5453648567199707], [-0.3204960525035858, -1.2938570976257324], [-0.2813124358654022, -1.4056503772735596], [-0.39707309007644653, -1.1156107187271118], [-0.40063533186912537, -1.1083422899246216], [-0.4277319312095642, -1.0555130243301392], [-0.03316972777247429, -3.4226551055908203], [-0.32228535413742065, -1.2891364097595215], [-0.1329793930053711, -2.0833139419555664], [-0.6684486269950867, -0.7184712886810303], [-0.4602571129798889, -0.9972874522209167], [-0.02249917760491371, -3.805504560470581], [-0.2527502477169037, -1.4990683794021606], [-0.015737032517790794, -4.159597396850586], [-0.03472418710589409, -3.377629280090332], [-0.1174619123339653, -2.1997976303100586], [-0.33497852087020874, -1.256507158279419], [-0.09638737887144089, -2.3871870040893555], [-0.23702985048294067, -1.5557444095611572], [-0.11773206293582916, -2.197632074356079], [-0.01530122384428978, -4.187464237213135], [-0.027975162491202354, -3.5903947353363037], [-0.3576826751232147, -1.2016253471374512], [-0.057608712464571, -2.8827476501464844], [-1.1212433576583862, -0.39433884620666504], [-0.003684638300910592, -5.605432033538818], [-0.5584501028060913, -0.8488541841506958], [-0.677761435508728, -0.7087733745574951], [-0.07395680248737335, -2.641024589538574], [-0.39926213026046753, -1.1111350059509277], [-0.045396894216537476, -3.1149234771728516], [-0.06556800752878189, -2.757272243499756], [-0.12415380030870438, -2.1476688385009766], [-0.276676207780838, -1.420058012008667], [-0.6120813488960266, -0.7813690900802612], [-0.09046182036399841, -2.4477169513702393], [-0.41162756085395813, -1.0864001512527466], [-0.11170197278261185, -2.2472524642944336], [-0.05964432656764984, -2.849029541015625], [-0.0349673330783844, -3.370772123336792], [-0.28232112526893616, -1.4025517702102661], [-0.03419958055019379, -3.3925914764404297], [-0.46669793128967285, -0.9863632321357727], [-0.11711397022008896, -2.2025938034057617], [-0.30248498916625977, -1.3431568145751953], [-0.45489102602005005, -1.0065357685089111], [-0.08691556751728058, -2.4859609603881836], [-0.09360416233539581, -2.4151177406311035], [-0.01980856992304325, -3.9315273761749268], [-0.8643258213996887, -0.5470324754714966], [-1.594366431236267, -0.22694718837738037], [-0.10738851130008698, -2.2845160961151123], [-0.03029644303023815, -3.5118331909179688], [-1.1519715785980225, -0.37981653213500977], [-0.32900935411453247, -1.27166748046875], [-0.3862367868423462, -1.1382150650024414], [-0.30969035625457764, -1.3230345249176025], [-0.42235758900642395, -1.065659999847412], [-0.10032444447278976, -2.349088191986084], [-0.3905971050262451, -1.1290284395217896], [-0.19333143532276154, -1.7384581565856934], [-0.3434387445449829, -1.2355561256408691], [-0.06376948952674866, -2.7841951847076416], [-0.677465558052063, -0.7090787291526794], [-0.12488509714603424, -2.1421542167663574], [-0.1738106906414032, -1.835435390472412], [-0.3072652816772461, -1.3297456502914429], [-0.22017866373062134, -1.6213862895965576], [-0.12136602401733398, -2.169013738632202], [-1.6112886667251587, -0.22268138825893402], [-0.1377856582403183, -2.0501580238342285], [-0.13408485054969788, -2.075576066970825], [-0.07976078242063522, -2.5683391094207764], [-2.6911373138427734, -0.0702119693160057], [-1.0019619464874268, -0.4575350880622864], [-0.35322076082229614, -1.2120792865753174], [-0.06905481219291687, -2.707183599472046], [-0.20599670708179474, -1.6811261177062988], [-0.4545614719390869, -1.0071080923080444], [-0.07546664774417877, -2.621561050415039], [-0.41490697860717773, -1.0799918174743652], [-0.32464924454689026, -1.2829468250274658], [-0.5060312747955322, -0.9235255718231201], [-0.49768558144569397, -0.9363301992416382], [-1.34952712059021, -0.3002445697784424], [-0.18381060659885406, -1.7843472957611084], [-0.04216436296701431, -3.1871883869171143], [-0.1568726748228073, -1.9297322034835815], [-0.027581535279750824, -3.6043665409088135], [-0.03145194426178932, -3.4749791622161865], [-0.45833808183670044, -1.0005793571472168], [-0.315515398979187, -1.3071610927581787], [-0.07246119529008865, -2.6607165336608887], [-0.4860970079898834, -0.9545693397521973], [-0.8104749917984009, -0.5881510972976685], [-0.8919504880905151, -0.5273878574371338], [-1.9873377084732056, -0.14740999042987823], [-0.3698557913303375, -1.1738767623901367], [-0.36506766080856323, -1.184659481048584], [-0.15648742020130157, -1.932003140449524], [-0.7085807919502258, -0.6779481172561646], [-0.04274363070726395, -3.173830509185791], [-0.0795207992196083, -2.5712337493896484], [-0.26246941089630127, -1.4659868478775024], [-0.0829019844532013, -2.5312609672546387], [-0.36562085151672363, -1.1834050416946411], [-0.2439398318529129, -1.5303254127502441], [-0.060228489339351654, -2.839573860168457], [-0.3536902964115143, -1.210971713066101], [-0.016311168670654297, -4.124046802520752], [-0.1802857220172882, -1.8020012378692627], [-0.029538404196500778, -3.5367956161499023], [-0.12095426768064499, -2.1722099781036377], [-0.15885381400585175, -1.9181468486785889], [-0.39171430468559265, -1.1266944408416748], [-0.3193036913871765, -1.2970199584960938], [-0.03696209192276001, -3.316286563873291], [-0.2647024989128113, -1.4585824012756348], [-0.22886693477630615, -1.5868667364120483], [-0.8158899545669556, -0.5838366150856018], [-0.03898521140217781, -3.264002799987793], [-0.2801828384399414, -1.4091355800628662], [-0.05225604772567749, -2.977614402770996], [-0.3344162106513977, -1.2579216957092285], [-0.3360867500305176, -1.2537273168563843], [-0.5869530439376831, -0.8119733333587646], [-0.25785696506500244, -1.481509804725647], [-0.078780896961689, -2.580216407775879], [-0.3425741195678711, -1.2376693487167358], [-0.12098933756351471, -2.1719377040863037], [-0.006307220086455345, -5.069221496582031], [-0.005936135072261095, -5.129666805267334], [-0.17100997269153595, -1.8503204584121704], [-0.4199462831020355, -1.0702643394470215], [-0.40974122285842896, -1.0901145935058594], [-0.499911904335022, -0.9328879117965698], [-0.15436458587646484, -1.9446275234222412], [-0.15132856369018555, -1.963012456893921], [-0.9445562362670898, -0.49241623282432556], [-0.6623162031173706, -0.7249591946601868], [-0.07162738591432571, -2.671877145767212], [-0.1066204085946083, -2.291316270828247], [-0.5862360000610352, -0.8128719329833984], [-0.28401586413383484, -1.3973743915557861], [-0.19221170246601105, -1.7437249422073364], [-1.210381031036377, -0.3539412021636963], [-0.23308268189430237, -1.5706406831741333], [-0.26034921407699585, -1.47308349609375], [-0.09220986068248749, -2.429439067840576], [-0.4290156960487366, -1.053112268447876], [-0.15145878493785858, -1.9622151851654053], [-0.2959185838699341, -1.3619842529296875], [-0.07287468016147614, -2.6552298069000244], [-0.07351341843605042, -2.6468193531036377], [-0.024545572698116302, -3.719472885131836], [-0.22010883688926697, -1.6216696500778198], [-0.007190421223640442, -4.938599109649658], [-0.096375472843647, -2.3873038291931152], [-0.3036406338214874, -1.3398921489715576], [-0.36770421266555786, -1.1787011623382568], [-0.2991669178009033, -1.3526105880737305], [-0.031128672882914543, -3.4851486682891846], [-0.35694456100463867, -1.2033441066741943], [-0.2709389328956604, -1.4382743835449219], [-0.7614980936050415, -0.6291707158088684], [-0.48591604828834534, -0.9548584222793579], [-0.5383694767951965, -0.8763472437858582], [-0.032760027796030045, -3.4348831176757812], [-0.08422724902629852, -2.516054391860962], [-0.1074969619512558, -2.283560037612915], [-0.2686977982521057, -1.4455103874206543], [-0.19125013053417206, -1.748274326324463], [-0.04617294669151306, -3.098358154296875], [-0.39250320196151733, -1.1250512599945068], [-0.06903266906738281, -2.7074925899505615], [-0.08077632635831833, -2.5561881065368652], [-0.0281857680529356, -3.582996368408203], [-0.07732096314430237, -2.5982019901275635], [-0.06607519090175629, -2.749817371368408], [-0.3647070527076721, -1.1854784488677979], [-0.3460511565208435, -1.229209542274475], [-0.15416444838047028, -1.9458277225494385], [-0.021470848470926285, -3.851773500442505], [-1.5528582334518433, -0.23780322074890137], [-0.5677931904792786, -0.8364976644515991], [-0.14276449382305145, -2.017091989517212], [-0.24485541880130768, -1.5270181894302368], [-0.20262308418750763, -1.6960091590881348], [-0.16239838302135468, -1.8978030681610107], [-0.09010304510593414, -2.451514720916748], [-0.31171756982803345, -1.3174712657928467], [-1.0405380725860596, -0.4358179271221161], [-0.22635513544082642, -1.596693992614746], [-0.3596874475479126, -1.1969788074493408], [-0.16239838302135468, -1.8978030681610107], [-0.01476268656551838, -4.223024368286133], [-0.9816294312477112, -0.4695238471031189], [-0.21590323746204376, -1.6389350891113281], [-0.011319346725940704, -4.4868974685668945], [-0.1950443834066391, -1.7304657697677612], [-0.003131844801828265, -5.767691612243652], [-0.19904394447803497, -1.7121015787124634], [-0.6702289581298828, -0.7166029810905457], [-0.17102906107902527, -1.8502179384231567], [-0.39056581258773804, -1.129093885421753], [-1.8517248630523682, -0.17074820399284363], [-0.6408528089523315, -0.7483278512954712], [-0.32362639904022217, -1.2856186628341675], [-0.09584314376115799, -2.392580986022949], [-0.20036837458610535, -1.7061095237731934], [-0.018156282603740692, -4.017806053161621], [-0.13102668523788452, -2.0971522331237793], [-0.43425053358078003, -1.0434141159057617], [-0.05598079413175583, -2.910606861114502], [-0.0788176953792572, -2.579767942428589], [-0.07494010031223297, -2.6283020973205566], [-0.272048681974411, -1.4347164630889893], [-0.40095409750938416, -1.1076958179473877], [-0.06486876308917999, -2.7676479816436768], [-0.4083888530731201, -1.0927903652191162], [-0.16080759465694427, -1.9068734645843506], [-0.31175389885902405, -1.3173719644546509], [-0.3003575801849365, -1.3492043018341064], [-4.431758880615234, -0.011964816600084305], [-0.18957267701625824, -1.7562724351882935], [-0.06298369914293289, -2.79620623588562], [-0.18194124102592468, -1.7936633825302124], [-0.3338245749473572, -1.2594130039215088], [-0.7412421703338623, -0.6472595930099487], [-0.02725294791162014, -3.6161911487579346], [-0.010057131759822369, -4.604502201080322], [-0.4131762683391571, -1.0833660364151], [-0.023703651502728462, -3.7539520263671875], [-0.33631664514541626, -1.2531521320343018], [-0.2651153802871704, -1.4572210311889648], [-0.15486033260822296, -1.9416626691818237], [-0.22886142134666443, -1.5868877172470093], [-0.6782422065734863, -0.7082778215408325], [-0.5763147473335266, -0.8254576921463013], [-0.5701552629470825, -0.8334158658981323], [-0.038384828716516495, -3.2792253494262695], [-0.3815828859806061, -1.1481590270996094], [-0.03831243887543678, -3.281076431274414], [-0.28827908635139465, -1.3845056295394897], [-0.0446108877658844, -3.1319994926452637], [-0.06502293050289154, -2.765349864959717], [-0.31102150678634644, -1.3193764686584473], [-0.37038394808769226, -1.1726975440979004], [-0.04533606022596359, -3.1162338256835938], [-0.030445044860243797, -3.507016658782959], [-0.006412525195628405, -5.052714824676514], [-0.03449307009577751, -3.3841938972473145], [-0.029638513922691345, -3.5334627628326416], [-0.3337979316711426, -1.2594799995422363], [-0.5841206312179565, -0.8155317902565002], [-2.6684317588806152, -0.07188369333744049], [-1.3533647060394287, -0.2989041209220886], [-0.07782983034849167, -2.591892957687378], [-0.11893133819103241, -2.1880853176116943], [-0.4672855734825134, -0.9853759407997131], [-1.265201210975647, -0.3315398693084717], [-0.6183063983917236, -0.7740455269813538], [-0.09767717123031616, -2.374528408050537], [-0.06479770690202713, -2.768709421157837], [-0.1455904096364975, -1.9988703727722168], [-0.18526817858219147, -1.7771552801132202], [-0.16239838302135468, -1.8978030681610107], [-0.4467409551143646, -1.02084481716156], [-0.23235052824020386, -1.5734353065490723], [-0.8506147861480713, -0.5571353435516357], [-0.0807841345667839, -2.5560948848724365], [-0.36132553219795227, -1.1932048797607422], [-0.057282302528619766, -2.8882687091827393], [-0.16921907663345337, -1.8599777221679688], [-0.010597973130643368, -4.5523881912231445], [-0.08665084093809128, -2.4888806343078613], [-0.145006000995636, -2.0026073455810547], [-0.837287425994873, -0.5671899914741516], [-1.088348150253296, -0.41063693165779114], [-0.4937325716018677, -0.942490816116333], [-0.14892710745334625, -1.9778379201889038], [-0.08310846984386444, -2.5288748741149902], [-0.47108227014541626, -0.9790342450141907], [-0.1423831582069397, -2.019580841064453], [-0.17013266682624817, -1.8550370931625366], [-0.16158469021320343, -1.9024304151535034], [-0.023551249876618385, -3.7603306770324707], [-0.18694129586219788, -1.7689754962921143], [-0.0357939638197422, -3.3478200435638428], [-0.19047003984451294, -1.7519841194152832], [-1.4658305644989014, -0.2625162601470947], [-0.6134591102600098, -0.7797397375106812], [-0.010445330291986465, -4.566813945770264], [-2.1927361488342285, -0.11834554374217987], [-0.13488735258579254, -2.0700011253356934], [-0.4605451822280884, -0.9967950582504272], [-0.08922582119703293, -2.4608659744262695], [-0.01010209508240223, -4.600054740905762], [-0.03321273997426033, -3.4213833808898926], [-0.12324535846710205, -2.1545681953430176], [-0.24081167578697205, -1.5417307615280151], [-2.908130407333374, -0.056123487651348114], [-0.037669867277145386, -3.297671318054199], [-0.41309717297554016, -1.0835206508636475], [-0.005595615599304438, -5.188573837280273], [-0.3119456171989441, -1.3168480396270752], [-0.35103580355644226, -1.2172558307647705], [-0.038006410002708435, -3.288942575454712], [-0.11855319887399673, -2.191084384918213], [-0.7180875539779663, -0.6688136458396912], [-0.11459522694349289, -2.22309947013855], [-0.012518754228949547, -4.386783123016357], [-0.024962954223155975, -3.702819347381592], [-0.015183113515377045, -4.195152759552002], [-0.16106224060058594, -1.9054148197174072], [-0.09671252965927124, -2.3839786052703857], [-0.3050791323184967, -1.3358486890792847], [-0.02504829317331314, -3.6994495391845703], [-0.25602665543556213, -1.4877573251724243], [-0.2041032761335373, -1.6894454956054688], [-1.0085216760635376, -0.4537489712238312], [-0.26425275206565857, -1.4600679874420166], [-0.2923927307128906, -1.3722940683364868], [-0.2995433807373047, -1.3515318632125854], [-0.5051963925361633, -0.9247943758964539], [-1.5017049312591553, -0.2519933581352234], [-0.0789397582411766, -2.578280210494995], [-0.2748975157737732, -1.4256591796875], [-0.41901615262031555, -1.0720490217208862], [-0.592239499092102, -0.8053919076919556], [-1.8546116352081299, -0.17021161317825317], [-0.14514952898025513, -2.00168776512146], [-1.5104248523712158, -0.24950820207595825], [-0.32476821541786194, -1.2826367616653442], [-0.2876426577568054, -1.3864126205444336], [-0.388143926858902, -1.1341814994812012], [-0.12251655757427216, -2.160141944885254], [-0.854092001914978, -0.5545503497123718], [-0.32856443524360657, -1.2728103399276733], [-0.15235936641693115, -1.95672607421875], [-0.17132169008255005, -1.8486506938934326], [-0.9138554334640503, -0.5124524235725403], [-0.11016389727592468, -2.260361909866333], [-0.3219679892063141, -1.2899715900421143], [-0.657370924949646, -0.7302510738372803], [-0.46966272592544556, -0.9813976883888245], [-0.027731236070394516, -3.5990288257598877], [-0.10675530135631561, -2.29011869430542], [-0.11184588074684143, -2.246035099029541], [-1.6352670192718506, -0.21678920090198517], [-0.23189109563827515, -1.5751936435699463], [-0.1598614603281021, -1.9123135805130005], [-0.1708907037973404, -1.8509601354599], [-0.753103494644165, -0.6365832090377808], [-0.3518037796020508, -1.2154319286346436], [-0.05390370264649391, -2.947387456893921], [-1.1478111743927002, -0.3817445933818817], [-0.34215247631073, -1.2387018203735352], [-0.4304317831993103, -1.0504744052886963], [-0.0696350634098053, -2.6991026401519775], [-0.10828300565481186, -2.2766597270965576], [-0.9654260873794556, -0.4793607294559479], [-2.1650588512420654, -0.12187755852937698], [-0.13263992965221405, -2.0857040882110596], [-0.1492285281419754, -1.9759626388549805], [-0.15811723470687866, -1.922435998916626], [-0.11988124996423721, -2.180595874786377], [-0.42948412895202637, -1.0522387027740479], [-0.30835220217704773, -1.3267300128936768], [-0.09083200991153717, -2.4438154697418213], [-0.3285529613494873, -1.272840142250061], [-0.05249180272221565, -2.9732296466827393], [-0.0772535428404808, -2.599040985107422], [-0.011856913566589355, -4.440764904022217], [-0.07193516939878464, -2.6677420139312744], [-0.01960846595466137, -3.941582679748535], [-0.09697362780570984, -2.38141131401062], [-0.22940263152122498, -1.584786295890808], [-0.015640098601579666, -4.165727138519287], [-0.13217481970787048, -2.0889892578125], [-0.04899059608578682, -3.040522813796997], [-0.6467025876045227, -0.7418544292449951], [-0.6675999164581299, -0.7193641662597656], [-0.17283476889133453, -1.8405920267105103], [-0.2461957037448883, -1.5222021341323853], [-0.05521378293633461, -2.924022912979126], [-0.007372553460299969, -4.913670063018799], [-0.04340247064828873, -3.1588611602783203], [-0.5619325637817383, -0.84421706199646], [-0.10527461767196655, -2.303358554840088], [-0.7279656529426575, -0.6595004200935364], [-0.18697966635227203, -1.7687889337539673], [-0.526657223701477, -0.8930037021636963], [-0.16709206998348236, -1.8715931177139282], [-0.8055522441864014, -0.5921100378036499], [-0.7557229399681091, -0.6342574954032898], [-0.18903444707393646, -1.758854627609253], [-0.030487827956676483, -3.505634069442749], [-0.005893235560506582, -5.136902809143066], [-1.1831581592559814, -0.36572983860969543], [-0.024315351620316505, -3.728778123855591], [-0.3954486548900604, -1.1189512014389038], [-3.115621566772461, -0.045364540070295334], [-0.6091595888137817, -0.7848408818244934], [-0.5655466318130493, -0.8394442796707153], [-0.1265547126531601, -2.129690408706665], [-0.4047344923019409, -1.100075125694275], [-0.2771473228931427, -1.4185811281204224], [-0.07781151682138443, -2.5921194553375244], [-0.15957461297512054, -1.9139704704284668], [-0.5279715061187744, -0.8911108374595642], [-0.10151730477809906, -2.3378548622131348], [-0.06531510502099991, -2.761012554168701], [-0.16507382690906525, -1.8827645778656006], [-0.02348325029015541, -3.763188600540161], [-0.7462023496627808, -0.6427655816078186], [-0.49020177125930786, -0.9480466842651367], [-2.013075351715088, -0.14338232576847076], [-0.5681465864181519, -0.8360355496406555], [-0.19535399973392487, -1.7290294170379639], [-2.033578634262085, -0.140258327126503], [-0.023776758462190628, -3.7509098052978516], [-0.45539391040802, -1.0056633949279785], [-0.13200633227825165, -2.0901827812194824], [-0.26087042689323425, -1.4713325500488281], [-0.028935682028532028, -3.5571134090423584], [-0.028211960569024086, -3.582080841064453], [-0.35493868589401245, -1.2080357074737549], [-0.01645529642701149, -4.115320682525635], [-0.23577184975147247, -1.5604615211486816], [-0.6537246108055115, -0.73418790102005], [-0.4428243935108185, -1.0278369188308716], [-0.024564184248447418, -3.7187247276306152], [-0.34546297788619995, -1.2306336164474487], [-0.37639713287353516, -1.1594128608703613], [-0.2507462501525879, -1.5060685873031616], [-0.6083669662475586, -0.7857866287231445], [-0.021942228078842163, -3.830294609069824], [-0.49092525243759155, -0.9469043016433716], [-0.1269698441028595, -2.126619338989258], [-0.03579465299844742, -3.347799301147461], [-0.038847390562295914, -3.26747465133667], [-5.644962787628174, -0.0035415091551840305], [-0.2577231228351593, -1.4819648265838623], [-1.9564239978790283, -0.15240901708602905], [-1.0800246000289917, -0.4148901402950287], [-0.02848079614341259, -3.5727319717407227], [-0.8174829483032227, -0.5825751423835754], [-1.2273931503295898, -0.3468031585216522], [-0.0107590826228261, -4.537382125854492], [-0.15667130053043365, -1.9309183359146118], [-0.31345438957214355, -1.3127381801605225], [-0.22543661296367645, -1.6003178358078003], [-0.053997110575437546, -2.945702075958252], [-0.45199087262153625, -1.0115909576416016], [-0.15831191837787628, -1.9212998151779175], [-0.010127939283847809, -4.5975213050842285], [-4.6259942054748535, -0.009842201136052608], [-0.07292887568473816, -2.6545138359069824], [-0.12068551033735275, -2.1743035316467285], [-0.03640417754650116, -3.3312199115753174], [-0.5028422474861145, -0.9283866882324219], [-0.16239838302135468, -1.8978030681610107], [-0.522172212600708, -0.8995087146759033], [-0.06891506165266037, -2.7091403007507324], [-0.04474198818206787, -3.1291303634643555], [-0.26620417833328247, -1.4536428451538086], [-0.44629746675491333, -1.0216326713562012], [-0.004896791186183691, -5.3216118812561035], [-0.5324974060058594, -0.8846389055252075], [-0.11669705808162689, -2.2059552669525146], [-0.6087191104888916, -0.7853661775588989], [-0.3924223780632019, -1.1252193450927734], [-0.09365713596343994, -2.414578437805176], [-0.030159154906868935, -3.516309976577759], [-0.031006408855319023, -3.489023208618164], [-0.1228712722659111, -2.1574249267578125], [-0.06691620498895645, -2.737586259841919], [-0.7610799074172974, -0.6295372843742371], [-0.02293640375137329, -3.786475419998169], [-0.1584835648536682, -1.920299768447876], [-0.08637161552906036, -2.491971731185913], [-0.4301129877567291, -1.0510674715042114], [-0.7268924117088318, -0.6605037450790405], [-0.29949769377708435, -1.3516627550125122], [-0.4819485545158386, -0.9612329006195068], [-1.3020691871643066, -0.3174109160900116], [-0.08407820761203766, -2.5177531242370605], [-0.06818798184394836, -2.7193877696990967], [-0.015190980397164822, -4.194642066955566], [-0.3307799994945526, -1.2671371698379517], [-0.5069226622581482, -0.9221740961074829], [-1.0803420543670654, -0.4147269129753113], [-0.42857539653778076, -1.0539346933364868], [-0.11992766708135605, -2.1802313327789307], [-1.1646058559417725, -0.3740328550338745], [-3.1768393516540527, -0.04261249676346779], [-0.13020819425582886, -2.103018283843994], [-0.12785884737968445, -2.120077133178711], [-0.3460511565208435, -1.229209542274475], [-0.33145490288734436, -1.265417456626892], [-0.45794516801834106, -1.0012555122375488], [-0.47560417652130127, -0.9715641736984253], [-0.3416993021965027, -1.2398135662078857], [-0.39910027384757996, -1.1114648580551147], [-0.22455962002277374, -1.6037936210632324], [-0.6434305906295776, -0.7454654574394226], [-0.06835421174764633, -2.7170350551605225], [-0.17946523427963257, -1.8061645030975342], [-0.5842801332473755, -0.8153308033943176], [-1.232939600944519, -0.3445129096508026], [-0.4429531395435333, -1.0276058912277222], [-0.053073715418577194, -2.9624922275543213], [-0.23971547186374664, -1.5457671880722046], [-0.5727553963661194, -0.8300427794456482], [-0.29872214794158936, -1.3538869619369507], [-0.08715301752090454, -2.4833502769470215], [-1.6528855562210083, -0.21257035434246063], [-0.18251390755176544, -1.7907986640930176], [-0.3592345714569092, -1.1980257034301758], [-1.2376484870910645, -0.3425825834274292], [-0.02985791116952896, -3.5261974334716797], [-0.1327490359544754, -2.0849356651306152], [-0.10427196323871613, -2.312436103820801], [-0.4609176516532898, -0.9961584806442261], [-1.6653457880020142, -0.20964166522026062], [-0.3058438003063202, -1.3337082862854004], [-0.005282610189169645, -5.245970726013184], [-0.08625974506139755, -2.4932126998901367], [-0.0846312940120697, -2.5114686489105225], [-0.04883984476327896, -3.0435292720794678], [-0.05519438162446022, -2.924363613128662], [-0.4354613423347473, -1.0411913394927979], [-0.47190582752227783, -0.9776668548583984], [-0.22825303673744202, -1.5892571210861206], [-0.08660339564085007, -2.489405870437622], [-0.41473889350891113, -1.0803186893463135], [-0.0663943886756897, -2.7451558113098145], [-0.45073041319847107, -1.0138005018234253], [-0.3693390488624573, -1.175032377243042], [-0.21717743575572968, -1.633664846420288], [-0.25053825974464417, -1.5067986249923706], [-0.08869937807321548, -2.466524124145508], [-0.5281450748443604, -0.8908611536026001], [-0.30977851152420044, -1.322791576385498], [-0.0030920335557311773, -5.780458450317383], [-0.6732493042945862, -0.7134491801261902], [-0.06353548169136047, -2.7877559661865234], [-1.8731623888015747, -0.16680698096752167], [-0.18768195807933807, -1.7653803825378418], [-0.9817348718643188, -0.469460666179657], [-0.19849827885627747, -1.7145826816558838], [-0.3503802716732025, -1.2188163995742798], [-0.0040374440141022205, -5.514167308807373], [-0.7449180483818054, -0.6439250707626343], [-0.21534699201583862, -1.6412465572357178], [-0.6840687394142151, -0.7023087739944458], [-0.5074836015701294, -0.9213249087333679], [-0.07183144241571426, -2.6691339015960693], [-0.1455904096364975, -1.9988703727722168], [-0.19521524012088776, -1.729672908782959], [-0.19939880073070526, -1.71049165725708], [-0.06492440402507782, -2.766817808151245], [-0.05218363553285599, -2.978963851928711], [-0.2862209379673004, -1.3906906843185425], [-0.539157509803772, -0.8752433657646179], [-0.6533123254776001, -0.7346349954605103], [-1.5263522863388062, -0.24504026770591736], [-1.450662612915039, -0.2671149671077728], [-0.23185697197914124, -1.5753244161605835], [-0.45070040225982666, -1.0138530731201172], [-0.48574092984199524, -0.9551386833190918], [-0.13563655316829681, -2.0648281574249268], [-0.0942474827170372, -2.4085850715637207], [-0.03669081628322601, -3.3235175609588623], [-1.1458665132522583, -0.38264986872673035], [-0.1078685000538826, -2.2802915573120117], [-0.29905518889427185, -1.352931022644043], [-0.12261684983968735, -2.1593732833862305], [-0.08156562596559525, -2.546853542327881], [-0.31994831562042236, -1.2953083515167236], [-3.41807222366333, -0.0333247072994709], [-0.06339652836322784, -2.789877414703369], [-0.3067602515220642, -1.331151008605957], [-0.4962459206581116, -0.9385668039321899], [-0.4893054664134979, -0.9494650363922119], [-0.9614944458007812, -0.4817865490913391], [-0.13561293482780457, -2.064990520477295], [-0.07204820960760117, -2.6662282943725586], [-0.08799527585506439, -2.4741477966308594], [-0.5771876573562622, -0.8243390321731567], [-0.1654822677373886, -1.8804914951324463], [-0.6145642399787903, -0.7784361839294434], [-0.27833107113838196, -1.4148838520050049], [-0.4163172245025635, -1.0772550106048584], [-0.15793035924434662, -1.9235270023345947], [-0.10855917632579803, -2.2742481231689453], [-0.01047541294246912, -4.563961505889893], [-0.1777188777923584, -1.815096139907837], [-0.6246605515480042, -0.7666714191436768], [-0.39574024081230164, -1.1183505058288574], [-0.19751504063606262, -1.7190732955932617], [-0.14444561302661896, -2.0062060356140137], [-1.7117723226547241, -0.19911643862724304], [-1.6374319791793823, -0.21626579761505127], [-0.3460511565208435, -1.229209542274475], [-0.5573118329048157, -0.8503780364990234], [-0.08375012874603271, -2.521501064300537], [-0.10632386803627014, -2.2939560413360596], [-0.322340190410614, -1.2889924049377441], [-0.231899231672287, -1.5751625299453735], [-0.1719147115945816, -1.8454831838607788], [-0.714073896408081, -0.6726493835449219], [-0.27710530161857605, -1.418712854385376], [-0.0506676621735096, -3.0076942443847656], [-0.0932396724820137, -2.418840169906616], [-0.38766536116600037, -1.1351914405822754], [-0.5751861333847046, -0.8269076347351074], [-0.2655189335346222, -1.4558926820755005], [-0.12784846127033234, -2.1201529502868652], [-0.644225001335144, -0.7445864677429199], [-0.39737439155578613, -1.1149928569793701], [-0.2617591917514801, -1.4683564901351929], [-0.08895396441221237, -2.4637842178344727], [-0.04022851958870888, -3.2332265377044678], [-0.991040050983429, -0.4639267921447754], [-0.07944197207689285, -2.572186231613159], [-0.021328024566173553, -3.858377456665039], [-0.2762092053890228, -1.4215244054794312], [-0.09652712941169739, -2.3858063220977783], [-0.03882525861263275, -3.2680351734161377], [-0.1841544508934021, -1.7826447486877441], [-0.08023958653211594, -2.5625903606414795], [-0.0584280863404274, -2.8690311908721924], [-0.021447978913784027, -3.852829694747925], [-0.08112417906522751, -2.552062749862671], [-0.0066072335466742516, -5.0228986740112305], [-0.19670741260051727, -1.722779631614685], [-0.017345750704407692, -4.063065528869629], [-0.01932051219046116, -3.9562301635742188], [-0.17895562946796417, -1.8087611198425293], [-0.283062607049942, -1.4002821445465088], [-0.18769973516464233, -1.765293836593628], [-0.13136929273605347, -2.0947089195251465], [-0.03214874118566513, -3.453413963317871], [-0.3178028464317322, -1.301020860671997], [-0.04676457494497299, -3.0859215259552], [-0.3815765380859375, -1.1481727361679077], [-0.32795077562332153, -1.2743899822235107], [-0.001646116841584444, -6.410128116607666], [-0.4934048056602478, -0.9430044889450073], [-0.07009994983673096, -2.6926774978637695], [-0.03687673062086105, -3.318557024002075], [-0.054921913892030716, -2.9291775226593018], [-0.06135531887412071, -2.821593999862671], [-0.36008453369140625, -1.1960620880126953], [-0.5343459844589233, -0.8820159435272217], [-0.5604619979858398, -0.8461705446243286], [-0.9784694314002991, -0.4714221954345703], [-0.3302183151245117, -1.268571138381958], [-0.09689832478761673, -2.3821511268615723], [-0.04811800643801689, -3.058060646057129], [-0.3394126892089844, -1.245449423789978], [-0.45155471563339233, -1.0123546123504639], [-0.2119605541229248, -1.6554641723632812], [-0.025307171046733856, -3.6892964839935303], [-0.22286589443683624, -1.6105492115020752], [-0.8126575350761414, -0.5864070653915405], [-0.21392108500003815, -1.6472026109695435], [-0.2810456156730652, -1.4064719676971436], [-0.42162013053894043, -1.067064642906189], [-0.413956880569458, -1.0818419456481934], [-0.24947579205036163, -1.5105392932891846], [-1.3635801076889038, -0.29536953568458557], [-0.31370148062705994, -1.3120673894882202], [-0.8917950391769409, -0.5274960398674011], [-0.30132395029067993, -1.3464508056640625], [-0.344767302274704, -1.2323213815689087], [-0.009213902987539768, -4.6916422843933105], [-0.03614033758640289, -3.338362216949463], [-0.3414720296859741, -1.2403719425201416], [-0.9330438375473022, -0.4998108148574829], [-0.32291606068611145, -1.2874799966812134], [-1.740087628364563, -0.19298423826694489], [-0.0023612494114786386, -6.049751281738281], [-0.23479190468788147, -1.5641555786132812], [-0.3282774090766907, -1.2735488414764404], [-0.20154139399528503, -1.7008394002914429], [-0.03927408903837204, -3.256763219833374], [-0.15769580006599426, -1.9248995780944824], [-0.3899952471256256, -1.1302889585494995], [-0.21894057095050812, -1.6264289617538452], [-0.04005582258105278, -3.237440824508667], [-0.011786110699176788, -4.446720123291016], [-0.1466759443283081, -1.9919716119766235], [-0.4538431763648987, -1.0083577632904053], [-0.32434117794036865, -1.2837504148483276], [-0.01507661398500204, -4.2021379470825195], [-1.0921846628189087, -0.4086945950984955], [-0.21512503921985626, -1.6421709060668945], [-0.1058698371052742, -2.2980129718780518], [-0.13170447945594788, -2.0923244953155518], [-0.18554845452308655, -1.775779128074646], [-0.06630157679319382, -2.746509552001953], [-0.005449796095490456, -5.214905261993408], [-0.27335885167121887, -1.4305377006530762], [-0.002690982772037387, -5.919190883636475], [-0.19567006826400757, -1.7275657653808594], [-0.09240790456533432, -2.4273905754089355], [-0.018657777458429337, -3.9908032417297363], [-0.19968020915985107, -1.7092176675796509], [-2.826963424682617, -0.06101655960083008], [-0.04685410484671593, -3.0840530395507812], [-0.02178652584552765, -3.8373382091522217], [-0.02001926489174366, -3.9210550785064697], [-0.21847444772720337, -1.6283354759216309], [-0.018155580386519432, -4.017841815948486], [-0.12816469371318817, -2.1178369522094727], [-0.9623411297798157, -0.48126280307769775], [-0.613593339920044, -0.7795810699462891], [-1.082183837890625, -0.41378161311149597], [-0.4932968020439148, -0.9431740045547485], [-0.42666664719581604, -1.0575119256973267], [-0.21552950143814087, -1.6404876708984375], [-0.022749044001102448, -3.794583320617676], [-0.13196171820163727, -2.090498447418213], [-0.11359155178070068, -2.2314043045043945], [-0.07842440903186798, -2.584575653076172], [-0.06824721395969391, -2.71854829788208], [-0.2140103131532669, -1.646828532218933], [-0.04910092428326607, -3.0383267402648926], [-0.8714463710784912, -0.5418795347213745], [-0.43069466948509216, -1.0499860048294067], [-0.10669230669736862, -2.2906785011291504], [-0.4622594118118286, -0.9938710927963257], [-0.2505970895290375, -1.5065923929214478], [-0.1452261358499527, -2.001197576522827], [-0.23781055212020874, -1.5528309345245361], [-0.14680801331996918, -1.991135835647583], [-0.6288972496986389, -0.7618104219436646], [-0.8453035950660706, -0.5611141324043274], [-0.2265516072511673, -1.5959206819534302], [-0.25619199872016907, -1.4871907234191895], [-0.19092871248722076, -1.7498011589050293], [-0.1632765233516693, -1.8928378820419312], [-0.04631955176591873, -3.0952601432800293], [-0.0014329414116218686, -6.548770904541016], [-1.4017704725265503, -0.28257620334625244], [-0.6784921884536743, -0.7080200910568237], [-0.11242015659809113, -2.2411952018737793], [-0.10888980329036713, -2.271369695663452], [-0.2715988755226135, -1.4361565113067627], [-0.01600724831223488, -4.142704963684082], [-0.26115867495536804, -1.470366358757019], [-0.3507381081581116, -1.2179641723632812], [-1.6169703006744385, -0.22126924991607666], [-0.2522927522659302, -1.5006605386734009], [-0.1654655933380127, -1.880584478378296], [-0.3434447646141052, -1.235541582107544], [-0.01641753688454628, -4.117602348327637], [-0.02746300958096981, -3.6086153984069824], [-0.2303423285484314, -1.5811500549316406], [-0.3261016607284546, -1.2791699171066284], [-0.6986691951751709, -0.6876554489135742], [-0.06341230869293213, -2.78963565826416], [-0.5370050668716431, -0.8782634735107422], [-0.052812088280916214, -2.9673056602478027], [-1.2083226442337036, -0.3548164665699005], [-0.5089260339736938, -0.9191468954086304], [-0.12501239776611328, -2.141197919845581], [-0.34838324785232544, -1.2235918045043945], [-0.1553482860326767, -1.9387545585632324], [-0.08018501102924347, -2.5632431507110596], [-0.30964207649230957, -1.3231674432754517], [-0.025858532637357712, -3.668016195297241], [-0.0838378295302391, -2.5204970836639404], [-0.13156956434249878, -2.09328293800354], [-0.0371447391808033, -3.3114495277404785], [-0.009605263359844685, -4.650237083435059], [-0.31454044580459595, -1.3097938299179077], [-0.3744056820869446, -1.1637842655181885], [-1.2453206777572632, -0.3394647538661957], [-0.1779746413230896, -1.8137824535369873], [-0.9006438255310059, -0.5213946104049683], [-0.010379028506577015, -4.573156833648682], [-0.08938761055469513, -2.4591338634490967], [-0.13633963465690613, -2.0600013732910156], [-0.2808728814125061, -1.4070043563842773], [-0.005762867629528046, -5.159194469451904], [-0.07943712174892426, -2.5722453594207764], [-0.44730159640312195, -1.0198501348495483], [-0.022535424679517746, -3.803915500640869], [-0.11395636200904846, -2.228377342224121], [-0.023952985182404518, -3.7436158657073975], [-0.26911869645118713, -1.4441460371017456], [-0.05964432656764984, -2.849029541015625], [-0.2911045551300049, -1.3760966062545776], [-0.050037406384944916, -3.019899368286133], [-0.10360969603061676, -2.3184826374053955], [-0.08357393741607666, -2.523519992828369], [-0.14706788957118988, -1.9894942045211792], [-0.2677527964115143, -1.4485820531845093], [-0.031089037656784058, -3.4864041805267334], [-0.4201829731464386, -1.0698108673095703], [-0.07628168910741806, -2.6112210750579834], [-0.3038085997104645, -1.3394187688827515], [-0.3480275869369507, -1.2244457006454468], [-0.02990095131099224, -3.524779796600342], [-0.49424684047698975, -0.9416858553886414], [-0.42331138253211975, -1.0638476610183716], [-0.3196672797203064, -1.2960541248321533], [-0.10100138932466507, -2.3426969051361084], [-0.4651760458946228, -0.98892742395401], [-0.12646563351154327, -2.1303510665893555], [-0.029978811740875244, -3.5222182273864746], [-0.06706537306308746, -2.7354323863983154], [-0.18762533366680145, -1.765654444694519], [-0.702960729598999, -0.6834290027618408], [-0.179030179977417, -1.8083808422088623], [-0.34251198172569275, -1.237821340560913], [-2.275630474090576, -0.10840077698230743], [-0.07292666286230087, -2.654542922973633], [-0.4915388226509094, -0.9459368586540222], [-0.28575557470321655, -1.3920962810516357], [-0.23456895351409912, -1.5649985074996948], [-0.003384815761819482, -5.690141201019287], [-0.07155059278011322, -2.672913074493408], [-0.06902287900447845, -2.7076308727264404], [-0.06379006803035736, -2.7838833332061768], [-3.3552582263946533, -0.03552386537194252], [-0.020914142951369286, -3.8777689933776855], [-0.237184539437294, -1.5551660060882568], [-0.21446168422698975, -1.6449395418167114], [-0.7778342962265015, -0.615075409412384], [-1.7959381341934204, -0.18148787319660187], [-0.1988155096769333, -1.7131394147872925], [-0.3640996217727661, -1.1868599653244019], [-0.047889627516269684, -3.0627059936523438], [-0.12805142998695374, -2.118666410446167], [-1.3467345237731934, -0.3012242913246155], [-0.17735745012760162, -1.8169565200805664], [-0.14065559208393097, -2.030944585800171], [-0.14474579691886902, -2.0042760372161865], [-0.007247348316013813, -4.9307355880737305], [-0.16239838302135468, -1.8978030681610107], [-0.055649906396865845, -2.916369915008545], [-0.233283132314682, -1.5698777437210083], [-0.4142075777053833, -1.0813533067703247], [-0.022456049919128418, -3.807403087615967], [-0.04082527384161949, -3.218796730041504], [-0.02908402308821678, -3.5520718097686768], [-0.034536950290203094, -3.3829445838928223], [-0.5192961096763611, -0.9037179946899414], [-0.5746763944625854, -0.827563464641571], [-0.18349701166152954, -1.785902738571167], [-0.22606229782104492, -1.597847580909729], [-0.3987847566604614, -1.1121083498001099], [-0.2610703408718109, -1.470662236213684], [-0.008157862350344658, -4.812847137451172], [-0.012718279846012592, -4.371063232421875], [-0.48743927478790283, -0.952428936958313], [-1.6494429111480713, -0.21338751912117004], [-0.12609505653381348, -2.1331045627593994], [-0.3431713581085205, -1.2362087965011597], [-2.0730319023132324, -0.13445039093494415], [-0.047946784645318985, -3.0615408420562744], [-0.12421318143606186, -2.1472201347351074], [-0.8542861342430115, -0.5544065237045288], [-0.0779467225074768, -2.5904500484466553], [-0.536673367023468, -0.8787301778793335], [-2.209873914718628, -0.1162131130695343], [-0.4066612422466278, -1.0962241888046265], [-0.20508074760437012, -1.6851400136947632], [-1.2029664516448975, -0.3571065366268158], [-0.09480147808790207, -2.402996063232422], [-0.055725112557411194, -2.9150569438934326], [-0.034407153725624084, -3.3866448402404785], [-0.2578774094581604, -1.481440544128418], [-0.02719123288989067, -3.6184260845184326], [-0.06786835193634033, -2.7239274978637695], [-0.05938620865345001, -2.8532397747039795], [-0.5022569894790649, -0.9292829036712646], [-0.5068397521972656, -0.9222995638847351], [-0.2969402074813843, -1.3590235710144043], [-0.6035168170928955, -0.7916091680526733], [-0.07452281564474106, -2.6336796283721924], [-0.022671665996313095, -3.7979540824890137], [-0.43925607204437256, -1.0342741012573242], [-0.3706793189048767, -1.1720390319824219], [-0.0701659619808197, -2.69176983833313], [-0.7402610182762146, -0.6481536626815796], [-0.28486403822898865, -1.3947962522506714], [-0.048197757452726364, -3.0564444065093994], [-0.10572206228971481, -2.299337148666382], [-0.09228628128767014, -2.4286484718322754], [-0.2068764567375183, -1.6772890090942383], [-0.35389602184295654, -1.2104872465133667], [-0.14634451270103455, -1.9940718412399292], [-0.863928496837616, -0.5473217964172363], [-0.9095912575721741, -0.5153169631958008], [-0.04554053395986557, -3.11183762550354], [-0.16327185928821564, -1.8928638696670532], [-0.6580364108085632, -0.729535698890686], [-0.21271954476833344, -1.6522555351257324], [-0.6539806127548218, -0.7339104413986206], [-0.31476208567619324, -1.3091944456100464], [-2.5001773834228516, -0.08563457429409027], [-0.023802950978279114, -3.7498230934143066], [-0.01635526493191719, -4.121371746063232], [-0.0073043908923864365, -4.922924995422363], [-0.2847841680049896, -1.3950389623641968], [-0.3960082530975342, -1.1177985668182373], [-0.13668428361415863, -2.057645559310913], [-0.12349909543991089, -2.152635097503662], [-0.2689494490623474, -1.4446942806243896], [-0.22168079018592834, -1.6153103113174438], [-0.7402517795562744, -0.6481620073318481], [-0.041749414056539536, -3.196871757507324], [-0.08796961605548859, -2.47442626953125], [-0.2498345524072647, -1.5092742443084717], [-0.1931602656841278, -1.7392609119415283], [-0.26653391122817993, -1.4525623321533203], [-0.146255224943161, -1.994638442993164], [-0.09784375876188278, -2.372906446456909], [-0.3437759280204773, -1.2347339391708374], [-0.01738101616501808, -4.061053276062012], [-0.18196986615657806, -1.7935199737548828], [-0.15651045739650726, -1.9318674802780151], [-0.12645995616912842, -2.1303935050964355], [-0.17514394223690033, -1.8284411430358887], [-0.3545483350753784, -1.2089524269104004], [-0.09128084033727646, -2.4391071796417236], [-0.0730891153216362, -2.652397394180298], [-0.13154448568820953, -2.093461751937866], [-0.5879634618759155, -0.8107092380523682], [-0.3482609689235687, -1.2238852977752686], [-0.5331119298934937, -0.8837659358978271], [-0.09236802160739899, -2.4278032779693604], [-0.18413738906383514, -1.7827293872833252], [-0.0244008619338274, -3.7253143787384033], [-0.02248099446296692, -3.806306838989258], [-0.04413182660937309, -3.142559051513672], [-0.09981870651245117, -2.3538942337036133], [-0.49354586005210876, -0.9427835941314697], [-0.041054703295230865, -3.2133076190948486], [-0.9769073724746704, -0.4723640978336334], [-0.05051829293370247, -3.010573148727417], [-0.527702808380127, -0.8914971947669983], [-0.8691262602806091, -0.5435515642166138], [-0.017666950821876526, -4.044878959655762], [-0.1466825306415558, -1.991929292678833], [-0.4772701859474182, -0.968834638595581], [-0.06468317657709122, -2.7704219818115234], [-0.018330810591578484, -4.008325576782227], [-0.05302872136235237, -2.9633190631866455], [-1.313979148864746, -0.3129979074001312], [-0.07121161371469498, -2.6774938106536865], [-0.043648310005664825, -3.1533355712890625], [-0.8467637896537781, -0.5600165128707886], [-0.11913951486349106, -2.1864383220672607], [-0.11519746482372284, -2.2181529998779297], [-0.09535582363605499, -2.3974392414093018], [-0.7862246632575989, -0.6080003380775452], [-0.09660603106021881, -2.385028123855591], [-0.0753646120429039, -2.6228628158569336], [-0.3467038869857788, -1.2276326417922974], [-0.020750107243657112, -3.885561943054199], [-0.05098230019211769, -3.0016586780548096], [-0.12532879412174225, -2.138824224472046], [-0.24156780540943146, -1.5389587879180908], [-0.0837346762418747, -2.5216777324676514], [-0.1455904096364975, -1.9988703727722168], [-0.5302373170852661, -0.8878617286682129], [-0.014629240147769451, -4.2320380210876465], [-0.14022734761238098, -2.0337846279144287], [-0.08821140229701996, -2.4718000888824463], [-0.33617934584617615, -1.253495693206787], [-0.41631433367729187, -1.0772607326507568], [-0.4103638827800751, -1.088886022567749], [-0.7788164615631104, -0.614241361618042], [-0.002898778999224305, -5.844910621643066], [-0.20676837861537933, -1.6777592897415161], [-0.04791610315442085, -3.062167167663574], [-0.1872403770685196, -1.7675220966339111], [-0.11436942219734192, -2.224961042404175], [-0.4429485499858856, -1.0276139974594116], [-0.11820118874311447, -2.193885326385498], [-0.18220487236976624, -1.792343258857727], [-0.26073744893074036, -1.4717788696289062], [-0.07306728512048721, -2.6526849269866943], [-0.46427902579307556, -0.9904437065124512], [-0.188354030251503, -1.7621309757232666], [-0.020579038187861443, -3.893754005432129], [-1.1515127420425415, -0.38002869486808777], [-0.707303524017334, -0.6791884303092957], [-0.2690891623497009, -1.4442417621612549], [-0.0373605415225029, -3.30576229095459], [-0.07315704226493835, -2.6515021324157715], [-0.369782418012619, -1.1740409135818481], [-0.02661146968603134, -3.6396875381469727], [-0.1747717559337616, -1.830387830734253], [-0.11549977213144302, -2.2156803607940674], [-0.0514407679438591, -2.9929351806640625], [-0.1922122985124588, -1.7437222003936768], [-0.3401574194431305, -1.2436089515686035], [-0.3349953293800354, -1.256464958190918], [-0.010077784769237041, -4.602455139160156], [-0.5370717644691467, -0.8781696557998657], [-0.07309698313474655, -2.652294397354126], [-0.27782347798347473, -1.4164671897888184], [-0.3576401472091675, -1.2017241716384888], [-0.14939096570014954, -1.9749538898468018], [-0.6014357805252075, -0.7941268086433411], [-0.0830458253622055, -2.529597759246826], [-1.0447800159454346, -0.43350842595100403], [-0.2157772034406662, -1.639458417892456], [-0.21285338699817657, -1.651691198348999], [-0.020455708727240562, -3.899705648422241], [-0.010430820286273956, -4.568202972412109], [-0.1455904096364975, -1.9988703727722168], [-0.8865212202072144, -0.5311759114265442], [-0.3204689919948578, -1.293928861618042], [-0.1592848300933838, -1.915647029876709], [-1.40104079246521, -0.28281450271606445], [-0.33358797430992126, -1.2600103616714478], [-0.42242681980133057, -1.0655282735824585], [-0.11410260945558548, -2.227165937423706], [-0.05696997791528702, -2.893580198287964], [-1.2766218185424805, -0.32708579301834106], [-1.0035369396209717, -0.456622451543808], [-0.6080819368362427, -0.7861269116401672], [-0.1255721151828766, -2.1370041370391846], [-0.015788545832037926, -4.156352996826172], [-1.3763943910598755, -0.2910040318965912], [-0.23669081926345825, -1.5570125579833984], [-0.019051892682909966, -3.9700965881347656], [-1.5911402702331543, -0.22777074575424194], [-0.6931148171424866, -0.6931795477867126], [-0.5397040843963623, -0.8744789958000183], [-0.5068581700325012, -0.9222714900970459], [-1.230920433998108, -0.34534457325935364], [-0.09133371710777283, -2.438554286956787], [-0.08165857940912247, -2.5457603931427], [-0.32860442996025085, -1.2727078199386597], [-0.005822839215397835, -5.148886203765869], [-0.04359615966677666, -3.1545047760009766], [-0.03821732476353645, -3.283512830734253], [-0.4286970794200897, -1.053707480430603], [-0.25164175033569336, -1.5029324293136597], [-0.05964432656764984, -2.849029541015625], [-0.4517996907234192, -1.011925458908081], [-0.01305167656391859, -4.345355033874512], [-0.1912909895181656, -1.7480806112289429], [-0.07225239276885986, -2.6634979248046875], [-0.38952282071113586, -1.1312803030014038], [-0.2494223713874817, -1.510727882385254], [-0.22602635622024536, -1.5979890823364258], [-0.006760226096957922, -5.0000786781311035], [-0.2896845042705536, -1.3803110122680664], [-0.02325557917356491, -3.7728140354156494], [-0.10364795476198196, -2.318131685256958], [-0.06252287328243256, -2.8033220767974854], [-0.435245156288147, -1.0415875911712646], [-0.7906926274299622, -0.6042768955230713], [-0.1298949122428894, -2.105274200439453], [-0.584149956703186, -0.81549471616745], [-0.4917292594909668, -0.9456368088722229], [-0.14268769323825836, -2.0175929069519043], [-0.12416096031665802, -2.1476147174835205], [-0.045333098620176315, -3.116299867630005], [-0.7765456438064575, -0.6161717772483826], [-0.8019087910652161, -0.5950628519058228], [-0.06006493791937828, -2.8422114849090576], [-0.14390842616558075, -2.009669542312622], [-0.6558016538619995, -0.7319417595863342], [-0.574023425579071, -0.8284049034118652], [-0.20127171277999878, -1.7020483016967773], [-0.4371173679828644, -1.0381635427474976], [-0.02223782241344452, -3.817060708999634], [-0.05231634899973869, -2.9764912128448486], [-0.47455060482025146, -0.9732967615127563], [-0.030301183462142944, -3.5116801261901855], [-0.21955320239067078, -1.623929738998413], [-0.1420103758573532, -2.022020101547241], [-0.08202182501554489, -2.5415008068084717], [-0.5788170099258423, -0.8222565650939941], [-0.29292482137680054, -1.3707292079925537], [-0.16513578593730927, -1.882419466972351], [-0.557126522064209, -0.850626528263092], [-0.32787811756134033, -1.2745771408081055], [-0.09178309142589569, -2.433868169784546], [-0.33598580956459045, -1.253980040550232], [-0.022814298048615456, -3.791752338409424], [-0.09783068299293518, -2.3730340003967285], [-0.5653422474861145, -0.8397133350372314], [-0.7343974709510803, -0.6535312533378601], [-0.02168702706694603, -3.8418660163879395], [-0.9955266118049622, -0.46128785610198975], [-0.13312079012393951, -2.082320213317871], [-0.19063575565814972, -1.7511950731277466], [-0.14653077721595764, -1.992890477180481], [-2.594900608062744, -0.07758684456348419], [-0.033216316252946854, -3.4212758541107178], [-0.4105878174304962, -1.0884448289871216], [-0.4027741849422455, -1.104015827178955], [-0.07974449545145035, -2.568535089492798], [-0.16408367455005646, -1.8882992267608643], [-0.8477566838264465, -0.5592716932296753], [-0.11162659525871277, -2.2478904724121094], [-0.5388123989105225, -0.875726580619812], [-0.020576585084199905, -3.8938722610473633], [-0.5182549953460693, -0.9052492380142212], [-0.1455904096364975, -1.9988703727722168], [-0.19323809444904327, -1.7388958930969238], [-0.3534071147441864, -1.2116395235061646], [-0.15182673931121826, -1.9599685668945312], [-0.3823414146900177, -1.1465283632278442], [-0.26289382576942444, -1.4645737409591675], [-0.05316256731748581, -2.9608652591705322], [-0.6583853960037231, -0.7291610836982727], [-0.23195603489875793, -1.5749443769454956], [-0.48427167534828186, -0.9574923515319824], [-0.3824290931224823, -1.146340250968933], [-0.24843303859233856, -1.5142279863357544], [-0.060237690806388855, -2.839423894882202], [-0.3441579043865204, -1.233803391456604], [-0.1547679305076599, -1.9422144889831543], [-0.6927226781845093, -0.6935718655586243], [-0.2775188684463501, -1.4174188375473022], [-0.23525933921337128, -1.5623915195465088], [-0.35425734519958496, -1.2096366882324219], [-0.7313047051429749, -0.6563922762870789], [-0.26106271147727966, -1.470687985420227], [-0.17008882761001587, -1.8552734851837158], [-0.2229171246290207, -1.6103439331054688], [-3.7068769931793213, -0.02486051432788372], [-0.098148874938488, -2.3699426651000977], [-0.2442280352115631, -1.529282808303833], [-0.11471598595380783, -2.2221059799194336], [-1.2007546424865723, -0.3580573797225952], [-0.24392040073871613, -1.5303955078125], [-0.0848810076713562, -2.5086448192596436], [-0.07849285006523132, -2.5837368965148926], [-0.0951826423406601, -2.3991711139678955], [-0.019445735961198807, -3.9498326778411865], [-0.49502402544021606, -0.9404714703559875], [-0.11428382247686386, -2.225667953491211], [-0.23419919610023499, -1.5663985013961792], [-0.055530715733766556, -2.9184563159942627], [-0.04055126756429672, -3.225396156311035], [-0.2903037369251251, -1.3784703016281128], [-0.034570690244436264, -3.381983757019043], [-2.0732979774475098, -0.13441213965415955], [-0.7957879304885864, -0.6000678539276123], [-2.5301475524902344, -0.08299832046031952], [-0.3476414978504181, -1.2253737449645996], [-0.14851853251457214, -1.980385661125183], [-0.2237413227558136, -1.6070501804351807], [-0.18329179286956787, -1.7869222164154053], [-0.11528223752975464, -2.217458963394165], [-0.08226537704467773, -2.538656234741211], [-0.10363634675741196, -2.3182382583618164], [-1.9880218505859375, -0.14730125665664673], [-0.023788167163729668, -3.7504384517669678], [-0.5646103620529175, -0.84067702293396], [-0.9027854204177856, -0.5199315547943115], [-0.030334491282701492, -3.5106000900268555], [-2.2191858291625977, -0.11507146060466766], [-0.16277803480625153, -1.8956528902053833], [-0.16651837527751923, -1.8747535943984985], [-0.1286557912826538, -2.114253044128418], [-0.2602705657482147, -1.4733480215072632], [-0.8511780500411987, -0.5567154884338379], [-0.5947696566581726, -0.8022695183753967], [-0.02480446547269821, -3.7091064453125], [-0.34103915095329285, -1.2414360046386719], [-0.08530821651220322, -2.503835678100586], [-0.1892835646867752, -1.7576582431793213], [-0.3319195806980133, -1.2642359733581543], [-0.2776166796684265, -1.4171130657196045], [-0.24477021396160126, -1.5273252725601196], [-0.5714786648750305, -0.8316965103149414], [-0.04364945366978645, -3.1533100605010986], [-0.10698937624692917, -2.288043975830078], [-0.5039526224136353, -0.9266896843910217], [-1.206950306892395, -0.3554016053676605], [-0.1818002164363861, -1.7943700551986694], [-0.13539181649684906, -2.066514253616333], [-0.5507620573043823, -0.8592261075973511], [-0.13249292969703674, -2.0867409706115723], [-0.021225329488515854, -3.8631551265716553], [-0.22413717210292816, -1.6054731607437134], [-0.20161768794059753, -1.7004976272583008], [-0.16512052714824677, -1.8825041055679321], [-1.0237135887145996, -0.4451289176940918], [-0.1862461119890213, -1.7723643779754639], [-2.5196430683135986, -0.08391259610652924], [-0.07903890311717987, -2.577073812484741], [-0.21949970722198486, -1.624147653579712], [-0.25817176699638367, -1.480440616607666], [-0.2570253908634186, -1.4843422174453735], [-0.216580331325531, -1.6361303329467773], [-0.4159817397594452, -1.077905297279358], [-0.5601648688316345, -0.8465662002563477], [-0.0954529196023941, -2.3964688777923584], [-0.08274012804031372, -2.533134698867798], [-0.0790531113743782, -2.57690167427063], [-0.04470163583755493, -3.1300132274627686], [-0.25335538387298584, -1.4969667196273804], [-0.35274678468704224, -1.2131989002227783], [-0.6602236032485962, -0.727191686630249], [-0.26041242480278015, -1.4728707075119019], [-0.3382308781147003, -1.2483798265457153], [-0.6650202870368958, -0.7220881581306458], [-3.1538305282592773, -0.04362628608942032], [-0.6887324452400208, -0.6975815296173096], [-0.25367510318756104, -1.4958585500717163], [-1.2684955596923828, -0.33024778962135315], [-0.49799656867980957, -0.9358484148979187], [-0.355361670255661, -1.207044005393982], [-0.13956370949745178, -2.0382046699523926], [-0.14031179249286652, -2.0332236289978027], [-0.09733989834785461, -2.377821683883667], [-3.7812623977661133, -0.02305767871439457], [-0.0018598416354507208, -6.288176536560059], [-0.030119827017188072, -3.517594814300537], [-0.2896684408187866, -1.3803589344024658], [-0.10630778968334198, -2.2940993309020996], [-0.06827238202095032, -2.718191385269165], [-0.20679910480976105, -1.6776256561279297], [-0.06486965715885162, -2.767634153366089], [-3.7100706100463867, -0.0247802771627903], [-0.6348451375961304, -0.7550600171089172], [-0.12507309019565582, -2.1407415866851807], [-0.11818890273571014, -2.193983554840088], [-0.06511295586824417, -2.764012336730957], [-1.4150810241699219, -0.2782678008079529], [-0.1747838705778122, -1.8303245306015015], [-0.14324887096881866, -2.0139410495758057], [-0.2491077035665512, -1.511839509010315], [-0.3070017993450165, -1.3304786682128906], [-0.4221644699573517, -1.0660275220870972], [-0.089264415204525, -2.4604525566101074], [-0.5740012526512146, -0.828433632850647], [-0.11498910933732986, -2.2198610305786133], [-0.08137344568967819, -2.549117088317871], [-0.06789074093103409, -2.72360897064209], [-0.4660266041755676, -0.987493097782135], [-0.2867666780948639, -1.3890455961227417], [-0.5108790397644043, -0.9162107706069946], [-0.0021136105060577393, -6.1604390144348145], [-0.10073411464691162, -2.345215320587158], [-1.5700023174285889, -0.23325027525424957], [-0.08609548211097717, -2.4950368404388428], [-0.03531123325228691, -3.3611583709716797], [-0.02709934674203396, -3.621764898300171], [-0.620596706867218, -0.7713760137557983], [-0.002649489790201187, -5.934734344482422], [-0.0644335150718689, -2.774165630340576], [-0.1384408324956894, -2.045734167098999], [-0.03708546981215477, -3.313016891479492], [-0.15743134915828705, -1.9264487028121948], [-0.03919729217886925, -3.2586817741394043], [-0.13751401007175446, -2.0519983768463135], [-0.04919455200433731, -3.036468029022217], [-0.21119289100170135, -1.658721923828125], [-0.08370090276002884, -2.522064685821533], [-0.1780402809381485, -1.8134453296661377], [-0.1508004069328308, -1.9662511348724365], [-0.154386967420578, -1.9444935321807861], [-0.02505294419825077, -3.6992640495300293], [-0.297579288482666, -1.3571772575378418], [-0.23579737544059753, -1.5603654384613037], [-0.6916182637214661, -0.6946784257888794], [-0.6150471568107605, -0.7778675556182861], [-0.1830195188522339, -1.78827702999115], [-0.42163458466529846, -1.0670371055603027], [-0.11427074670791626, -2.225775957107544], [-0.22243347764015198, -1.6122833490371704], [-0.11058887094259262, -2.2567203044891357], [-0.31052306294441223, -1.3207440376281738], [-0.5458554029464722, -0.8659446835517883], [-0.23214943706989288, -1.5742043256759644], [-0.1452956199645996, -2.000753164291382], [-0.1060718446969986, -2.296205997467041], [-0.06467859447002411, -2.77048921585083], [-0.022533560171723366, -3.803995370864868], [-0.008357314392924309, -4.788787841796875], [-0.0372050404548645, -3.3098561763763428], [-0.9342955350875854, -0.49900007247924805], [-0.14375139772891998, -2.0106847286224365], [-0.014903749339282513, -4.213587760925293], [-0.042627692222595215, -3.1764883995056152], [-1.0189826488494873, -0.4477913975715637], [-0.3034628629684448, -1.3403931856155396], [-0.4985416829586029, -0.9350043535232544], [-0.20713940262794495, -1.6761459112167358], [-0.07591237127780914, -2.6158924102783203], [-0.1190352737903595, -2.187263011932373], [-0.02154645137488842, -3.848299741744995], [-0.4160817563533783, -1.0777112245559692], [-0.1348344385623932, -2.0703673362731934], [-0.4064238965511322, -1.096697449684143], [-0.06558341532945633, -2.7570455074310303], [-0.06978126615285873, -2.697077751159668], [-0.008671958930790424, -4.751996040344238], [-0.6835399866104126, -0.7028474807739258], [-0.2828448712825775, -1.40094792842865], [-0.7948693633079529, -0.600823700428009], [-0.34279945492744446, -1.2371180057525635], [-0.5911852121353149, -0.806698203086853], [-0.28188714385032654, -1.403883457183838], [-0.46750307083129883, -0.9850106835365295], [-0.037112005054950714, -3.3123133182525635], [-1.4400310516357422, -0.27039292454719543], [-1.6683369874954224, -0.2089453488588333], [-0.30087950825691223, -1.3477157354354858], [-0.11408453434705734, -2.2273151874542236], [-0.2608017325401306, -1.4715633392333984], [-0.19432438910007477, -1.7338157892227173], [-0.08827230334281921, -2.471140146255493], [-0.20647595822811127, -1.6790337562561035], [-1.2138206958770752, -0.35248392820358276], [-0.017923062667250633, -4.030616760253906], [-0.5945092439651489, -0.8025902509689331], [-0.3302396535873413, -1.2685165405273438], [-0.4470251202583313, -1.0203404426574707], [-0.4565187096595764, -1.0037164688110352], [-0.0073233251459896564, -4.920357704162598], [-0.37206292152404785, -1.1689624786376953], [-1.2935402393341064, -0.3206157088279724], [-0.16137433052062988, -1.9036310911178589], [-0.11755995452404022, -2.1990106105804443], [-0.03496330603957176, -3.3708856105804443], [-0.3832840323448181, -1.1445071697235107], [-0.29722699522972107, -1.3581942319869995], [-0.9099853038787842, -0.5150514841079712], [-0.08838110417127609, -2.4699618816375732], [-0.11166252195835114, -2.2475860118865967], [-0.18462355434894562, -1.7803281545639038], [-0.4245759844779968, -1.0614523887634277], [-0.07459495961666107, -2.632748603820801], [-0.4615478515625, -0.9950829744338989], [-0.36344480514526367, -1.1883524656295776], [-0.04935784637928009, -3.033235788345337], [-0.14813867211341858, -1.9827617406845093], [-0.10739000886678696, -2.2845025062561035], [-0.0699697956442833, -2.6944730281829834], [-0.2998381555080414, -1.350688099861145], [-1.521317958831787, -0.2464427351951599], [-0.06677660346031189, -2.7396044731140137], [-0.10186684131622314, -2.3345894813537598], [-0.033336929976940155, -3.417711019515991], [-0.03928578272461891, -3.25647234916687], [-0.2572574019432068, -1.483550786972046], [-0.0027160681784152985, -5.909914016723633], [-0.7707177996635437, -0.6211630702018738], [-0.27077236771583557, -1.4388097524642944], [-0.23930858075618744, -1.5472710132598877], [-2.30075740814209, -0.10556374490261078], [-0.11356984823942184, -2.231584310531616], [-0.4495622217655182, -1.0158549547195435], [-0.3063812255859375, -1.3322076797485352], [-0.14479076862335205, -2.0039877891540527], [-0.4930897653102875, -0.9434986114501953], [-0.007011807058006525, -4.963657855987549], [-0.024142680689692497, -3.7358202934265137], [-0.9899337887763977, -0.46458035707473755], [-0.2602560520172119, -1.4733970165252686], [-0.41410523653030396, -1.0815527439117432], [-0.34270867705345154, -1.237339973449707], [-0.014739193953573704, -4.224608421325684], [-0.14320042729377747, -2.014256000518799], [-3.993675708770752, -0.018603837117552757], [-0.04815197363495827, -3.057373523712158], [-0.1927974820137024, -1.7409656047821045], [-0.1522619128227234, -1.9573185443878174], [-0.05602509155869484, -2.9098381996154785], [-0.016797881573438644, -4.094888210296631], [-0.3105188012123108, -1.320755958557129], [-0.32840025424957275, -1.2732326984405518], [-0.1006600633263588, -2.345914125442505], [-0.468237042427063, -0.9837805032730103], [-0.05246805027127266, -2.9736692905426025], [-1.0307822227478027, -0.4411872923374176], [-1.1279044151306152, -0.3911345601081848], [-0.515352725982666, -0.9095382690429688], [-0.14308564364910126, -2.0150017738342285], [-0.13408485054969788, -2.075576066970825], [-0.17305848002433777, -1.8394073247909546], [-0.22927117347717285, -1.5852961540222168], [-0.5228564143180847, -0.8985115885734558], [-0.07187293469905853, -2.668576955795288], [-0.3780308961868286, -1.1558473110198975], [-0.0578850619494915, -2.8780980110168457], [-0.018013102933764458, -4.025649547576904], [-0.6221305131912231, -0.7695953249931335], [-0.11555446684360504, -2.21523380279541], [-0.5837940573692322, -0.8159434795379639], [-0.10733068734407425, -2.2850260734558105], [-0.45516467094421387, -1.0060608386993408], [-1.455613613128662, -0.26560384035110474], [-0.34971514344215393, -1.2204031944274902], [-0.7751385569572449, -0.6173720359802246], [-0.026567475870251656, -3.641322374343872], [-0.022935587912797928, -3.7865121364593506], [-0.14951682090759277, -1.974173665046692], [-0.32351186871528625, -1.2859182357788086], [-0.25709599256515503, -1.4841012954711914], [-0.5722112655639648, -0.8307469487190247], [-0.707303524017334, -0.6791884303092957], [-0.38899683952331543, -1.132385492324829], [-0.02335294336080551, -3.768684148788452], [-0.3834734261035919, -1.1441020965576172], [-1.0406603813171387, -0.43575114011764526], [-0.017155231907963753, -4.074019432067871], [-0.2704715132713318, -1.4397778511047363], [-0.025684848427772522, -3.674668788909912], [-0.035152994096279144, -3.365571975708008], [-0.050352808088064194, -3.0137717723846436], [-0.39090922474861145, -1.12837553024292], [-0.03564351052045822, -3.3519556522369385], [-0.1076798066496849, -2.2819504737854004], [-0.2703670859336853, -1.4401142597198486], [-0.021860240027308464, -3.833996057510376], [-0.1921735405921936, -1.7439050674438477], [-0.7436370253562927, -0.64508455991745], [-0.5583771467208862, -0.8489516973495483], [-1.2283889055252075, -0.3463907241821289], [-0.05468785762786865, -2.933332920074463], [-0.15282490849494934, -1.953901767730713], [-0.12319635599851608, -2.1549415588378906], [-0.23092304170131683, -1.5789114236831665], [-0.4278237819671631, -1.0553410053253174], [-0.21123766899108887, -1.658531904220581], [-0.32072755694389343, -1.2932446002960205], [-1.6102454662322998, -0.2229418307542801], [-0.0791504755616188, -2.5757193565368652], [-0.27600404620170593, -1.422169804573059], [-0.10987257212400436, -2.2628676891326904], [-0.19995403289794922, -1.7079792022705078], [-0.33392778038978577, -1.2591525316238403], [-0.08851335942745209, -2.468531608581543], [-0.024748878553509712, -3.7113237380981445], [-0.006764725316315889, -4.9994120597839355], [-0.016629885882139206, -4.104854106903076], [-0.05964432656764984, -2.849029541015625], [-0.7041383385658264, -0.6822755336761475], [-0.984714150428772, -0.46767985820770264], [-0.25173676013946533, -1.5026007890701294], [-0.0374227836728096, -3.3041298389434814], [-0.03469206020236015, -3.378540277481079], [-0.11800775676965714, -2.1954286098480225], [-0.2123405486345291, -1.6538562774658203], [-0.017275569960474968, -4.067089557647705], [-0.37482526898384094, -1.1628608703613281], [-0.06588424742221832, -2.7526164054870605], [-0.08650916069746017, -2.490448236465454], [-0.13943958282470703, -2.039033889770508], [-0.5117926597595215, -0.9148419499397278], [-4.276629447937012, -0.013986782170832157], [-0.1894775927066803, -1.7567278146743774], [-0.09602769464254379, -2.3907480239868164], [-0.279579758644104, -1.4110028743743896], [-0.053753577172756195, -2.950101137161255], [-0.15148542821407318, -1.9620530605316162], [-0.09648242592811584, -2.3862481117248535], [-0.4947775602340698, -0.9408562183380127], [-0.02565034106373787, -3.675995349884033], [-0.5068543553352356, -0.9222773313522339], [-1.3731582164764404, -0.2920994162559509], [-0.16342584788799286, -1.8919962644577026], [-0.7430838346481323, -0.6455860733985901], [-0.21281175315380096, -1.6518666744232178], [-0.13282355666160583, -2.0844099521636963], [-0.05922701582312584, -2.855844259262085], [-0.0508032962679863, -3.005087375640869], [-0.27547693252563477, -1.4238299131393433], [-0.041851166635751724, -3.194488286972046], [-0.5138633251190186, -0.9117515087127686], [-0.013552562333643436, -4.307947158813477], [-1.2869665622711182, -0.32311171293258667], [-0.19015654921531677, -1.7534795999526978], [-0.6798245906829834, -0.7066497206687927], [-0.034361887723207474, -3.387939453125], [-0.2139507383108139, -1.6470786333084106], [-0.46518921852111816, -0.9889050722122192], [-0.029852934181690216, -3.526360511779785], [-0.12345421314239502, -2.1529769897460938], [-0.38877010345458984, -1.1328625679016113], [-0.20655788481235504, -1.6786766052246094], [-0.6589213013648987, -0.7285861968994141], [-0.9797502160072327, -0.4706515669822693], [-0.5588818788528442, -0.8482773303985596], [-0.24044525623321533, -1.543077826499939], [-0.08402318507432938, -2.5183794498443604], [-0.1002158597111702, -2.350118398666382], [-0.2292855829000473, -1.585240364074707], [-0.10014975070953369, -2.3507461547851562], [-0.018712768331170082, -3.98789381980896], [-0.025048526003956795, -3.6994383335113525], [-0.16356191039085388, -1.8912302255630493], [-0.023301001638174057, -3.7708842754364014], [-0.28782469034194946, -1.385866641998291], [-1.5793911218643188, -0.2307984083890915], [-1.0680837631225586, -0.4210861027240753], [-0.16908378899097443, -1.8607118129730225], [-0.4161863327026367, -1.0775086879730225], [-0.748697817325592, -0.6405207514762878], [-0.5373609066009521, -0.8777632713317871], [-0.16783839464187622, -1.8674991130828857], [-0.3682628870010376, -1.1774452924728394], [-0.022309403866529465, -3.8138794898986816], [-0.2915440797805786, -1.374796986579895], [-0.011785993352532387, -4.446732997894287], [-0.1725265383720398, -1.8422279357910156], [-0.39011064171791077, -1.130047082901001], [-0.15961627662181854, -1.9137296676635742], [-0.05661328509449959, -2.899684190750122], [-0.16905862092971802, -1.8608486652374268], [-0.14987820386886597, -1.9719359874725342], [-0.05390709266066551, -2.94732666015625], [-0.4203418493270874, -1.0695067644119263], [-0.46356990933418274, -0.9916449785232544], [-0.062206245958805084, -2.808241844177246], [-0.04695909097790718, -3.081865072250366], [-0.6165441870689392, -0.7761086225509644], [-0.27520301938056946, -1.4246939420700073], [-0.44970396161079407, -1.0156054496765137], [-2.6028120517730713, -0.07695125788450241], [-0.6009514927864075, -0.7947142124176025], [-0.24823373556137085, -1.51493501663208], [-1.1402394771575928, -0.38528382778167725], [-0.5469363331794739, -0.8644577264785767], [-0.1630595177412033, -1.8940622806549072], [-4.276629447937012, -0.013986782170832157], [-0.015823161229491234, -4.154180526733398], [-0.3460511565208435, -1.229209542274475], [-0.026039734482765198, -3.661125421524048], [-2.0327913761138916, -0.1403769552707672], [-0.17591308057308197, -1.8244328498840332], [-0.6448875665664673, -0.7438545823097229], [-0.07232225686311722, -2.6625661849975586], [-0.10040337592363358, -2.348341464996338], [-0.29713648557662964, -1.3584561347961426], [-0.4464350938796997, -1.021388292312622], [-0.35211342573165894, -1.2146978378295898], [-0.034609269350767136, -3.380887508392334], [-0.48891791701316833, -0.9500794410705566], [-0.049883633852005005, -3.022899627685547], [-0.3661586046218872, -1.1821876764297485], [-0.11394327878952026, -2.228485584259033], [-0.19209660589694977, -1.7442680597305298], [-0.157603457570076, -1.9254400730133057], [-0.22002063691616058, -1.6220279932022095], [-0.806199312210083, -0.5915876030921936], [-0.8256922364234924, -0.5761321187019348], [-0.10625837743282318, -2.2945399284362793], [-0.023848464712500572, -3.7479348182678223], [-0.3656432628631592, -1.183354377746582], [-0.06497064977884293, -2.766129493713379], [-0.0039952946826815605, -5.52463960647583], [-0.07147645950317383, -2.6739132404327393], [-0.048251375555992126, -3.0553605556488037], [-0.024031776934862137, -3.740368366241455], [-0.1685829609632492, -1.8634350299835205], [-0.08484803885221481, -2.509016990661621], [-0.2036527544260025, -1.691437840461731], [-1.101991057395935, -0.4037799835205078], [-0.5757206082344055, -0.8262203335762024], [-0.17842820286750793, -1.8114566802978516], [-0.15671135485172272, -1.9306823015213013], [-0.47826099395751953, -0.9672166705131531], [-0.388621062040329, -1.1331762075424194], [-0.37590160965919495, -1.1604981422424316], [-0.016398655250668526, -4.118741035461426], [-0.6854510307312012, -0.7009029984474182], [-0.09517819434404373, -2.3992161750793457], [-0.2124354988336563, -1.6534547805786133], [-0.011815681122243404, -4.444224834442139], [-0.2707490026950836, -1.4388848543167114], [-0.07745248079299927, -2.596566915512085], [-0.8379724025726318, -0.5666674375534058], [-1.0483872890472412, -0.4315564036369324], [-0.11619634926319122, -2.2100095748901367], [-1.0407588481903076, -0.4356973171234131], [-0.40679770708084106, -1.0959523916244507], [-0.09264199435710907, -2.424976348876953], [-0.7029951810836792, -0.683395266532898], [-0.15685464441776276, -1.9298381805419922], [-0.6812989115715027, -0.7051374316215515], [-4.484405517578125, -0.011347752064466476], [-0.08558675646781921, -2.5007126331329346], [-0.3110147714614868, -1.3193950653076172], [-0.4664263427257538, -0.9868199825286865], [-0.02073294296860695, -3.886380910873413], [-0.02830154076218605, -3.578956365585327], [-0.029630297794938087, -3.533735513687134], [-0.14954052865505219, -1.9740263223648071], [-1.1295902729034424, -0.39032870531082153], [-0.20727728307247162, -1.6755471229553223], [-0.37698888778686523, -1.1581193208694458], [-0.2532215714454651, -1.4974310398101807], [-0.04746885970234871, -3.0713207721710205], [-0.055968958884477615, -2.910811185836792], [-0.4373956024646759, -1.037656307220459], [-0.16239838302135468, -1.8978030681610107], [-0.043491385877132416, -3.1568593978881836], [-0.7736433744430542, -0.6186506748199463], [-0.13454397022724152, -2.0723817348480225], [-0.32258474826812744, -1.2883497476577759], [-0.7184951901435852, -0.6684258580207825], [-1.1930978298187256, -0.36137205362319946], [-0.6358054280281067, -0.7539780139923096], [-0.034992773085832596, -3.370058059692383], [-0.2836574912071228, -1.3984661102294922], [-0.014899403788149357, -4.213871002197266], [-0.08121419697999954, -2.5509979724884033], [-0.011834884062409401, -4.442615985870361], [-0.19935280084609985, -1.7107000350952148], [-0.11637081205844879, -2.208595037460327], [-0.23461788892745972, -1.5648136138916016], [-0.08408993482589722, -2.517618417739868], [-0.46136194467544556, -0.9954001307487488], [-0.5309405326843262, -0.8868572115898132], [-0.08268657326698303, -2.533756971359253], [-0.004342768341302872, -5.441422939300537], [-0.2309613674879074, -1.578763723373413], [-0.690615177154541, -0.695685625076294], [-0.3425753712654114, -1.237666130065918], [-0.7036772966384888, -0.6827268004417419], [-0.24312491714954376, -1.533280611038208], [-0.10862890630960464, -2.2736406326293945], [-0.4493844211101532, -1.0161683559417725], [-0.37284472584724426, -1.1672301292419434], [-0.5227771401405334, -0.8986271023750305], [-0.625800609588623, -0.7653589844703674], [-0.26582393050193787, -1.4548903703689575], [-0.006056764628738165, -5.109609603881836], [-0.011901678517460823, -4.4370222091674805], [-0.1658487319946289, -1.8784575462341309], [-0.2618204951286316, -1.4681518077850342], [-0.09231193363666534, -2.4283828735351562], [-0.37329375743865967, -1.1662371158599854], [-0.37947508692741394, -1.152711033821106], [-0.32898131012916565, -1.2717396020889282], [-0.7117450833320618, -0.6748888492584229], [-0.08536206930875778, -2.5032310485839844], [-0.0036737113259732723, -5.608386039733887], [-0.14332552254199982, -2.013444185256958], [-0.08178523927927017, -2.544271945953369], [-0.03933965042233467, -3.2551276683807373], [-0.5208722352981567, -0.9014075994491577], [-2.845759391784668, -0.05984567105770111], [-0.36751991510391235, -1.1791160106658936], [-0.5869476795196533, -0.8119800090789795], [-0.22910186648368835, -1.5859534740447998], [-0.04260621592402458, -3.1769819259643555], [-0.010309064760804176, -4.579883575439453], [-0.014999697916209698, -4.20721435546875], [-0.25347888469696045, -1.496538519859314], [-0.5112013816833496, -0.9157273769378662], [-0.534732460975647, -0.881469190120697], [-0.05855199322104454, -2.8669729232788086], [-0.35547521710395813, -1.206777811050415], [-0.09465444087982178, -2.4044761657714844], [-0.21173572540283203, -1.6564172506332397], [-0.04959440231323242, -3.0285727977752686], [-1.1032119989395142, -0.40317317843437195], [-0.18217714130878448, -1.792481780052185], [-0.01980716735124588, -3.9315993785858154], [-0.20268070697784424, -1.695752739906311], [-0.029917726293206215, -3.5242249965667725], [-0.8839305639266968, -0.5329959392547607], [-0.07931897044181824, -2.5736756324768066], [-0.8059989809989929, -0.5917492508888245], [-0.01726268231868744, -4.0678300857543945], [-1.6134909391403198, -0.2221328169107437], [-0.025720518082380295, -3.6732983589172363], [-0.21755392849445343, -1.6321145296096802], [-0.31903165578842163, -1.297743558883667], [-2.336367607116699, -0.10167636722326279], [-0.16595345735549927, -1.8778772354125977], [-0.36093443632125854, -1.1941039562225342], [-0.42059794068336487, -1.0690168142318726], [-0.10249486565589905, -2.3287527561187744], [-0.6576212644577026, -0.7299817800521851], [-0.11545930802822113, -2.216010808944702], [-0.03248137608170509, -3.4432857036590576], [-2.89982533454895, -0.05660506337881088], [-0.5474456548690796, -0.8637585639953613], [-0.570745587348938, -0.8326482176780701], [-0.15661799907684326, -1.9312330484390259], [-0.13124656677246094, -2.095582962036133], [-0.07750554382801056, -2.5959084033966064], [-0.22028981149196625, -1.620935082435608], [-0.0637357085943222, -2.7847096920013428], [-0.15132610499858856, -1.9630268812179565], [-0.7012025117874146, -0.6851562261581421], [-0.05964432656764984, -2.849029541015625], [-0.33502739667892456, -1.256384253501892], [-0.5012403726577759, -0.9308431148529053], [-0.45359447598457336, -1.0087908506393433], [-0.05150146037340164, -2.9917843341827393], [-1.0317108631134033, -0.44067278504371643], [-0.3402945101261139, -1.243270754814148], [-0.00921260379254818, -4.691779136657715], [-0.08234310895204544, -2.5377488136291504], [-0.4134887456893921, -1.0827555656433105], [-0.04463574290275574, -3.131455898284912], [-0.11581940203905106, -2.213074207305908], [-2.2145395278930664, -0.11563963443040848], [-1.5357067584991455, -0.2424582690000534], [-0.22955112159252167, -1.5842101573944092], [-0.6843188405036926, -0.7020541429519653], [-0.18264102935791016, -1.7901637554168701], [-0.7603180408477783, -0.6302056908607483], [-0.09715688973665237, -2.3796138763427734], [-0.32259830832481384, -1.2883139848709106], [-0.4221731424331665, -1.0660109519958496], [-0.3217392861843109, -1.290574073791504], [-0.08726347237825394, -2.482137680053711], [-0.6071301698684692, -0.787265419960022], [-0.258351594209671, -1.479830026626587], [-0.6647661328315735, -0.722357451915741], [-0.23642340302467346, -1.5580147504806519], [-0.08440869301557541, -2.5139923095703125], [-0.7686891555786133, -0.6229132413864136], [-0.33471718430519104, -1.2571638822555542], [-0.19910509884357452, -1.71182382106781], [-0.6192061901092529, -0.772995114326477], [-0.012075652368366718, -4.4225969314575195], [-0.4096563756465912, -1.0902820825576782], [-0.1954265534877777, -1.7286933660507202], [-0.3450663685798645, -1.2315952777862549], [-0.16167789697647095, -1.9018993377685547], [-0.006864654831588268, -4.984801769256592], [-0.02923847921192646, -3.54685378074646], [-0.22721441090106964, -1.5933183431625366], [-1.0588093996047974, -0.42597696185112], [-0.10171416401863098, -2.33601450920105], [-0.07757195085287094, -2.5950851440429688], [-0.2618429660797119, -1.4680767059326172], [-0.05565475672483444, -2.9162850379943848], [-0.08649101108312607, -2.4906482696533203], [-0.1547415852546692, -1.9423720836639404], [-1.2054388523101807, -0.3560473322868347], [-0.5589483976364136, -0.8481882810592651], [-2.0561463832855225, -0.13690397143363953], [-0.10084415972232819, -2.344177007675171], [-0.1925874799489975, -1.7419536113739014], [-0.744488000869751, -0.644314169883728], [-0.00971163809299469, -4.639283657073975], [-2.1078951358795166, -0.1295318901538849], [-0.30406132340431213, -1.338707447052002], [-0.44370412826538086, -1.0262597799301147], [-0.02806267887353897, -3.587311267852783], [-1.1101906299591064, -0.3997258245944977], [-0.35143768787384033, -1.2163007259368896], [-0.08544547110795975, -2.502295732498169], [-0.740903377532959, -0.6475681662559509], [-0.12333977967500687, -2.15384840965271], [-0.1228020042181015, -2.1579549312591553], [-2.099708318710327, -0.13066940009593964], [-0.003972259815782309, -5.53040885925293], [-0.5341010689735413, -0.882362961769104], [-0.36080336570739746, -1.1944056749343872], [-0.38571247458457947, -1.139328122138977], [-0.19336219131946564, -1.738314151763916], [-1.041822910308838, -0.43511685729026794], [-0.32552504539489746, -1.2806671857833862], [-0.5292956233024597, -0.8892101049423218], [-0.02405586652457714, -3.7393798828125], [-0.7439314723014832, -0.6448177099227905], [-0.06796157360076904, -2.722601890563965], [-0.09542712569236755, -2.39672589302063], [-0.6948700547218323, -0.6914272308349609], [-3.6295809745788574, -0.026885494589805603], [-0.018621739000082016, -3.992724657058716], [-0.6338686943054199, -0.7561622858047485], [-0.07411566376686096, -2.6389575004577637], [-0.06050153449177742, -2.8351845741271973], [-0.38555172085762024, -1.1396697759628296], [-0.27944716811180115, -1.4114140272140503], [-0.3064337968826294, -1.3320608139038086], [-0.33180665969848633, -1.2645230293273926], [-0.17875246703624725, -1.8097983598709106], [-0.056348416954278946, -2.904242992401123], [-0.6238782405853271, -0.7675738334655762], [-0.5565307140350342, -0.8514261245727539], [-0.6233780384063721, -0.7681517601013184], [-0.6019489765167236, -0.7935048341751099], [-0.1381654143333435, -2.0475914478302], [-0.24744130671024323, -1.5177526473999023], [-0.3894379436969757, -1.1314585208892822], [-0.5435492992401123, -0.869129478931427], [-0.021903159096837044, -3.8320538997650146], [-0.027871640399098396, -3.5940475463867188], [-0.09160656481981277, -2.4357059001922607], [-0.14791855216026306, -1.98414146900177], [-2.607250213623047, -0.07659709453582764], [-2.229440450668335, -0.11382807046175003], [-0.1455904096364975, -1.9988703727722168], [-0.03048551455140114, -3.505707263946533], [-1.8349738121032715, -0.1738983541727066], [-0.7778933048248291, -0.6150253415107727], [-0.7295140027999878, -0.6580567359924316], [-0.26501578092575073, -1.4575493335723877], [-0.9549239277839661, -0.48587512969970703], [-0.23678725957870483, -1.5566518306732178], [-1.062130093574524, -0.4242178201675415], [-0.24457402527332306, -1.5280331373214722], [-0.8747981786727905, -0.5394757390022278], [-0.3985908031463623, -1.1125043630599976], [-0.707303524017334, -0.6791884303092957], [-0.06835711002349854, -2.716993808746338], [-0.6607599854469299, -0.7266185879707336], [-0.044337574392557144, -3.1380088329315186], [-0.1884288787841797, -1.7617700099945068], [-0.10312948375940323, -2.3228909969329834], [-1.0021847486495972, -0.45740586519241333], [-0.012200371362268925, -4.412384033203125], [-0.7744124531745911, -0.6179924607276917], [-0.12057985365390778, -2.1751277446746826], [-0.16727885603904724, -1.8705666065216064], [-1.17896568775177, -0.36758676171302795], [-0.028413014486432076, -3.5750796794891357], [-0.48012158274650574, -0.9641902446746826], [-0.5000609755516052, -0.9326580166816711], [-0.18504104018211365, -1.7782716751098633], [-0.0014746040105819702, -6.520102024078369], [-1.172729730606079, -0.370369553565979], [-0.24786333739757538, -1.5162509679794312], [-0.019670885056257248, -3.9384355545043945], [-0.06162603944540024, -2.8173251152038574], [-0.05197315663099289, -2.9829022884368896], [-0.7726979851722717, -0.6194609999656677], [-0.22361379861831665, -1.6075594425201416], [-0.6804437637329102, -0.7060140371322632], [-0.2583262622356415, -1.4799158573150635], [-0.358670175075531, -1.1993327140808105], [-0.6000299453735352, -0.7958340048789978], [-0.7110205292701721, -0.6755878329277039], [-0.28230640292167664, -1.4025969505310059], [-0.26511335372924805, -1.4572275876998901], [-0.383943110704422, -1.1430976390838623], [-0.21040493249893188, -1.6620798110961914], [-0.01717527024447918, -4.07286262512207], [-0.29807573556900024, -1.3557462692260742], [-0.11450125277042389, -2.2238738536834717], [-0.05077836662530899, -3.0055665969848633], [-0.10314550250768661, -2.322744131088257], [-0.33585622906684875, -1.2543047666549683], [-0.16676843166351318, -1.8733744621276855], [-0.28537237644195557, -1.3932557106018066], [-0.8442239761352539, -0.5619275569915771], [-1.288575291633606, -0.3224988281726837], [-0.4082128405570984, -1.093139410018921], [-0.10453259944915771, -2.3100671768188477], [-0.08369915187358856, -2.5220847129821777], [-0.4598497152328491, -0.9979848861694336], [-0.21917995810508728, -1.6254513263702393], [-0.31268611550331116, -1.314827799797058], [-0.30296093225479126, -1.3418104648590088], [-0.4764164686203003, -0.9702317714691162], [-0.2775997221469879, -1.4171661138534546], [-0.1964562088251114, -1.7239360809326172], [-0.026666026562452316, -3.6376702785491943], [-0.1458945870399475, -1.996931791305542], [-0.39474523067474365, -1.1204031705856323], [-0.6950090527534485, -0.6912887692451477], [-0.04661234840750694, -3.0891060829162598], [-0.05095658451318741, -3.0021512508392334], [-0.22227925062179565, -1.6129026412963867], [-0.6647618412971497, -0.7223619222640991], [-0.3094319701194763, -1.323746919631958], [-0.16445641219615936, -1.8862113952636719], [-0.04575692489743233, -3.1072022914886475], [-0.49338021874427795, -0.9430432319641113], [-0.44583672285079956, -1.0224525928497314], [-0.41244685649871826, -1.084793210029602], [-0.1444334238767624, -2.006284236907959], [-0.1787344217300415, -1.809890866279602], [-0.6755932569503784, -0.7110147476196289], [-0.5310053825378418, -0.886764645576477], [-0.5652985572814941, -0.8397706747055054], [-0.34626737236976624, -1.2286869287490845], [-0.061292532831430435, -2.822587013244629], [-0.22839848697185516, -1.588690161705017], [-0.6698461174964905, -0.7170041799545288], [-0.44139403104782104, -1.030409574508667], [-0.4360494911670685, -1.040114402770996], [-0.014289435930550098, -4.255372047424316], [-0.40835851430892944, -1.092850685119629], [-0.9148136377334595, -0.5118116140365601], [-0.16967813670635223, -1.857491374015808], [-0.21587000787258148, -1.6390732526779175], [-0.17966964840888977, -1.8051252365112305], [-0.768013596534729, -0.6234974265098572], [-0.2719151973724365, -1.4351437091827393], [-0.0931607186794281, -2.419647693634033], [-0.028837356716394424, -3.56046724319458], [-0.19223570823669434, -1.743611454963684], [-0.020715661346912384, -3.887202739715576], [-0.026204532012343407, -3.654897689819336], [-0.3669153153896332, -1.180478572845459], [-0.3541792333126068, -1.2098203897476196], [-0.2070375382900238, -1.6765884160995483], [-0.1754375696182251, -1.8269087076187134], [-0.0014611531514674425, -6.529261589050293], [-1.269195318222046, -0.32997408509254456], [-0.13774867355823517, -2.050408363342285], [-1.2681422233581543, -0.3303862512111664], [-1.5566612482070923, -0.23678471148014069], [-0.8813292384147644, -0.5348312854766846], [-0.9182595014572144, -0.5095151662826538], [-0.19124609231948853, -1.7482938766479492], [-0.3876359164714813, -1.135253667831421], [-1.320340633392334, -0.31067004799842834], [-0.4480520486831665, -1.0185211896896362], [-0.15454243123531342, -1.9435631036758423], [-0.07552998512983322, -2.6207528114318848], [-0.12135874480009079, -2.16907000541687], [-0.23723062872886658, -1.554993987083435], [-0.05567234754562378, -2.9159791469573975], [-0.07839079201221466, -2.5849878787994385], [-0.2891865074634552, -1.3817944526672363], [-0.1281793862581253, -2.117729425430298], [-0.8883914947509766, -0.5298671722412109], [-0.6370624303817749, -0.7525653839111328], [-0.19538262486457825, -1.7288964986801147], [-0.3540835976600647, -1.210045576095581], [-0.036326125264167786, -3.333327054977417], [-0.2899744510650635, -1.379448413848877], [-0.9776226282119751, -0.4719325304031372], [-0.3716723620891571, -1.1698296070098877], [-0.0034797375556081533, -5.662537574768066], [-0.2600514590740204, -1.4740850925445557], [-0.42355549335479736, -1.063384771347046], [-0.27131327986717224, -1.4370726346969604], [-0.2942483425140381, -1.3668503761291504], [-0.5114830732345581, -0.9153054356575012], [-0.11851995438337326, -2.1913485527038574], [-0.32314735651016235, -1.2868733406066895], [-1.5399619340896606, -0.24129381775856018], [-0.01465156115591526, -4.230525016784668], [-0.09221845120191574, -2.429349660873413], [-0.43791767954826355, -1.0367056131362915], [-0.6053522825241089, -0.789398193359375], [-0.02210758440196514, -3.8228673934936523], [-0.21960067749023438, -1.6237363815307617], [-0.19512972235679626, -1.7300695180892944], [-0.8886987566947937, -0.5296523571014404], [-0.040274206548929214, -3.232113838195801], [-0.06484943628311157, -2.767937183380127], [-0.30461519956588745, -1.3371503353118896], [-0.0711175799369812, -2.67876935005188], [-0.18773511052131653, -1.7651225328445435], [-0.2620963454246521, -1.4672305583953857], [-0.4508170783519745, -1.0136483907699585], [-1.1083282232284546, -0.4006422758102417], [-0.3348143398761749, -1.2569197416305542], [-0.031431615352630615, -3.475616931915283], [-0.15750914812088013, -1.925992488861084], [-0.3721170723438263, -1.1688423156738281], [-0.07890098541975021, -2.5787525177001953], [-0.0678117647767067, -2.7247345447540283], [-0.02974879741668701, -3.5298047065734863], [-0.4182336926460266, -1.0735540390014648], [-0.26390340924263, -1.4612233638763428], [-0.1296086460351944, -2.1073405742645264], [-0.03348807618021965, -3.4132630825042725], [-0.019069669768214226, -3.96917724609375], [-0.3203018009662628, -1.294371247291565], [-0.618034303188324, -0.77436363697052], [-0.1311570703983307, -2.096221446990967], [-0.035590820014476776, -3.3534107208251953], [-0.049272630363702774, -3.0349225997924805], [-0.05295252054929733, -2.964719533920288], [-0.0669877827167511, -2.7365524768829346], [-0.20986291766166687, -1.664397954940796], [-0.2243633270263672, -1.6045737266540527], [-0.0303349532186985, -3.5105834007263184], [-0.22942519187927246, -1.5846986770629883], [-0.7945753931999207, -0.6010659337043762], [-0.015991292893886566, -4.143692970275879], [-0.06796570122241974, -2.7225425243377686], [-0.12898297607898712, -2.1118736267089844], [-0.00964304432272911, -4.646337032318115], [-0.3054368495941162, -1.3348464965820312], [-0.2909826636314392, -1.376457691192627], [-0.24265842139720917, -1.5349774360656738], [-0.7307791709899902, -0.6568801999092102], [-0.13305535912513733, -2.082780122756958], [-0.48676660656929016, -0.9535006284713745], [-0.0038176528178155422, -5.570013046264648], [-0.14787805080413818, -1.984395146369934], [-0.0562787801027298, -2.9054441452026367], [-0.3785036504268646, -1.154819130897522], [-0.19656002521514893, -1.723458170890808], [-0.24878697097301483, -1.5129741430282593], [-0.044960375875234604, -3.1243693828582764], [-0.18809953331947327, -1.7633601427078247], [-0.07658064365386963, -2.6074576377868652], [-0.2003173530101776, -1.7063395977020264], [-0.004342768341302872, -5.441422939300537], [-0.01574735902249813, -4.158946514129639], [-0.05491480231285095, -2.9293034076690674], [-0.021382169798016548, -3.855868339538574], [-0.3175411820411682, -1.3017204999923706], [-1.0351473093032837, -0.43877482414245605], [-0.15151022374629974, -1.9619007110595703], [-0.20640632510185242, -1.679337501525879], [-0.03293052688241005, -3.429774761199951], [-0.29832255840301514, -1.3550359010696411], [-0.07777843624353409, -2.592528820037842], [-0.13655108213424683, -2.0585548877716064], [-0.16393382847309113, -1.8891396522521973], [-2.3899149894714355, -0.0961117222905159], [-0.052834250032901764, -2.966895818710327], [-0.2693541944026947, -1.443384051322937], [-0.30168116092681885, -1.3454359769821167], [-0.11285088956356049, -2.2375824451446533], [-0.12042968720197678, -2.176299571990967], [-0.3400663733482361, -1.2438337802886963], [-0.3658911883831024, -1.1827930212020874], [-0.07257173210382462, -2.6592464447021484], [-0.01379009522497654, -4.29069185256958], [-0.009057151153683662, -4.708724021911621], [-0.37620213627815247, -1.1598396301269531], [-0.5010973811149597, -0.9310627579689026], [-0.9746591448783875, -0.47372400760650635], [-0.6593499183654785, -0.7281268239021301], [-0.2117244452238083, -1.65646493434906], [-0.3137330114841461, -1.3119815587997437], [-0.39768680930137634, -1.1143527030944824], [-0.11986950784921646, -2.180687665939331], [-0.8247977495193481, -0.5768293738365173], [-1.008493423461914, -0.4537651538848877], [-0.02684812620282173, -3.630952835083008], [-0.29835405945777893, -1.3549450635910034], [-0.22538979351520538, -1.600502848625183], [-0.0199786014854908, -3.9230637550354004], [-0.03188793361186981, -3.4614295959472656], [-0.3054841160774231, -1.3347141742706299], [-0.4937155544757843, -0.9425177574157715], [-0.3193816542625427, -1.2968125343322754], [-0.10959719121456146, -2.2652413845062256], [-0.4987885057926178, -0.9346225261688232], [-0.31081587076187134, -1.3199403285980225], [-0.49669134616851807, -0.9378737807273865], [-0.08707062900066376, -2.48425555229187], [-0.5793829560279846, -0.8215352296829224], [-0.009729819372296333, -4.637426853179932], [-0.21748286485671997, -1.6324067115783691], [-0.6539820432662964, -0.7339089512825012], [-0.01506992056965828, -4.202581405639648], [-0.014876148663461208, -4.215427398681641], [-0.016224846243858337, -4.129314422607422], [-0.17507879436016083, -1.8287814855575562], [-0.14513860642910004, -2.0017576217651367], [-0.325740247964859, -1.280107855796814], [-1.1098322868347168, -0.39990198612213135], [-0.18688839673995972, -1.7692327499389648], [-0.011733093298971653, -4.451206207275391], [-0.1381426751613617, -2.0477447509765625], [-0.3797905445098877, -1.15202796459198], [-4.187312126159668, -0.015303571708500385], [-0.7624134421348572, -0.6283694505691528], [-0.27146223187446594, -1.4365946054458618], [-0.12941312789916992, -2.1087543964385986], [-0.28098225593566895, -1.4066674709320068], [-0.2568315863609314, -1.4850034713745117], [-0.029858604073524475, -3.5261762142181396], [-1.6267030239105225, -0.21887342631816864], [-0.5060765743255615, -0.9234568476676941], [-0.21636173129081726, -1.6370348930358887], [-0.3029826879501343, -1.3417489528656006], [-0.23038777709007263, -1.5809745788574219], [-0.1289452463388443, -2.112147092819214], [-0.5860680341720581, -0.8130828142166138], [-0.13457345962524414, -2.0721774101257324], [-0.009181302972137928, -4.695169925689697], [-0.2220105230808258, -1.6139827966690063], [-0.5442929267883301, -0.8681005239486694], [-0.12437878549098969, -2.145968437194824], [-0.15766200423240662, -1.925097107887268], [-0.2651522159576416, -1.4570996761322021], [-1.2164467573165894, -0.3513762056827545], [-0.6409727931022644, -0.7481943368911743], [-0.028807125985622406, -3.5615012645721436], [-0.34361547231674194, -1.2351248264312744], [-0.23714891076087952, -1.555299162864685], [-0.19419196248054504, -1.7344335317611694], [-0.12370379269123077, -2.1510794162750244], [-0.1841740757226944, -1.782547950744629], [-1.2416293621063232, -0.34096065163612366], [-1.095757007598877, -0.40689587593078613], [-0.28542882204055786, -1.3930847644805908], [-2.082498550415039, -0.13309544324874878], [-0.23797659575939178, -1.5522124767303467], [-0.3477465808391571, -1.2251209020614624], [-0.24975228309631348, -1.5095641613006592], [-0.2588294744491577, -1.4782108068466187], [-0.1147710382938385, -2.2216527462005615], [-0.04794939607381821, -3.0614874362945557], [-0.5831758975982666, -0.8167237639427185], [-0.10586705058813095, -2.2980382442474365], [-0.17784611880779266, -1.8144419193267822], [-0.2784706652164459, -1.414448857307434], [-0.003057212568819523, -5.791793346405029], [-1.2950108051300049, -0.32006049156188965], [-0.25784921646118164, -1.4815361499786377], [-0.3454003632068634, -1.2307852506637573], [-0.1277129203081131, -2.1211471557617188], [-0.10431879013776779, -2.3120100498199463], [-0.24883130192756653, -1.512817144393921], [-0.4106009304523468, -1.0884188413619995], [-0.06959713995456696, -2.6996283531188965], [-0.14635923504829407, -1.9939780235290527], [-0.16016407310962677, -1.910569667816162], [-0.1316256821155548, -2.092884063720703], [-0.11180281639099121, -2.246399402618408], [-0.010581223294138908, -4.55396032333374], [-0.16408367455005646, -1.8882991075515747], [-0.008435452356934547, -4.779521465301514], [-0.5157707333564758, -0.9089187383651733], [-0.5028259754180908, -0.928411602973938], [-0.5418633222579956, -0.8714691996574402], [-0.24673524498939514, -1.5202714204788208], [-0.09688901901245117, -2.382242441177368], [-0.013706612400710583, -4.296720027923584], [-0.6079171299934387, -0.7863239645957947], [-0.4516974091529846, -1.0121047496795654], [-1.2642723321914673, -0.3319053649902344], [-0.042522817850112915, -3.1789016723632812], [-0.43728968501091003, -1.0378491878509521], [-0.4684102535247803, -0.9834904074668884], [-0.08426285535097122, -2.5156497955322266], [-0.5422233939170837, -0.8709685206413269], [-0.20713940262794495, -1.6761459112167358], [-0.054747335612773895, -2.932274580001831], [-0.18380773067474365, -1.784361720085144], [-0.1455904096364975, -1.9988703727722168], [-0.1511320024728775, -1.9642163515090942], [-0.21338261663913727, -1.649463415145874], [-1.8629070520401, -0.16867993772029877], [-0.19983866810798645, -1.7085011005401611], [-0.22973351180553436, -1.5835037231445312], [-0.4402468800544739, -1.0324804782867432], [-0.6786159873008728, -0.7078925967216492], [-0.3967427909374237, -1.1162885427474976], [-0.013378962874412537, -4.320754528045654], [-0.01578514277935028, -4.156569480895996], [-0.597240686416626, -0.7992370128631592], [-0.31996986269950867, -1.2952511310577393], [-0.9103370308876038, -0.5148147344589233], [-0.623357892036438, -0.7681748867034912], [-0.4494934678077698, -1.0159761905670166], [-0.6576980352401733, -0.7298992872238159], [-0.1086033508181572, -2.2738635540008545], [-0.35023927688598633, -1.219152569770813], [-0.23650047183036804, -1.5577260255813599], [-0.27604150772094727, -1.4220519065856934], [-0.07638263702392578, -2.6099483966827393], [-0.06256867200136185, -2.8026113510131836], [-0.0338442362844944, -3.4028613567352295], [-0.08165253698825836, -2.545830249786377], [-0.13843543827533722, -2.0457701683044434], [-0.21223846077919006, -1.6542878150939941], [-0.1325726956129074, -2.0861783027648926], [-0.07783567160367966, -2.59182071685791], [-0.2736303508281708, -1.4296746253967285], [-0.004342768341302872, -5.441422939300537], [-0.13627202808856964, -2.06046462059021], [-0.25192421674728394, -1.501946210861206], [-0.24608126282691956, -1.5226120948791504], [-0.34134018421173096, -1.240695834159851], [-0.16583974659442902, -1.8785077333450317], [-0.47280049324035645, -0.9761852025985718], [-0.17357683181762695, -1.8366680145263672], [-0.34512123465538025, -1.2314621210098267], [-0.023824602365493774, -3.7489237785339355], [-0.11134913563728333, -2.2502427101135254], [-0.08061038702726364, -2.558162212371826], [-0.2870030105113983, -1.3883343935012817], [-0.24364322423934937, -1.5313997268676758], [-1.318619966506958, -0.311297744512558], [-0.5303719639778137, -0.8876694440841675], [-0.9114952087402344, -0.5140355229377747], [-0.08835458755493164, -2.4702494144439697], [-0.07871423661708832, -2.5810303688049316], [-0.24831800162792206, -1.5146359205245972], [-0.8448969125747681, -0.5614203214645386], [-0.15371322631835938, -1.948538899421692], [-0.34888216853141785, -1.222395658493042], [-0.15853677690029144, -1.9199901819229126], [-0.18015022575855255, -1.8026872873306274], [-0.77284836769104, -0.6193321943283081], [-1.6735179424285889, -0.2077452689409256], [-0.0711241289973259, -2.678679943084717], [-0.14284582436084747, -2.0165624618530273], [-0.08027687668800354, -2.562143087387085], [-0.5015906095504761, -0.9303051233291626], [-0.10288643836975098, -2.325131416320801], [-0.1260485053062439, -2.133450508117676], [-0.30601760745048523, -1.3332226276397705], [-0.24237604439258575, -1.5360064506530762], [-0.06199853867292404, -2.8114845752716064], [-0.40145450830459595, -1.106682300567627], [-0.050590939819812775, -3.009171724319458], [-0.022726088762283325, -3.7955827713012695], [-0.5511791110038757, -0.8586585521697998], [-0.15054088830947876, -1.9678466320037842], [-0.03360877186059952, -3.409727096557617], [-0.3702867329120636, -1.1729145050048828], [-0.010829605162143707, -4.530879020690918], [-0.13483892381191254, -2.0703365802764893], [-0.5976727604866028, -0.7987083792686462], [-0.04280553758144379, -3.172415256500244], [-0.25356724858283997, -1.496232509613037], [-0.24794045090675354, -1.5159767866134644], [-0.10732544213533401, -2.2850728034973145], [-0.27523940801620483, -1.424579381942749], [-0.7817960977554321, -0.611720860004425], [-0.1851167231798172, -1.7778997421264648], [-1.624587059020996, -0.2193918228149414], [-1.2233400344848633, -0.3484881520271301], [-1.617745280265808, -0.22107747197151184], [-0.44623613357543945, -1.0217419862747192], [-0.15154966711997986, -1.9616597890853882], [-0.034218937158584595, -3.3920373916625977], [-0.3346235454082489, -1.2573996782302856], [-0.585148811340332, -0.8142373561859131], [-0.15275830030441284, -1.9543051719665527], [-0.41182398796081543, -1.086014747619629], [-0.2851601541042328, -1.393898606300354], [-0.2887548506259918, -1.3830829858779907], [-0.03596348688006401, -3.3431806564331055], [-0.4062964618206024, -1.0969516038894653], [-1.0148136615753174, -0.4501538872718811], [-0.10558198392391205, -2.300593852996826], [-0.1024206206202507, -2.3294403553009033], [-0.38168323040008545, -1.1479430198669434], [-2.8631999492645264, -0.05877997353672981], [-0.9718264937400818, -0.4754444360733032], [-0.269442617893219, -1.4430980682373047], [-0.03352796286344528, -3.4120919704437256], [-0.28787270188331604, -1.3857227563858032], [-0.07130474597215652, -2.6762335300445557], [-0.043452922254800797, -3.157723903656006], [-0.09320861101150513, -2.4191572666168213], [-0.16267095506191254, -1.8962589502334595], [-1.9155402183532715, -0.1593032330274582], [-0.14005637168884277, -2.0349209308624268], [-0.016493523493409157, -4.1130242347717285], [-0.005282136145979166, -5.246060848236084], [-0.0695943608880043, -2.6996662616729736], [-0.09653502702713013, -2.3857290744781494], [-0.30086010694503784, -1.347771167755127], [-0.3968442678451538, -1.1160801649093628], [-1.164591670036316, -0.37403926253318787], [-0.09405023604631424, -2.4105827808380127], [-0.053125374019145966, -2.9615464210510254], [-1.592515230178833, -0.22741934657096863], [-1.2234256267547607, -0.34845247864723206], [-1.5248875617980957, -0.24544735252857208], [-0.30776330828666687, -1.3283623456954956], [-0.19073082506656647, -1.7507423162460327], [-0.3614963889122009, -1.192812442779541], [-0.11710824072360992, -2.202639102935791], [-0.46334192156791687, -0.9920316934585571], [-0.5404061079025269, -0.8734986186027527], [-0.8163129687309265, -0.5835012197494507], [-0.07563024014234543, -2.619476556777954], [-0.02932669408619404, -3.54388427734375], [-1.108390212059021, -0.40061187744140625], [-1.0003612041473389, -0.45846492052078247], [-0.22571079432964325, -1.5992342233657837], [-0.0920877754688263, -2.430704116821289], [-0.01763884164392948, -4.046461582183838], [-0.6422982215881348, -0.7467209696769714], [-0.11716306209564209, -2.2021985054016113], [-0.07761342823505402, -2.594571113586426], [-0.1509680151939392, -1.965221643447876], [-0.004342768341302872, -5.441422939300537], [-0.2676585018634796, -1.4488892555236816], [-0.1311856210231781, -2.096018075942993], [-1.5895737409591675, -0.22817182540893555], [-2.6284470558166504, -0.07492882013320923], [-0.05953538045287132, -2.850804090499878], [-0.4819066524505615, -0.9613004326820374], [-0.3281590938568115, -1.2738533020019531], [-0.12503743171691895, -2.141009569168091], [-0.16244682669639587, -1.8975290060043335], [-0.4992281198501587, -0.9339431524276733], [-0.09966657310724258, -2.35534405708313], [-0.5056582689285278, -0.924092173576355], [-0.7867225408554077, -0.6075838208198547], [-0.0835760235786438, -2.52349591255188], [-0.03743242844939232, -3.3038747310638428], [-0.2003418356180191, -1.7062290906906128], [-0.015935681760311127, -4.14715051651001], [-0.2534193992614746, -1.4967447519302368], [-0.25932446122169495, -1.4765371084213257], [-0.08105525374412537, -2.5528783798217773], [-0.8939325213432312, -0.5260137915611267], [-0.5797472596168518, -0.8210713267326355], [-0.4384170174598694, -1.035797119140625], [-0.30348584055900574, -1.3403284549713135], [-1.398681402206421, -0.28358691930770874], [-0.1408376544713974, -2.02974009513855], [-1.6431875228881836, -0.21488121151924133], [-0.031894974410533905, -3.4612112045288086], [-0.4458528757095337, -1.022423505783081], [-0.08005253970623016, -2.564831495285034], [-0.07845030725002289, -2.5842583179473877], [-0.2922014892101288, -1.3728573322296143], [-0.02341652661561966, -3.7659969329833984], [-1.882511019706726, -0.16511930525302887], [-0.010972402058541775, -4.517858028411865], [-0.608996570110321, -0.7850351333618164], [-1.2364264726638794, -0.34308236837387085], [-0.02313351258635521, -3.778015613555908], [-0.18649503588676453, -1.7711492776870728], [-0.13248927891254425, -2.0867671966552734], [-0.13764968514442444, -2.051079273223877], [-0.17901045083999634, -1.8084814548492432], [-0.028431322425603867, -3.5744473934173584], [-0.14269483089447021, -2.0175461769104004], [-0.02113371156156063, -3.867436647415161], [-0.4567720890045166, -1.0032784938812256], [-0.48526129126548767, -0.9559060335159302], [-0.4233437180519104, -1.063786268234253], [-0.02037126198410988, -3.9038007259368896], [-0.5147724151611328, -0.9103996753692627], [-0.5707821249961853, -0.8326008319854736], [-0.5225169658660889, -0.8990061283111572], [-0.5840058922767639, -0.8156764507293701], [-0.5076273679733276, -0.9211075305938721], [-0.09417891502380371, -2.409278631210327], [-0.4717889428138733, -0.9778608679771423], [-0.5249884128570557, -0.895415723323822], [-0.060037098824977875, -2.8426618576049805], [-0.17155377566814423, -1.8474093675613403], [-0.14367437362670898, -2.011183023452759], [-0.04332096874713898, -3.160701036453247], [-0.1493811011314392, -1.97501540184021], [-0.2865220904350281, -1.389782428741455], [-0.3745310306549072, -1.1635081768035889], [-0.3220127522945404, -1.2898536920547485], [-0.13482068479061127, -2.070462703704834], [-0.21739116311073303, -1.6327840089797974], [-0.6007307767868042, -0.7949821949005127], [-0.5813261270523071, -0.8190651535987854], [-0.07803857326507568, -2.58931827545166], [-0.1654384285211563, -1.8807355165481567], [-0.025326348841190338, -3.6885483264923096], [-0.24824675917625427, -1.514889121055603], [-0.16239838302135468, -1.8978030681610107], [-0.31538087129592896, -1.3075237274169922], [-0.05191170424222946, -2.9840548038482666], [-0.061777789145708084, -2.814941167831421], [-0.004342768341302872, -5.441422939300537], [-0.09615135937929153, -2.389521598815918], [-0.16076567769050598, -1.9071134328842163], [-0.3512394428253174, -1.2167717218399048], [-0.3467405438423157, -1.2275443077087402], [-0.1428074836730957, -2.016812324523926], [-0.04575237259268761, -3.107299566268921], [-0.1662263721227646, -1.8763670921325684], [-0.45688652992248535, -1.0030806064605713], [-0.3961106836795807, -1.117587685585022], [-0.20342984795570374, -1.6924253702163696], [-0.13633038103580475, -2.0600650310516357], [-0.915989339351654, -0.5110266208648682], [-0.0590684749186039, -2.858445882797241], [-0.0079609714448452, -4.8371782302856445], [-0.4709553122520447, -0.9792452454566956], [-0.17463131248950958, -1.8311234712600708], [-0.23897962272167206, -1.5484881401062012], [-0.30750617384910583, -1.3290764093399048], [-0.05142197385430336, -2.9932897090911865], [-0.03009796515107155, -3.518310785293579], [-0.02557981014251709, -3.6787161827087402], [-0.05349675938487053, -2.9547626972198486], [-1.6740617752075195, -0.20761963725090027], [-1.4497699737548828, -0.26738837361335754], [-0.45454347133636475, -1.0071394443511963], [-0.004083035048097372, -5.50295877456665], [-0.27092450857162476, -1.4383208751678467], [-0.019110605120658875, -3.967054843902588], [-0.38084468245506287, -1.1497498750686646], [-0.6174352765083313, -0.7750644683837891], [-0.003682381473481655, -5.606021881103516], [-0.2999662160873413, -1.3503220081329346], [-0.19067910313606262, -1.750988483428955], [-0.13981209695339203, -2.0365476608276367], [-0.434499055147171, -1.042957067489624], [-4.401937484741211, -0.012329314835369587], [-0.578213095664978, -0.8230275511741638], [-0.1533379852771759, -1.9508001804351807], [-0.20323480665683746, -1.6932899951934814], [-0.05880279093980789, -2.862823724746704], [-0.1086939200758934, -2.2730743885040283], [-0.7912403345108032, -0.6038225293159485], [-0.12774942815303802, -2.1208794116973877], [-0.313355952501297, -1.3130055665969849], [-0.08731984347105026, -2.4815192222595215], [-0.47861647605895996, -0.966637372970581], [-0.28568723797798157, -1.3923027515411377], [-0.1343260556459427, -2.073896646499634], [-0.06496729701757431, -2.7661798000335693], [-0.16282828152179718, -1.8953686952590942], [-0.19496218860149384, -1.730847716331482], [-0.19947360455989838, -1.7101526260375977], [-0.21537582576274872, -1.6411265134811401], [-0.012147494591772556, -4.4166998863220215], [-0.9666085243225098, -0.47863414883613586], [-0.33157598972320557, -1.2651094198226929], [-0.2639673054218292, -1.4610118865966797], [-0.17148306965827942, -1.8477873802185059], [-0.05080771446228027, -3.0050039291381836], [-0.14083516597747803, -2.029756546020508], [-0.3023730218410492, -1.3434737920761108], [-0.8961403369903564, -0.5244884490966797], [-0.2776443362236023, -1.4170267581939697], [-0.7920741438865662, -0.6031317710876465], [-0.08191803842782974, -2.542714834213257], [-1.472538948059082, -0.2605111002922058], [-0.670033872127533, -0.7168073654174805], [-0.06827015429735184, -2.718223810195923], [-0.0976477637887001, -2.374814510345459], [-0.16239838302135468, -1.8978030681610107], [-0.22943077981472015, -1.5846773386001587], [-0.16907261312007904, -1.8607723712921143], [-0.05871342867612839, -2.8643007278442383], [-0.3712817132472992, -1.170697808265686], [-0.018577391281723976, -3.995083808898926], [-0.2672913670539856, -1.4500865936279297], [-0.4233776032924652, -1.0637222528457642], [-0.03609204664826393, -3.339674711227417], [-0.1502244770526886, -1.9697970151901245], [-1.8126847743988037, -0.1781885325908661], [-0.07992389798164368, -2.5663764476776123], [-0.03195478767156601, -3.459369421005249], [-0.4288254380226135, -1.0534677505493164], [-0.731630802154541, -0.6560898423194885], [-0.21552228927612305, -1.6405173540115356], [-0.16708117723464966, -1.8716533184051514], [-0.38299664855003357, -1.14512300491333], [-0.0013556823832914233, -6.604093551635742], [-0.07833699882030487, -2.58564829826355], [-0.6522156596183777, -0.7358258962631226], [-0.7002171874046326, -0.6861268281936646], [-1.068357229232788, -0.42094284296035767], [-0.3381282091140747, -1.248635172843933], [-0.06368011981248856, -2.7855546474456787], [-0.2291869968175888, -1.585623025894165], [-1.8214175701141357, -0.17649409174919128], [-1.775576114654541, -0.18558993935585022], [-0.015620498917996883, -4.1669697761535645], [-0.4491152763366699, -1.0166430473327637], [-0.0165004413574934, -4.112605094909668], [-0.5602849125862122, -0.8464064002037048], [-0.8912938833236694, -0.527844250202179], [-0.1101064458489418, -2.2608561515808105], [-0.29395174980163574, -1.3677177429199219], [-0.049947820603847504, -3.0216469764709473], [-1.3855061531066895, -0.2879450023174286], [-0.11313612759113312, -2.2351977825164795], [-0.3369476795196533, -1.2515754699707031], [-0.3830912709236145, -1.1449201107025146], [-0.08688245713710785, -2.486325979232788], [-0.06790433079004288, -2.7234156131744385], [-0.10288278013467789, -2.325165033340454], [-0.09038406610488892, -2.4485392570495605], [-0.03579339012503624, -3.3478341102600098], [-0.3136898875236511, -1.312098741531372], [-1.745902180671692, -0.19175086915493011], [-0.02748922072350979, -3.6076760292053223], [-0.22839270532131195, -1.5887125730514526], [-0.06219974905252457, -2.8083431720733643], [-0.2095242142677307, -1.6658496856689453], [-4.651154041290283, -0.009596525691449642], [-0.22270561754703522, -1.611191749572754], [-0.7873811721801758, -0.6070335507392883], [-0.09530521929264069, -2.3979451656341553], [-0.030432555824518204, -3.5074188709259033], [-0.16877047717571259, -1.8624144792556763], [-0.09073784202337265, -2.4448070526123047], [-0.43911507725715637, -1.0345299243927002], [-0.2725889980792999, -1.432990550994873], [-0.707303524017334, -0.6791884303092957], [-0.01253711897879839, -4.385324478149414], [-0.24539951980113983, -1.525059461593628], [-0.028165485709905624, -3.5837087631225586], [-0.35137829184532166, -1.2164417505264282], [-0.15088672935962677, -1.965720534324646], [-0.1823367029428482, -1.7916837930679321], [-0.600287675857544, -0.7955206036567688], [-0.5839700698852539, -0.8157215118408203], [-0.0057243462651968, -5.165881156921387], [-0.2595180571079254, -1.4758833646774292], [-0.02751345932483673, -3.6068058013916016], [-0.08591652661561966, -2.4970293045043945], [-0.17901045083999634, -1.808481216430664], [-0.382173627614975, -1.1468888521194458], [-0.10108640789985657, -2.341897487640381], [-0.15193478763103485, -1.959309458732605], [-0.20492875576019287, -1.6858081817626953], [-0.026762360706925392, -3.6341092586517334], [-0.1468254178762436, -1.9910260438919067], [-0.03659508749842644, -3.3260834217071533], [-0.40708431601524353, -1.095381736755371], [-0.06767028570175171, -2.7267520427703857], [-0.7615550756454468, -0.6291208267211914], [-0.3265976309776306, -1.2778847217559814], [-0.02670862339437008, -3.6360933780670166], [-0.15087883174419403, -1.9657695293426514], [-0.4889325499534607, -0.9500561356544495], [-0.006746135652065277, -5.002159118652344], [-0.12354408949613571, -2.1522932052612305], [-0.061693623661994934, -2.8162636756896973], [-0.0582185834646225, -2.8725194931030273], [-0.2811437249183655, -1.4061698913574219], [-0.6508901119232178, -0.7372691631317139], [-1.275577425956726, -0.3274902105331421], [-0.16239838302135468, -1.8978030681610107], [-0.5920217633247375, -0.8056614398956299], [-0.6852414608001709, -0.7011159062385559], [-0.09496324509382248, -2.4013707637786865], [-0.15249745547771454, -1.9558874368667603], [-0.015896378085017204, -4.149599552154541], [-0.6850415468215942, -0.7013189792633057], [-0.37165236473083496, -1.169873833656311], [-0.12027495354413986, -2.1775100231170654], [-0.2152261734008789, -1.6417498588562012], [-0.17380158603191376, -1.835483193397522], [-0.8406789302825928, -0.5646088719367981], [-0.671896755695343, -0.7148590683937073], [-0.049307581037282944, -3.034230947494507], [-0.24633093178272247, -1.5217177867889404], [-0.08556388318538666, -2.500969171524048], [-0.006063873879611492, -5.108443260192871], [-0.6315972208976746, -0.7587354183197021], [-0.1712210327386856, -1.849189043045044], [-0.19019736349582672, -1.7532850503921509], [-0.06526853889226913, -2.7617013454437256], [-0.380270779132843, -1.150989055633545], [-0.4257509112358093, -1.0592350959777832], [-0.6776952743530273, -0.7088415622711182], [-0.8451629877090454, -0.5612200498580933], [-2.170217514038086, -0.12121080607175827], [-0.2433045655488968, -1.5326282978057861], [-0.4561986029148102, -1.0042697191238403], [-2.0497567653656006, -0.1378449648618698], [-0.4938361644744873, -0.942328691482544], [-0.7929918766021729, -0.6023727059364319], [-0.04429777339100838, -3.1388871669769287], [-0.035890113562345505, -3.3451857566833496], [-0.26474228501319885, -1.4584509134292603], [-0.010821822099387646, -4.531595706939697], [-3.192967176437378, -0.04191621392965317], [-1.150773286819458, -0.3803706765174866], [-0.08089012652635574, -2.554835796356201], [-0.1912727802991867, -1.748166799545288], [-0.8626083731651306, -0.5482847094535828], [-0.05730965733528137, -2.8878049850463867], [-0.3593361973762512, -1.1977908611297607], [-0.12047702819108963, -2.1759297847747803], [-0.21779173612594604, -1.631136178970337], [-1.0984617471694946, -0.40554043650627136], [-0.4790341854095459, -0.9659572243690491], [-0.03980806842446327, -3.2435224056243896], [-0.03486798703670502, -3.3735692501068115], [-0.22566474974155426, -1.5994163751602173], [-0.7505393028259277, -0.638870894908905], [-0.07506684213876724, -2.6266753673553467], [-0.037981048226356506, -3.289597749710083], [-0.3861015737056732, -1.1385018825531006], [-0.9386223554611206, -0.4962102770805359], [-0.11191388964653015, -2.2454609870910645], [-0.021733686327934265, -3.8397390842437744], [-0.8335185647010803, -0.5700762271881104], [-0.3056299090385437, -1.334306240081787], [-0.13271187245845795, -2.0851972103118896], [-0.5862499475479126, -0.8128544092178345], [-0.2434786707162857, -1.5319961309432983], [-0.050902433693408966, -3.0031886100769043], [-0.264678418636322, -1.4586617946624756], [-0.21034282445907593, -1.6623454093933105], [-0.32529956102371216, -1.281253457069397], [-0.16349762678146362, -1.8915917873382568], [-0.4696846306324005, -0.9813610315322876], [-0.16792647540569305, -1.867017149925232], [-0.08937714248895645, -2.4592463970184326], [-0.04356386139988899, -3.1552295684814453], [-0.027630122378468513, -3.6026298999786377], [-0.06048111245036125, -2.835512161254883], [-0.05707233399152756, -2.8918354511260986], [-0.617017388343811, -0.775553822517395], [-0.07831297069787979, -2.585942268371582], [-0.0449100024998188, -3.1254653930664062], [-0.46343672275543213, -0.9918709993362427], [-0.4958813190460205, -0.9391345977783203], [-0.1942044347524643, -1.734375238418579], [-0.707303524017334, -0.6791884303092957], [-0.16696880757808685, -1.872271180152893], [-0.04969501867890358, -3.026594638824463], [-0.008312981575727463, -4.794090747833252], [-0.49525266885757446, -0.9401144981384277], [-0.057565946131944656, -2.8834688663482666], [-0.14468948543071747, -2.004638433456421], [-0.48024702072143555, -0.9639866352081299], [-0.2635449767112732, -1.4624111652374268], [-0.41958558559417725, -1.070955753326416], [-0.49225056171417236, -0.9448168277740479], [-0.8615478873252869, -0.5490599274635315], [-0.18574963510036469, -1.774793267250061], [-0.009237290360033512, -4.6891279220581055], [-0.1930949091911316, -1.7395679950714111], [-0.646575391292572, -0.7419943809509277], [-0.0635920912027359, -2.7868945598602295], [-0.44962936639785767, -1.0157368183135986], [-0.1675802320241928, -1.868913173675537], [-0.8408963680267334, -0.5644440054893494], [-0.03280963376164436, -3.4333930015563965], [-0.5993808507919312, -0.7966240644454956], [-1.106288194656372, -0.4016490876674652], [-0.45223456621170044, -1.0111644268035889], [-0.1034565269947052, -2.319885730743408], [-0.2105923891067505, -1.661279559135437], [-1.9976134300231934, -0.1457875370979309], [-0.12105851620435715, -2.1713998317718506], [-0.48305171728134155, -0.959453821182251], [-0.3665566146373749, -1.1812883615493774], [-0.4284909963607788, -1.0540926456451416], [-0.22660207748413086, -1.5957224369049072], [-1.1606191396713257, -0.375846266746521], [-0.6039662957191467, -0.7910669445991516], [-0.003303548786789179, -5.714417457580566], [-0.004342768341302872, -5.441422939300537], [-0.2846744954586029, -1.3953715562820435], [-0.06637843698263168, -2.7453885078430176], [-0.8905826807022095, -0.5283389687538147], [-0.2879956066608429, -1.3853543996810913], [-0.07384852319955826, -2.6424367427825928], [-0.6323797702789307, -0.7578476667404175], [-0.3622395396232605, -1.191107988357544], [-0.09408549964427948, -2.4102256298065186], [-0.14781120419502258, -1.9848147630691528], [-2.3712270259857178, -0.09801648557186127], [-0.12129168957471848, -2.1695899963378906], [-0.33916833996772766, -1.2460544109344482], [-0.19179022312164307, -1.7457159757614136], [-0.5924389362335205, -0.8051451444625854], [-3.7472434043884277, -0.023865224793553352], [-0.08611680567264557, -2.494800090789795], [-0.11340021342039108, -2.2329959869384766], [-0.16993646323680878, -1.8560960292816162], [-0.0246130358427763, -3.716761350631714], [-0.0902431309223175, -2.4500300884246826], [-0.41577085852622986, -1.078313946723938], [-1.112776756286621, -0.398457407951355], [-0.18620583415031433, -1.772560954093933], [-0.34448522329330444, -1.2330069541931152], [-0.04303827881813049, -3.167107582092285], [-2.209873914718628, -0.1162131130695343], [-0.34420135617256165, -1.233697533607483], [-0.004021771717816591, -5.518033981323242], [-0.3585946559906006, -1.1995078325271606], [-1.366197943687439, -0.29447153210639954], [-0.27489298582077026, -1.425673246383667], [-0.24350997805595398, -1.5318830013275146], [-0.22521403431892395, -1.601198673248291], [-0.18982689082622528, -1.7550550699234009], [-0.17109446227550507, -1.8498668670654297], [-0.08492075651884079, -2.5081965923309326], [-0.0636976808309555, -2.7852871417999268], [-0.38469767570495605, -1.141487717628479], [-0.0798049196600914, -2.567807674407959], [-0.022543933242559433, -3.8035409450531006], [-0.2813619375228882, -1.4054981470108032], [-0.50196772813797, -0.9297264218330383], [-0.012210028246045113, -4.411600589752197], [-0.20713940262794495, -1.6761459112167358], [-0.15782500803470612, -1.9241433143615723], [-0.10725851356983185, -2.285663604736328], [-0.01902347058057785, -3.9715795516967773], [-0.1292492002248764, -2.109941244125366], [-0.7217340469360352, -0.6653549671173096], [-0.3413708508014679, -1.2406206130981445], [-0.4876915514469147, -0.9520273208618164], [-0.2091609388589859, -1.6674097776412964], [-0.4266733229160309, -1.0574994087219238], [-1.0584261417388916, -0.4261804521083832], [-0.02361680194735527, -3.757582902908325], [-0.16670799255371094, -1.8737075328826904], [-0.10277296602725983, -2.326179265975952], [-0.3043604791164398, -1.3378657102584839], [-0.010320155881345272, -4.5788092613220215], [-0.004342768341302872, -5.441422939300537], [-0.3621757924556732, -1.1912540197372437], [-0.576240599155426, -0.8255528807640076], [-0.004342768341302872, -5.441422939300537], [-0.18905052542686462, -1.7587774991989136], [-0.6294680833816528, -0.7611587643623352], [-0.01540406048297882, -4.180819511413574], [-0.12662413716316223, -2.129175901412964], [-0.09481709450483322, -2.4028398990631104], [-0.5798710584640503, -0.8209136724472046], [-0.40006178617477417, -1.1095073223114014], [-0.6902235746383667, -0.6960793733596802], [-0.4307710826396942, -1.0498442649841309], [-0.311722993850708, -1.3174563646316528], [-0.4540301561355591, -1.008032202720642], [-0.33447951078414917, -1.2577621936798096], [-0.11245797574520111, -2.240877866744995], [-0.2815161347389221, -1.4050233364105225], [-0.2523849308490753, -1.5003395080566406], [-0.3264610469341278, -1.2782384157180786], [-1.2768590450286865, -0.3269939720630646], [-0.37681111693382263, -1.1585074663162231], [-4.613196849822998, -0.009969559498131275], [-0.0037882011383771896, -5.5777692794799805], [-0.19214805960655212, -1.7440249919891357], [-0.5807732343673706, -0.8197668790817261], [-0.016841605305671692, -4.092309951782227], [-0.3677549660205841, -1.1785870790481567], [-0.0037935450673103333, -5.5763468742370605], [-0.0866401270031929, -2.488999128341675], [-0.6765815615653992, -0.7099918127059937], [-0.1580214649438858, -1.9229950904846191], [-0.21564336121082306, -1.6400141716003418], [-0.06963583827018738, -2.6990914344787598], [-0.2967924475669861, -1.3594510555267334], [-0.13883477449417114, -2.0430848598480225], [-0.07569003105163574, -2.618715286254883], [-0.45305734872817993, -1.0097272396087646], [-0.09973563253879547, -2.3546857833862305], [-0.29082241654396057, -1.3769320249557495], [-0.6211915016174316, -0.7706845998764038], [-0.18443086743354797, -1.7812790870666504], [-0.04106969013810158, -3.2129509449005127], [-0.35418975353240967, -1.2097957134246826], [-2.8385860919952393, -0.06028977036476135], [-0.2385174036026001, -1.5502021312713623], [-0.11038083583116531, -2.2585012912750244], [-0.07338558882474899, -2.648496150970459], [-0.5599507093429565, -0.8468515276908875], [-0.5062556862831116, -0.9231850504875183], [-0.2222781926393509, -1.6129071712493896], [-0.25662723183631897, -1.4857019186019897], [-0.020428963005542755, -3.9009974002838135], [-0.9090162515640259, -0.515704870223999], [-0.03199877589941025, -3.4580130577087402], [-0.720458447933197, -0.6665619611740112], [-0.13248342275619507, -2.086808204650879], [-0.21014080941677094, -1.6632086038589478], [-0.09696096926927567, -2.381535530090332], [-0.46977511048316956, -0.9812102317810059], [-0.013629119843244553, -4.302350997924805], [-0.04338512197136879, -3.1592531204223633], [-0.3421037793159485, -1.238821268081665], [-0.2135234922170639, -1.6488710641860962], [-0.21439655125141144, -1.6452115774154663], [-0.2294529527425766, -1.5845907926559448], [-0.36325961351394653, -1.1887750625610352], [-0.42689061164855957, -1.057091236114502], [-1.2893502712249756, -0.3222040832042694], [-0.03206908702850342, -3.455854892730713], [-0.2664306163787842, -1.452900767326355], [-0.14550970494747162, -1.9993855953216553], [-0.053026232868433, -2.963364601135254], [-0.1525820940732956, -1.955373764038086], [-0.8301911354064941, -0.5726407766342163], [-0.10055453330278397, -2.3469104766845703], [-0.0349557064473629, -3.3711016178131104], [-0.013347674161195755, -4.323078155517578], [-0.39670950174331665, -1.1163568496704102], [-0.17195013165473938, -1.8452941179275513], [-1.26943039894104, -0.3298822045326233], [-0.27143532037734985, -1.4366810321807861], [-0.899391770362854, -0.5222524404525757], [-0.14505600929260254, -2.002286434173584], [-0.24757440388202667, -1.517278790473938], [-1.8330703973770142, -0.17426034808158875], [-0.49398714303970337, -0.9420923590660095], [-0.04901125654578209, -3.040111541748047], [-0.055338989943265915, -2.9218194484710693], [-0.14641566574573517, -1.9936201572418213], [-2.6005754470825195, -0.07713038474321365], [-0.34249159693717957, -1.2378712892532349], [-0.27944204211235046, -1.4114298820495605], [-0.4401296377182007, -1.0326921939849854], [-0.6852299571037292, -0.7011276483535767], [-0.7914904952049255, -0.6036151647567749], [-0.00439475430175662, -5.429532527923584], [-0.5002745985984802, -0.932328999042511], [-0.16981495916843414, -1.8567523956298828], [-0.1461898237466812, -1.9950541257858276], [-0.6489906311035156, -0.7393439412117004], [-0.2394377887248993, -1.546792984008789], [-0.3365060091018677, -1.252678632736206], [-2.7355051040649414, -0.06706035137176514], [-0.41113418340682983, -1.087369680404663], [-0.13206003606319427, -2.0898022651672363], [-0.03986099362373352, -3.2422215938568115], [-2.188636302947998, -0.11886180192232132], [-0.009078415110707283, -4.706396579742432], [-0.011534903198480606, -4.468143463134766], [-0.06498293578624725, -2.7659451961517334], [-0.22562812268733978, -1.5995607376098633], [-0.16314640641212463, -1.8935714960098267], [-0.7518603801727295, -0.6376909017562866], [-0.31581810116767883, -1.3063453435897827], [-0.43711352348327637, -1.038170576095581], [-0.07565179467201233, -2.619201898574829], [-0.20747850835323334, -1.6746735572814941], [-0.386271208524704, -1.1381417512893677], [-0.14570634067058563, -1.998130440711975], [-0.45382213592529297, -1.0083942413330078], [-0.19192533195018768, -1.745077133178711], [-0.4153960049152374, -1.0790414810180664], [-0.4382309019565582, -1.0361356735229492], [-0.544108510017395, -0.8683556914329529], [-0.004613114055246115, -5.381162643432617], [-0.07274344563484192, -2.656968116760254], [-0.007579734083265066, -4.8860697746276855], [-0.1833970844745636, -1.7863991260528564], [-0.7871220111846924, -0.6072499752044678], [-0.010413124226033688, -4.569894790649414], [-0.23566007614135742, -1.560882329940796], [-0.02595703676342964, -3.6642637252807617], [-0.3190496861934662, -1.2976957559585571], [-1.3764475584030151, -0.290986031293869], [-1.2343621253967285, -0.3439284861087799], [-0.3000299036502838, -1.3501402139663696], [-0.23715031147003174, -1.555294156074524], [-0.0435858853161335, -3.1547350883483887], [-0.24318912625312805, -1.5330474376678467], [-1.899430751800537, -0.16211175918579102], [-0.01903984509408474, -3.97072696685791], [-0.5061705708503723, -0.9233143329620361], [-0.09670679271221161, -2.384035110473633], [-0.001928376266732812, -6.252023696899414], [-1.0274816751480103, -0.44302234053611755], [-0.36496224999427795, -1.1848987340927124], [-0.013985371217131615, -4.276730537414551], [-0.1646554172039032, -1.8850985765457153], [-0.046670034527778625, -3.087897539138794], [-0.05818900465965271, -2.873011589050293], [-0.03396949917078018, -3.3992292881011963], [-0.609594464302063, -0.7843226194381714], [-0.019326593726873398, -3.9559237957000732], [-1.6118717193603516, -0.22253596782684326], [-0.222004696726799, -1.614006519317627], [-0.20273132622241974, -1.69552743434906], [-0.05286138877272606, -2.966395854949951], [-0.4409615099430084, -1.0311896800994873], [-0.4899859130382538, -0.9483879804611206], [-2.0687315464019775, -0.1350707858800888], [-0.4767177999019623, -0.969738245010376], [-0.011054699309170246, -4.510417461395264], [-0.1727922409772873, -1.8408174514770508], [-0.1062903180718422, -2.294255018234253], [-0.0608060285449028, -2.8303158283233643], [-0.2661755084991455, -1.453736662864685], [-0.1118568629026413, -2.2459425926208496], [-1.1077557802200317, -0.4009244740009308], [-0.2364397794008255, -1.5579533576965332], [-0.12469611316919327, -2.14357590675354], [-0.6457703709602356, -0.7428805828094482], [-0.11093290895223618, -2.2537829875946045], [-0.1878972351551056, -1.7643380165100098], [-0.15858274698257446, -1.919722557067871], [-0.025098515674471855, -3.697469472885132], [-0.07545526325702667, -2.621706008911133], [-0.6382800340652466, -0.751200258731842], [-0.1785227358341217, -1.8109732866287231], [-0.12443425506353378, -2.1455495357513428], [-0.10402435809373856, -2.3146915435791016], [-0.034263975918293, -3.390742540359497], [-0.1622656136751175, -1.8985569477081299], [-0.3487371504306793, -1.2227429151535034], [-0.02399977296590805, -3.7416880130767822], [-0.3355817496776581, -1.2549926042556763], [-0.38243943452835083, -1.1463178396224976], [-0.4016326665878296, -1.1063215732574463], [-0.10136242210865021, -2.339305877685547], [-0.0071842665784060955, -4.939449310302734], [-0.042272813618183136, -3.1846725940704346], [-0.10446741431951523, -2.310659170150757], [-0.03525139391422272, -3.3628246784210205], [-0.026064125820994377, -3.6601974964141846], [-0.229331836104393, -1.585060715675354], [-1.5321898460388184, -0.2434253990650177], [-0.5399373769760132, -0.8741531372070312], [-0.08129256218671799, -2.550072193145752], [-0.0015905360924080014, -6.444482803344727], [-0.05964432656764984, -2.849029541015625], [-0.0634290874004364, -2.7893788814544678], [-0.06513886898756027, -2.763627052307129], [-0.5556563138961792, -0.8526016473770142], [-0.3409639000892639, -1.241621494293213], [-0.05010124295949936, -3.0186562538146973], [-0.19344176352024078, -1.7379406690597534], [-0.18562786281108856, -1.7753900289535522], [-0.13458815217018127, -2.072075843811035], [-0.002452106447890401, -6.012056350708008], [-0.2976834177970886, -1.3568768501281738], [-0.18426035344600677, -1.7821216583251953], [-0.03969934582710266, -3.2462031841278076], [-0.2099674642086029, -1.6639503240585327], [-0.3415272533893585, -1.2402360439300537], [-0.12269213795661926, -2.1587963104248047], [-0.4217170774936676, -1.0668798685073853], [-0.08914840221405029, -2.4616951942443848], [-0.7534317970275879, -0.6362911462783813], [-0.15623068809509277, -1.9335200786590576], [-0.21503053605556488, -1.6425645351409912], [-0.20934690535068512, -1.666610836982727], [-0.18076162040233612, -1.799595832824707], [-0.07097379118204117, -2.6807217597961426], [-0.6908076405525208, -0.6954922080039978], [-0.18168750405311584, -1.794935941696167], [-0.4227132201194763, -1.064983606338501], [-1.6813673973083496, -0.20594149827957153], [-0.03757411986589432, -3.300168514251709], [-0.18687474727630615, -1.7692996263504028], [-0.259020060300827, -1.4775657653808594], [-0.014797925017774105, -4.220659255981445], [-1.1484383344650269, -0.38145312666893005], [-0.08044276386499405, -2.5601603984832764], [-0.16523431241512299, -1.8818703889846802], [-0.4094105362892151, -1.090767741203308], [-0.014408357441425323, -4.247146129608154], [-0.05038148909807205, -3.013216257095337], [-0.5684635639190674, -0.8356212377548218], [-0.12543553113937378, -2.1380255222320557], [-0.38242194056510925, -1.1463555097579956], [-0.02584877423942089, -3.668386936187744], [-0.6134744882583618, -0.7797214984893799], [-0.23807770013809204, -1.5518367290496826], [-0.03666231408715248, -3.324281930923462], [-0.043274275958538055, -3.1617560386657715], [-0.4628368616104126, -0.9928891658782959], [-0.30923381447792053, -1.3242932558059692], [-0.18852217495441437, -1.7613204717636108], [-0.0017723818309605122, -6.336340427398682], [-0.30185940861701965, -1.344929814338684], [-0.04821309447288513, -3.0561344623565674], [-0.12976111471652985, -2.1062393188476562], [-0.3607773780822754, -1.1944655179977417], [-0.21571052074432373, -1.6397351026535034], [-0.640884518623352, -0.7482925653457642], [-0.11257046461105347, -2.2399332523345947], [-0.5765877962112427, -0.8251075744628906], [-1.0194059610366821, -0.44755232334136963], [-0.20865628123283386, -1.6695817708969116], [-0.1828841120004654, -1.7889517545700073], [-0.316535085439682, -1.304417371749878], [-0.6282287240028381, -0.7625744938850403], [-1.0702775716781616, -0.4199393093585968], [-0.2848384976387024, -1.394874095916748], [-0.45409250259399414, -1.0079237222671509], [-0.7275614142417908, -0.6598780751228333], [-0.6201916337013245, -0.771847128868103], [-0.2011970430612564, -1.7023831605911255], [-0.437442421913147, -1.0375709533691406], [-0.28218674659729004, -1.4029637575149536], [-0.14177007973194122, -2.0235962867736816], [-0.09708625078201294, -2.3803064823150635], [-0.24525567889213562, -1.5255768299102783], [-0.05820261314511299, -2.8727855682373047], [-0.23560865223407745, -1.5610756874084473], [-0.1109914779663086, -2.253284454345703], [-0.01976637728512287, -3.933640480041504], [-0.4895985722541809, -0.949000895023346], [-1.7707983255386353, -0.1865670531988144], [-0.602519154548645, -0.7928148508071899], [-0.18588823080062866, -1.7741143703460693], [-1.2909616231918335, -0.3215921223163605], [-0.4940885901451111, -0.9419335126876831], [-0.16697798669338226, -1.8722211122512817], [-0.14412984251976013, -2.0082404613494873], [-2.2228381633758545, -0.11462701112031937], [-0.1269674152135849, -2.1266367435455322], [-0.15384835004806519, -1.947725772857666], [-0.09834521263837814, -2.3680410385131836], [-0.03469090908765793, -3.378573417663574], [-0.28435876965522766, -1.3963308334350586], [-0.17495881021022797, -1.8294092416763306], [-0.022457914426922798, -3.807318925857544], [-0.2339453548192978, -1.5673608779907227], [-0.6395827531814575, -0.7497440576553345], [-0.4396856129169464, -1.0334957838058472], [-0.4040820300579071, -1.101384162902832], [-0.08419634401798248, -2.516406536102295], [-0.07799965143203735, -2.5897974967956543], [-1.0614897012710571, -0.42455625534057617], [-0.42978760600090027, -1.051673173904419], [-0.3276331424713135, -1.2752087116241455], [-0.471381276845932, -0.9785372018814087], [-0.16615206003189087, -1.8767781257629395], [-0.23812128603458405, -1.551674485206604], [-0.30813366174697876, -1.3273355960845947], [-0.08416324853897095, -2.5167839527130127], [-0.09880256652832031, -2.3636257648468018], [-0.3201865255832672, -1.2946767807006836], [-0.08108977228403091, -2.55246901512146], [-0.11094453930854797, -2.2536838054656982], [-0.8372812271118164, -0.5671946406364441], [-0.1455904096364975, -1.9988703727722168], [-0.39849525690078735, -1.1126995086669922], [-0.20571589469909668, -1.6823543310165405], [-0.012418446131050587, -4.394774913787842], [-0.12437762320041656, -2.145977735519409], [-0.08257703483104706, -2.5350282192230225], [-0.20876580476760864, -1.669109582901001], [-0.06769345700740814, -2.7264208793640137], [-0.09794266521930695, -2.3719451427459717], [-0.024805977940559387, -3.7090463638305664], [-0.35057178139686584, -1.2183600664138794], [-0.011810851283371449, -4.44463586807251], [-0.12851333618164062, -2.115291118621826], [-0.7291555404663086, -0.6583905816078186], [-0.6670334935188293, -0.7199609875679016], [-0.3044842779636383, -1.3375178575515747], [-0.1385354846715927, -2.0450968742370605], [-0.1911756992340088, -1.748627781867981], [-0.0012642494402825832, -6.673879623413086], [-0.2634471654891968, -1.4627360105514526], [-0.46652692556381226, -0.9866507649421692], [-1.3561967611312866, -0.297919362783432], [-2.526076555252075, -0.08335132151842117], [-0.808611273765564, -0.5896456837654114], [-0.26622045040130615, -1.4535894393920898], [-0.005503028631210327, -5.205196380615234], [-0.04154118895530701, -3.2017672061920166], [-0.7729101777076721, -0.6192789673805237], [-0.38671863079071045, -1.1371935606002808], [-0.044076960533857346, -3.1437768936157227], [-0.2109392136335373, -1.6598013639450073], [-0.807316780090332, -0.5906869173049927], [-0.5147379040718079, -0.9104509353637695], [-1.033377766609192, -0.43975090980529785], [-0.31865033507347107, -1.298758864402771], [-0.1108875647187233, -2.2541699409484863], [-0.5643562078475952, -0.8410120010375977], [-0.2018062174320221, -1.6996543407440186], [-0.26225537061691284, -1.4667000770568848], [-1.9563926458358765, -0.1524142324924469], [-0.0006286313873715699, -7.372361660003662], [-0.2372361719608307, -1.5549732446670532], [-0.16243891417980194, -1.897573709487915], [-0.032802943140268326, -3.4335954189300537], [-0.19722715020179749, -1.7203925848007202], [-0.4649829864501953, -0.9892534017562866], [-0.2169121354818344, -1.6347594261169434], [-0.424355149269104, -1.0618700981140137], [-0.30831077694892883, -1.3268449306488037], [-0.44665035605430603, -1.021005630493164], [-0.21940657496452332, -1.6245273351669312], [-0.06426338851451874, -2.776724100112915], [-0.1840389221906662, -1.7832163572311401], [-0.26765722036361694, -1.4488937854766846], [-0.15180206298828125, -1.9601192474365234], [-0.36424124240875244, -1.186537742614746], [-0.08403874933719635, -2.5182018280029297], [-0.17406043410301208, -1.8341208696365356], [-0.05486255884170532, -2.930229663848877], [-0.24227948486804962, -1.53635835647583], [-0.0037258509546518326, -5.594333648681641], [-0.04852066934108734, -3.049928665161133], [-0.37464913725852966, -1.1632484197616577], [-2.461306095123291, -0.0891847088932991], [-0.27074190974235535, -1.4389076232910156], [-0.2889701724052429, -1.3824400901794434], [-0.4768596589565277, -0.9695060849189758], [-0.4775155186653137, -0.9684335589408875], [-0.48847270011901855, -0.9507856965065002], [-0.2932673692703247, -1.3697233200073242], [-0.4605090618133545, -0.9968567490577698], [-0.3371306359767914, -1.2511191368103027], [-0.8652815818786621, -0.5463371276855469], [-0.36190372705459595, -1.1918776035308838], [-0.35322368144989014, -1.2120723724365234], [-1.3488364219665527, -0.3004865348339081], [-0.2444627583026886, -1.5284347534179688], [-4.094097137451172, -0.01681136153638363], [-0.04781723767518997, -3.064181327819824], [-0.40185633301734924, -1.1058690547943115], [-0.11396615207195282, -2.2282960414886475], [-0.038199424743652344, -3.28397274017334], [-0.6430379748344421, -0.7459003925323486], [-0.2525639533996582, -1.4997165203094482], [-0.6159460544586182, -0.7768106460571289], [-0.018346143886446953, -4.0074968338012695], [-0.1199350655078888, -2.1801726818084717], [-0.012696504592895508, -4.372772216796875], [-0.38005998730659485, -1.1514447927474976], [-0.5835487842559814, -0.8162528872489929], [-0.24228210747241974, -1.536348819732666], [-0.26061710715293884, -1.4721828699111938], [-0.23751485347747803, -1.553933024406433], [-0.30153295397758484, -1.3458569049835205], [-0.006077500060200691, -5.1061930656433105], [-0.041296087205410004, -3.2075653076171875], [-0.049182865768671036, -3.0366997718811035], [-0.2623875141143799, -1.466259479522705], [-0.3633730113506317, -1.1885162591934204], [-0.026972178369760513, -3.626403331756592], [-0.01854720152914524, -3.996694326400757], [-0.11073742806911469, -2.255451202392578], [-0.20188863575458527, -1.6992855072021484], [-0.01575029268860817, -4.158759593963623], [-0.2765856087207794, -1.4203420877456665], [-0.3123597800731659, -1.3157174587249756], [-0.020518425852060318, -3.8966729640960693], [-0.036671970039606094, -3.324021816253662], [-0.27476394176483154, -1.4260812997817993], [-0.019552823156118393, -3.9443931579589844], [-0.523317813873291, -0.8978403806686401], [-0.405690461397171, -1.0981615781784058], [-0.274599552154541, -1.426601529121399], [-0.16859574615955353, -1.8633655309677124], [-0.0310153067111969, -3.488741874694824], [-0.2240922898054123, -1.60565185546875], [-0.06027428060770035, -2.8388350009918213], [-1.6619547605514526, -0.21043428778648376], [-0.3973623812198639, -1.115017294883728], [-0.2240869551897049, -1.60567307472229], [-0.018787411972880363, -3.983945846557617], [-0.22950658202171326, -1.5843833684921265], [-0.1318208873271942, -2.0914971828460693], [-0.39617934823036194, -1.1174464225769043], [-0.21651802957057953, -1.6363877058029175], [-0.18000924587249756, -1.803402066230774], [-0.16239838302135468, -1.8978030681610107], [-0.045095305889844894, -3.121441125869751], [-0.05959513410925865, -2.8498313426971436], [-0.26597607135772705, -1.4543910026550293], [-0.3058739900588989, -1.3336238861083984], [-0.47858908772468567, -0.966681957244873], [-0.5956352949142456, -0.8012052774429321], [-0.05049154534935951, -3.0110881328582764], [-0.16523663699626923, -1.8818578720092773], [-0.0574718602001667, -2.885057210922241], [-0.4840657114982605, -0.9578231573104858], [-0.2787787914276123, -1.4134900569915771], [-0.1475207805633545, -1.986640214920044], [-0.13649533689022064, -2.0589358806610107], [-0.26649409532546997, -1.4526927471160889], [-0.8649060726165771, -0.5466101169586182], [-0.03600085899233818, -3.342158079147339], [-0.138638436794281, -2.0444042682647705], [-0.030877193436026573, -3.4931344985961914], [-0.2885885536670685, -1.3835797309875488], [-1.0550847053527832, -0.4279605448246002], [-0.06538534164428711, -2.7599709033966064], [-0.799545407295227, -0.59698885679245], [-0.21749216318130493, -1.6323683261871338], [-1.6078903675079346, -0.22353076934814453], [-0.885115385055542, -0.5321626663208008], [-0.1795521080493927, -1.8057231903076172], [-0.17785599827766418, -1.8143911361694336], [-0.24490386247634888, -1.526843547821045], [-0.3802436292171478, -1.151047945022583], [-0.06448335945606232, -2.7734169960021973], [-0.3027384877204895, -1.3424391746520996], [-0.5184263586997986, -0.9049968719482422], [-0.1377791166305542, -2.0502023696899414], [-0.0770580992102623, -2.6014771461486816], [-0.006318473257124424, -5.067429065704346], [-0.4664241671562195, -0.9868236780166626], [-0.10703382641077042, -2.2876501083374023], [-0.6575453877449036, -0.7300633788108826], [-0.016940532252192497, -4.086503505706787], [-0.2682693600654602, -1.446901559829712], [-0.005558392032980919, -5.195230960845947], [-0.013808907009661198, -4.289341449737549], [-0.024059126153588295, -3.7392451763153076], [-0.24933969974517822, -1.5110199451446533], [-0.2081684023141861, -1.6716874837875366], [-0.4381425976753235, -1.0362963676452637], [-0.074700728058815, -2.6313834190368652], [-0.27293628454208374, -1.4318828582763672], [-0.0499674417078495, -3.0212645530700684], [-0.9661019444465637, -0.4789453148841858], [-0.18870550394058228, -1.76043701171875], [-0.7606480121612549, -0.6299160122871399], [-0.2494811713695526, -1.5105204582214355], [-0.05010883882641792, -3.018507957458496], [-0.09406878799200058, -2.4103944301605225], [-0.20297560095787048, -1.6944410800933838], [-0.2770473062992096, -1.4188945293426514], [-0.3445528745651245, -1.2328425645828247], [-0.35537686944007874, -1.2070082426071167], [-0.13847778737545013, -2.045485496520996], [-1.6049913167953491, -0.22425834834575653], [-0.8969073295593262, -0.5239598155021667], [-0.18464170396327972, -1.7802391052246094], [-0.09154205769300461, -2.4363789558410645], [-0.11948399990797043, -2.1837196350097656], [-0.5260013937950134, -0.8939504623413086], [-0.01628689095377922, -4.125524520874023], [-0.3678475618362427, -1.1783788204193115], [-0.0619717612862587, -2.811901569366455], [-0.19582033157348633, -1.7268710136413574], [-0.18077674508094788, -1.799519658088684], [-0.32695770263671875, -1.276953101158142], [-0.008951887488365173, -4.720367908477783], [-0.21041081845760345, -1.6620545387268066], [-0.08747877925634384, -2.4797794818878174], [-0.33692365884780884, -1.2516353130340576], [-0.08165550231933594, -2.5457966327667236], [-0.07249844819307327, -2.6602206230163574], [-0.23973076045513153, -1.5457109212875366], [-0.05964432656764984, -2.849029541015625], [-0.08705784380435944, -2.4843955039978027], [-1.73004949092865, -0.1951340287923813], [-0.5147765874862671, -0.9103934168815613], [-0.05948101729154587, -2.8516910076141357], [-0.34488940238952637, -1.2320247888565063], [-0.400206983089447, -1.1092123985290527], [-0.5945941209793091, -0.8024857044219971], [-0.3006189465522766, -1.3484585285186768], [-0.002397878561168909, -6.034350872039795], [-0.06615385413169861, -2.7486674785614014], [-0.6688379645347595, -0.7180622220039368], [-0.4295448660850525, -1.0521254539489746], [-0.9837832450866699, -0.4682353138923645], [-0.44049128890037537, -1.0320385694503784], [-0.3612450659275055, -1.193389654159546], [-0.10044391453266144, -2.347956895828247], [-0.2726324796676636, -1.4328516721725464], [-0.05656157806515694, -2.9005727767944336], [-0.246102973818779, -1.5225344896316528], [-0.27142295241355896, -1.4367204904556274], [-0.1414913386106491, -2.025428056716919], [-0.004342768341302872, -5.441422939300537], [-0.019979069009423256, -3.9230406284332275], [-0.24926704168319702, -1.5112767219543457], [-0.6297957301139832, -0.7607852220535278], [-0.44298407435417175, -1.027550458908081], [-0.11653930693864822, -2.2072300910949707], [-0.5444943308830261, -0.8678221702575684], [-0.05854277312755585, -2.86712646484375], [-0.30040186643600464, -1.3490777015686035], [-0.02388361655175686, -3.746478319168091], [-0.029065264388918877, -3.5527093410491943], [-0.16252434253692627, -1.8970892429351807], [-0.388569176197052, -1.1332852840423584], [-0.5048115849494934, -0.9253802299499512], [-1.2082905769348145, -0.3548301160335541], [-0.18298457562923431, -1.788450837135315], [-0.030418217182159424, -3.507883310317993], [-0.16159555315971375, -1.9023687839508057], [-0.8482146859169006, -0.5589286088943481], [-0.28432953357696533, -1.3964200019836426], [-0.2220393568277359, -1.613867163658142], [-0.24851690232753754, -1.5139309167861938], [-0.17571160197257996, -1.8254811763763428], [-0.5314970016479492, -0.8860634565353394], [-0.08745966106653214, -2.4799890518188477], [-0.04232240840792656, -3.1835248470306396], [-0.04372796416282654, -3.1515514850616455], [-0.20943942666053772, -1.6662136316299438], [-0.08153124153614044, -2.5472583770751953], [-1.024173617362976, -0.4448711574077606], [-0.1292685717344284, -2.1098010540008545], [-0.12123995274305344, -2.1699914932250977], [-0.6225113272666931, -0.7691542506217957], [-0.045443370938301086, -3.113924980163574], [-0.14416977763175964, -2.0079824924468994], [-0.24472784996032715, -1.5274780988693237], [-0.32438021898269653, -1.2836487293243408], [-0.5133394002914429, -0.912531852722168], [-0.0009483369067311287, -6.961294651031494], [-0.339909166097641, -1.2442220449447632], [-0.0025653094053268433, -5.9669647216796875], [-0.046058882027864456, -3.1007750034332275], [-0.12638327479362488, -2.1309618949890137], [-0.3013519048690796, -1.3463714122772217], [-0.13172747194766998, -2.0921614170074463], [-0.3697361350059509, -1.1741443872451782], [-0.0806247889995575, -2.557990550994873], [-0.02960275299847126, -3.5346522331237793], [-0.06602832674980164, -2.7505042552948], [-0.05045187845826149, -3.011855363845825], [-0.1081543043255806, -2.2777862548828125], [-1.1906342506408691, -0.36244645714759827], [-0.2265978902578354, -1.5957388877868652], [-0.17951056361198425, -1.8059344291687012], [-0.23627516627311707, -1.5585707426071167], [-0.4303545653820038, -1.0506181716918945], [-0.4569104015827179, -1.0030397176742554], [-0.1334647834300995, -2.0799078941345215], [-0.09686683863401413, -2.382460594177246], [-0.32568731904029846, -1.2802454233169556], [-0.20827613770961761, -1.6712218523025513], [-0.004048723261803389, -5.511392116546631], [-0.09116723388433456, -2.4402968883514404], [-0.4845017194747925, -0.957123339176178], [-0.18779923021793365, -1.7648123502731323], [-0.9995102882385254, -0.4589602053165436], [-0.17285723984241486, -1.8404734134674072], [-0.16872112452983856, -1.8626829385757446], [-0.31895211338996887, -1.2979552745819092], [-0.02560560591518879, -3.6777191162109375], [-0.08323889225721359, -2.527371406555176], [-0.05228489637374878, -2.9770753383636475], [-0.27633851766586304, -1.4211180210113525], [-4.609929084777832, -0.010002370923757553], [-0.17798779904842377, -1.8137147426605225], [-0.004342768341302872, -5.441422939300537], [-1.6568279266357422, -0.21163886785507202], [-0.3761265277862549, -1.1600053310394287], [-0.23507626354694366, -1.563081979751587], [-1.418014407157898, -0.27732837200164795], [-0.3790224492549896, -1.153692364692688], [-0.7921946048736572, -0.6030320525169373], [-0.2328265756368637, -1.5716170072555542], [-0.15489046275615692, -1.9414825439453125], [-0.10354359447956085, -2.3190879821777344], [-0.23534442484378815, -1.5620707273483276], [-0.09171239286661148, -2.434603214263916], [-0.06258300691843033, -2.802389144897461], [-0.6056397557258606, -0.7890529036521912], [-0.5044165253639221, -0.9259819984436035], [-0.09311336278915405, -2.420133590698242], [-0.024404818192124367, -3.7251534461975098], [-0.5646072626113892, -0.8406810760498047], [-0.1646186113357544, -1.88530433177948], [-0.6709160208702087, -0.7158839106559753], [-0.6835307478904724, -0.7028570771217346], [-0.3817179799079895, -1.1478683948516846], [-0.38507533073425293, -1.1406832933425903], [-0.1971186101436615, -1.7208906412124634], [-0.2070244550704956, -1.6766453981399536], [-0.0486486479640007, -3.0473577976226807], [-0.08829620480537415, -2.470881223678589], [-0.04073623567819595, -3.220935821533203], [-0.03321147337555885, -3.4214179515838623], [-0.37085360288619995, -1.1716508865356445], [-0.18787738680839539, -1.7644342184066772], [-0.14010414481163025, -2.0346033573150635], [-0.03375457599759102, -3.4054698944091797], [-1.6676394939422607, -0.20910745859146118], [-1.1749184131622314, -0.36938998103141785], [-0.06855147331953049, -2.7142505645751953], [-0.0307081937789917, -3.498541831970215], [-0.05964432656764984, -2.849029541015625], [-0.0029850706923753023, -5.815613269805908], [-0.12783503532409668, -2.120250940322876], [-0.190623939037323, -1.751250982284546], [-0.28231313824653625, -1.402576208114624], [-0.0954044833779335, -2.3969528675079346], [-0.2884368598461151, -1.3840333223342896], [-0.22186891734600067, -1.6145528554916382], [-0.3010507822036743, -1.3472281694412231], [-0.09791889041662216, -2.372175931930542], [-0.26188331842422485, -1.4679417610168457], [-0.385261595249176, -1.140286922454834], [-0.02448241040110588, -3.7220144271850586], [-0.8475708961486816, -0.5594111680984497], [-0.15729017555713654, -1.9272773265838623], [-0.35868266224861145, -1.1993038654327393], [-0.3122939169406891, -1.315896987915039], [-0.516937255859375, -0.9071927666664124], [-0.3646751046180725, -1.1855511665344238], [-3.294300079345703, -0.037799470126628876], [-0.05909634009003639, -2.8579893112182617], [-1.5047271251678467, -0.2511288523674011], [-0.06687740236520767, -2.7381458282470703], [-0.03542664274573326, -3.3579518795013428], [-0.8998516798019409, -0.5219370126724243], [-0.39890405535697937, -1.1118650436401367], [-1.1468513011932373, -0.38219112157821655], [-0.19636520743370056, -1.7243558168411255], [-0.3403776288032532, -1.2430657148361206], [-0.5740865468978882, -0.8283236026763916], [-0.23990079760551453, -1.5450832843780518], [-0.2626829147338867, -1.4652756452560425], [-0.049381788820028305, -3.0327630043029785], [-0.2213471233844757, -1.6166558265686035], [-0.08584530651569366, -2.497823715209961], [-0.38791441917419434, -1.1346657276153564], [-0.31420189142227173, -1.3107106685638428], [-0.05354128032922745, -2.9539523124694824], [-0.6063793301582336, -0.7881652116775513], [-0.16998031735420227, -1.8558595180511475], [-0.014369932934641838, -4.2497968673706055], [-0.0045000240206718445, -5.405911445617676], [-0.29067176580429077, -1.3773787021636963], [-1.5534684658050537, -0.23763948678970337], [-0.22402864694595337, -1.605905294418335], [-0.09727900475263596, -2.378417491912842], [-0.3545437157154083, -1.2089632749557495], [-0.7765205502510071, -0.6161931157112122], [-0.033533383160829544, -3.4119346141815186], [-0.12378500401973724, -2.150463104248047], [-0.17357683181762695, -1.8366680145263672], [-0.19009917974472046, -1.753753900527954], [-1.7411736249923706, -0.19275324046611786], [-0.5701920390129089, -0.8333680629730225], [-0.7673328518867493, -0.6240869164466858], [-0.3408638536930084, -1.2418675422668457], [-1.1366875171661377, -0.38695764541625977], [-1.6516902446746826, -0.21285367012023926], [-0.7276512980461121, -0.6597939133644104], [-0.5209721326828003, -0.9012613892555237], [-0.24296177923679352, -1.5338737964630127], [-0.008288154378533363, -4.797066688537598], [-0.5965123772621155, -0.8001289367675781], [-0.39212384819984436, -1.1258410215377808], [-0.24447134137153625, -1.5284035205841064], [-0.037973932921886444, -3.2897820472717285], [-0.22965118288993835, -1.5838227272033691], [-0.5713138580322266, -0.8319103121757507], [-0.20015878975391388, -1.707054853439331], [-0.17224028706550598, -1.8437490463256836], [-0.2591201364994049, -1.4772272109985352], [-0.08654414862394333, -2.490060806274414], [-1.0368075370788574, -0.4378615915775299], [-0.23344331979751587, -1.569267988204956], [-0.7132555246353149, -0.6734352111816406], [-1.4594802856445312, -0.2644304633140564], [-0.15601623058319092, -1.9347896575927734], [-0.26827508211135864, -1.446882963180542], [-0.4489746689796448, -1.0168910026550293], [-0.02589198760688305, -3.6667420864105225], [-0.07925697416067123, -2.5744261741638184], [-0.010499713942408562, -4.56165075302124], [-0.22501938045024872, -1.6019693613052368], [-0.03384654223918915, -3.4027955532073975], [-0.24746598303318024, -1.5176645517349243], [-0.07175266742706299, -2.670191764831543], [-0.6928086876869202, -0.6934857368469238], [-0.12063891440629959, -2.1746668815612793], [-0.5207022428512573, -0.9016563296318054], [-0.7688840627670288, -0.6227448582649231], [-0.19141867756843567, -1.747475504875183], [-2.3318371772766113, -0.1021624431014061], [-0.009419876150786877, -4.669641971588135], [-0.020057355985045433, -3.9191696643829346], [-0.2781887352466583, -1.4153273105621338], [-0.18183669447898865, -1.7941876649856567], [-0.2527267336845398, -1.499150037765503], [-0.5205071568489075, -0.9019420742988586], [-0.18137890100479126, -1.7964861392974854], [-0.44764620065689087, -1.0192396640777588], [-0.0913558080792427, -2.438323736190796], [-1.2983518838882446, -0.3188030421733856], [-0.2879956066608429, -1.3853543996810913], [-0.03168792277574539, -3.467620611190796], [-0.3029276430606842, -1.3419044017791748], [-0.08079534769058228, -2.555962085723877], [-0.27734047174453735, -1.4179766178131104], [-0.023898281157016754, -3.745873212814331], [-0.09410003572702408, -2.4100780487060547], [-0.18042317032814026, -1.8013056516647339], [-0.6292396187782288, -0.7614194750785828], [-0.004551408346742392, -5.39458703994751], [-0.33554545044898987, -1.2550835609436035], [-0.8988202214241028, -0.5226445198059082], [-0.18127299845218658, -1.7970185279846191], [-2.471323013305664, -0.08825549483299255], [-0.055533312261104584, -2.918410301208496], [-0.08552207797765732, -2.501437187194824], [-0.11130882054567337, -2.2505850791931152], [-0.734862744808197, -0.6531022787094116], [-0.08868257701396942, -2.466705322265625], [-0.18555517494678497, -1.775746464729309], [-0.5947197675704956, -0.8023309707641602], [-0.034771278500556946, -3.37629771232605], [-0.4031742215156555, -1.1032098531723022], [-0.43196985125541687, -1.047621726989746], [-0.07157822698354721, -2.6725406646728516], [-0.39259031414985657, -1.1248700618743896], [-0.12580108642578125, -2.1352944374084473], [-1.6344704627990723, -0.2169821858406067], [-0.05480218306183815, -2.931300163269043], [-0.41022342443466187, -1.089163064956665], [-0.7086660861968994, -0.6778654456138611], [-0.31229260563850403, -1.3159005641937256], [-0.010440493933856487, -4.5672783851623535], [-0.20417647063732147, -1.6891224384307861], [-0.03903106972575188, -3.262849807739258], [-0.04471177980303764, -3.1297898292541504], [-0.6184053421020508, -0.7739298343658447], [-0.03998114913702011, -3.239272356033325], [-0.03827687352895737, -3.281986951828003], [-0.3172625005245209, -1.3024665117263794], [-0.056478098034858704, -2.902007579803467], [-0.22565598785877228, -1.5994510650634766], [-0.0623902752995491, -2.8053784370422363], [-0.21811585128307343, -1.6298054456710815], [-0.2766117453575134, -1.420259952545166], [-0.3183368444442749, -1.299594521522522], [-0.17831560969352722, -1.812033772468567], [-0.030216524377465248, -3.514434576034546], [-0.14560730755329132, -1.9987627267837524], [-0.12545129656791687, -2.1379072666168213], [-0.5564360618591309, -0.8515531420707703], [-0.17966267466545105, -1.8051612377166748], [-0.27789798378944397, -1.4162344932556152], [-0.8575004935264587, -0.5520316362380981], [-0.4254113733768463, -1.0598751306533813], [-0.4445686936378479, -1.0247135162353516], [-0.012572200037539005, -4.382551193237305], [-1.360431432723999, -0.2964537739753723], [-0.1897597461938858, -1.7553763389587402], [-0.25791269540786743, -1.4813203811645508], [-0.15066659450531006, -1.9670734405517578], [-0.09203482419252396, -2.4312524795532227], [-0.18175141513347626, -1.7946146726608276], [-0.001956336200237274, -6.2376790046691895], [-0.6653398275375366, -0.7217499613761902], [-0.28044593334198, -1.4083222150802612], [-1.9211993217468262, -0.15832921862602234], [-0.18432220816612244, -1.781816005706787], [-0.11629568040370941, -2.2092037200927734], [-1.0769248008728027, -0.4164879024028778], [-0.11484819650650024, -2.2210187911987305], [-0.4933537244796753, -0.9430845975875854], [-0.024622689932584763, -3.7163727283477783], [-0.3947955071926117, -1.120299220085144], [-0.1132078766822815, -2.2345995903015137], [-1.6705572605133057, -0.20843003690242767], [-0.019779467955231667, -3.9329864978790283], [-0.061944980174303055, -2.812321186065674], [-0.5000333786010742, -0.9327007532119751], [-0.07736852020025253, -2.5976102352142334], [-0.10543941706418991, -2.301874876022339], [-0.12374297529459, -2.150782585144043], [-0.027941428124904633, -3.5915825366973877], [-0.8586362600326538, -0.5511956810951233], [-0.6183597445487976, -0.7739832401275635], [-1.1123266220092773, -0.39867788553237915], [-0.5634133219718933, -0.8422567844390869], [-0.1392630934715271, -2.0402138233184814], [-0.3679216504096985, -1.1782121658325195], [-0.38044077157974243, -1.150621771812439], [-0.04987592250108719, -3.0230507850646973], [-0.04203909635543823, -3.1900999546051025], [-1.7056043148040771, -0.20048047602176666], [-0.5468884706497192, -0.864523708820343], [-0.3729366064071655, -1.1670268774032593], [-0.16239838302135468, -1.8978030681610107], [-0.043841153383255005, -3.149021625518799], [-0.07693193852901459, -2.603053569793701], [-0.44957149028778076, -1.0158387422561646], [-0.07769107818603516, -2.5936083793640137], [-0.12062697857618332, -2.1747593879699707], [-0.02808203548192978, -3.5866329669952393], [-0.14231358468532562, -2.0200350284576416], [-0.25816023349761963, -1.4804794788360596], [-0.240264892578125, -1.5437414646148682], [-0.7908523082733154, -0.6041443347930908], [-0.2140735387802124, -1.6465638875961304], [-0.0022691949270665646, -6.089488506317139], [-0.1834964156150818, -1.7859058380126953], [-1.1703513860702515, -0.37143754959106445], [-0.04204846918582916, -3.1898815631866455], [-0.12968865036964417, -2.106762409210205], [-0.05943765863776207, -2.85239839553833], [-0.031967487186193466, -3.4589765071868896], [-0.5421467423439026, -0.8710751533508301], [-0.2252650409936905, -1.600996732711792], [-1.6560038328170776, -0.2118331491947174], [-0.3982525169849396, -1.1131954193115234], [-0.23455405235290527, -1.5650551319122314], [-0.16901946067810059, -1.8610610961914062], [-0.121912382543087, -2.1647896766662598], [-0.10794319957494736, -2.2796366214752197], [-0.08378137648105621, -2.5211424827575684], [-0.3607161045074463, -1.1946063041687012], [-0.3650765120983124, -1.184639573097229], [-0.014067655429244041, -4.270900726318359], [-0.17424042522907257, -1.8331749439239502], [-0.29117289185523987, -1.3758944272994995], [-0.29135239124298096, -1.3753637075424194], [-0.036472223699092865, -3.3293843269348145], [-0.6768268346786499, -0.7097382545471191], [-0.35642385482788086, -1.2045589685440063], [-0.13651405274868011, -2.058807849884033], [-0.12292609363794327, -2.157005786895752], [-0.0477425716817379, -3.065709352493286], [-0.29258477687835693, -1.3717290163040161], [-0.028331901878118515, -3.5779001712799072], [-0.16269536316394806, -1.8961207866668701], [-0.39383837580680847, -1.122279405593872], [-0.07596297562122345, -2.6152498722076416], [-0.5809955596923828, -0.8194843530654907], [-0.3235134184360504, -1.2859145402908325], [-0.20923367142677307, -1.6670969724655151], [-0.21847674250602722, -1.6283259391784668], [-0.4369320273399353, -1.0385016202926636], [-0.19644847512245178, -1.723971962928772], [-0.5759644508361816, -0.825907289981842], [-0.12331101298332214, -2.1540675163269043], [-0.04388941451907158, -3.1479458808898926], [-0.5999479293823242, -0.795933723449707], [-0.7516142129898071, -0.6379106640815735], [-0.13380999863147736, -2.07749342918396], [-0.7156606912612915, -0.6711294054985046], [-0.02806314267218113, -3.5872962474823], [-0.43308913707733154, -1.045553207397461], [-0.08754529058933258, -2.479053020477295], [-0.08811196684837341, -2.472878932952881], [-0.003338955342769623, -5.703758239746094], [-0.4758909344673157, -0.9710932970046997], [-0.05764303356409073, -2.882168769836426], [-1.1743075847625732, -0.36966314911842346], [-0.37057143449783325, -1.1722793579101562], [-0.29963570833206177, -1.3512675762176514], [-0.27409765124320984, -1.4281911849975586], [-0.18538683652877808, -1.7765724658966064], [-0.15577653050422668, -1.93621027469635], [-0.36788609623908997, -1.1782920360565186], [-0.29219865798950195, -1.3728656768798828], [-0.10869359970092773, -2.2730765342712402], [-0.4061797857284546, -1.097184419631958], [-0.07302340865135193, -2.6532649993896484], [-0.9978522062301636, -0.45992717146873474], [-0.1339757889509201, -2.07633638381958], [-0.4305269718170166, -1.0502976179122925], [-0.7193582653999329, -0.6676056385040283], [-0.0519302636384964, -2.983705997467041], [-0.029583195224404335, -3.535304307937622], [-2.6328654289245605, -0.07458588480949402], [-0.345991849899292, -1.2293529510498047], [-0.5896952152252197, -0.808549702167511], [-0.7076077461242676, -0.6788927316665649], [-0.19780881702899933, -1.7177289724349976], [-0.5475900173187256, -0.8635604381561279], [-2.8262264728546143, -0.06106299161911011], [-0.10553102940320969, -2.3010518550872803], [-0.4027152359485626, -1.1041347980499268], [-0.005249170120805502, -5.252304553985596], [-0.1613996922969818, -1.9034861326217651], [-0.23721200227737427, -1.5550634860992432], [-0.05164547264575958, -2.989065170288086], [-0.08888350427150726, -2.464540958404541], [-0.03865082934498787, -3.272451400756836], [-0.10896356403827667, -2.270728588104248], [-0.16208286583423615, -1.899595022201538], [-0.31564390659332275, -1.3068145513534546], [-0.11697738617658615, -2.20369291305542], [-1.168576955795288, -0.3722366988658905], [-0.0025285673327744007, -5.981368064880371], [-0.35420289635658264, -1.2097649574279785], [-0.03409888967871666, -3.3954927921295166], [-0.707303524017334, -0.6791884303092957], [-0.07460447400808334, -2.632625102996826], [-0.2104966789484024, -1.661688208580017], [-0.2984679639339447, -1.354617714881897], [-0.17847168445587158, -1.8112341165542603], [-0.20578935742378235, -1.6820329427719116], [-4.276629447937012, -0.013986782170832157], [-0.010165229439735413, -4.593857765197754], [-0.42502060532569885, -1.060612440109253], [-0.15696673095226288, -1.929178237915039], [-0.07161518186330795, -2.67204213142395], [-0.043044332414865494, -3.1669700145721436], [-0.12264753133058548, -2.159137725830078], [-0.22423015534877777, -1.6051031351089478], [-0.06961293518543243, -2.699409008026123], [-0.004429410211741924, -5.421698093414307], [-0.5192153453826904, -0.9038364887237549], [-0.1292600929737091, -2.109862804412842], [-0.057425711303949356, -2.8858392238616943], [-0.46484917402267456, -0.9894794821739197], [-0.015896964818239212, -4.149562835693359], [-0.03290780261158943, -3.430452585220337], [-0.13703474402427673, -2.05525541305542], [-0.3350563645362854, -1.2563114166259766], [-0.10935817658901215, -2.267307758331299], [-0.015171841718256474, -4.195889472961426], [-0.31907394528388977, -1.2976309061050415], [-0.47071611881256104, -0.979642927646637], [-0.2161904275417328, -1.6377445459365845], [-0.1348094344139099, -2.0705409049987793], [-0.13770723342895508, -2.0506887435913086], [-0.5492679476737976, -0.8612636923789978], [-0.07398713380098343, -2.640629529953003], [-0.041210293769836426, -3.2096009254455566], [-0.2551071047782898, -1.490915298461914], [-0.5164847373962402, -0.9078616499900818], [-0.04238605499267578, -3.182053565979004], [-0.09355704486370087, -2.4155983924865723], [-0.5058534741401672, -0.9237958192825317], [-0.05976875498890877, -2.8470075130462646], [-0.11161059886217117, -2.24802565574646], [-0.05040869116783142, -3.012690782546997], [-0.3949689269065857, -1.119941234588623], [-0.1580832451581955, -1.9226343631744385], [-0.2332201600074768, -1.5701172351837158], [-0.7139601707458496, -0.6727585196495056], [-0.5402591824531555, -0.87370365858078], [-0.5620986819267273, -0.8439968824386597], [-0.030659407377243042, -3.5001065731048584], [-0.007639005314558744, -4.878305435180664], [-0.12451288104057312, -2.144956588745117], [-0.1130724623799324, -2.2357301712036133], [-0.5546239614486694, -0.8539927005767822], [-4.276629447937012, -0.013986782170832157], [-1.0160298347473145, -0.4494630694389343], [-0.005300160031765699, -5.242657661437988], [-0.2594769299030304, -1.4760220050811768], [-0.4606715440750122, -0.9965788125991821], [-0.21694667637348175, -1.634616494178772], [-0.05185069888830185, -2.985199213027954], [-0.2306186705827713, -1.5800843238830566], [-0.14944177865982056, -1.9746389389038086], [-2.544769287109375, -0.08174283802509308], [-0.3463844954967499, -1.2284038066864014], [-0.6866347789764404, -0.6997023224830627], [-0.0991867333650589, -2.3599345684051514], [-0.018974579870700836, -3.974125385284424], [-0.7187953591346741, -0.6681405305862427], [-0.19483789801597595, -1.7314250469207764], [-0.9919567704200745, -0.46338599920272827], [-0.22165252268314362, -1.6154241561889648], [-0.29102736711502075, -1.3763251304626465], [-0.5959165692329407, -0.8008600473403931], [-0.5312384366989136, -0.8864322900772095], [-0.09836844354867935, -2.367816209793091], [-0.019333958625793457, -3.9555463790893555], [-0.08630753308534622, -2.4926815032958984], [-0.21178588271141052, -1.6562045812606812], [-0.12053948640823364, -2.1754422187805176], [-0.153311088681221, -1.9509624242782593], [-0.6044024229049683, -0.790541410446167], [-0.2583439350128174, -1.4798561334609985], [-0.1777137964963913, -1.8151220083236694], [-4.7898783683776855, -0.008348211646080017], [-0.19914720952510834, -1.711632490158081], [-0.26559123396873474, -1.4556552171707153], [-0.3429035246372223, -1.236863374710083], [-0.5792539119720459, -0.8216996192932129], [-0.17687851190567017, -1.8194282054901123], [-0.9400027394294739, -0.49532437324523926], [-0.08093388378620148, -2.5543172359466553], [-0.6150487065315247, -0.7778656482696533], [-0.2317437082529068, -1.5757583379745483], [-0.2990690767765045, -1.3528910875320435], [-0.19265925884246826, -1.741615891456604], [-0.09036130458116531, -2.4487802982330322], [-0.1208178922533989, -2.173272132873535], [-0.5994102358818054, -0.7965882420539856], [-0.5153161287307739, -0.9095927476882935], [-0.846150279045105, -0.5604773163795471], [-2.473454713821411, -0.08805902302265167], [-0.0013906818348914385, -6.578652381896973], [-0.5703790187835693, -0.8331247568130493], [-0.034524742513895035, -3.3832919597625732], [-0.025651967152953148, -3.6759328842163086], [-0.21800896525382996, -1.6302440166473389], [-0.48433440923690796, -0.9573917984962463], [-0.24276615679264069, -1.5345849990844727], [-0.435139924287796, -1.0417805910110474], [-0.025623267516493797, -3.6770377159118652], [-0.8031599521636963, -0.5940465927124023], [-0.014271808788180351, -4.256600379943848], [-0.5395117402076721, -0.8747479915618896], [-0.2420809417963028, -1.5370831489562988], [-0.8507749438285828, -0.5570158362388611], [-0.2277066558599472, -1.59139084815979], [-0.38988497853279114, -1.1305203437805176], [-0.12378479540348053, -2.1504645347595215], [-0.0194960068911314, -3.947275161743164], [-0.5505341291427612, -0.8595364093780518], [-0.390767365694046, -1.1286721229553223], [-2.4509005546569824, -0.09016099572181702], [-0.06775561720132828, -2.7255337238311768], [-0.0012525817146524787, -6.683139324188232], [-0.05097674950957298, -3.001765251159668], [-0.1455904096364975, -1.9988703727722168], [-0.3117963969707489, -1.3172557353973389], [-0.03838930279016495, -3.279109001159668], [-0.10833349823951721, -2.276218891143799], [-0.005619680043309927, -5.18428373336792], [-0.8486011028289795, -0.5586395263671875], [-0.14365899562835693, -2.011282444000244], [-0.45417243242263794, -1.0077846050262451], [-0.5714706778526306, -0.8317067623138428], [-0.22889366745948792, -1.586762547492981], [-0.02269229292869568, -3.7970521450042725], [-0.07138267159461975, -2.6751797199249268], [-0.1822747141122818, -1.7919939756393433], [-0.4581359624862671, -1.000927209854126], [-3.221893548965454, -0.0406964085996151], [-0.17210792005062103, -1.8444534540176392], [-0.22848168015480042, -1.5883656740188599], [-0.23878003656864166, -1.5492279529571533], [-3.085177421569824, -0.04680018126964569], [-1.6792877912521362, -0.20641766488552094], [-0.33196258544921875, -1.2641270160675049], [-0.04814629629254341, -3.057487726211548], [-0.121828593313694, -2.165436029434204], [-0.14285853505134583, -2.016479253768921], [-0.15092813968658447, -1.9654664993286133], [-0.05141449719667435, -2.99343204498291], [-0.35219907760620117, -1.2144951820373535], [-0.30168697237968445, -1.3454194068908691], [-0.07342159003019333, -2.6480231285095215], [-0.8157568573951721, -0.5839420557022095], [-0.23641060292720795, -1.55806303024292], [-0.29523521661758423, -1.36397123336792], [-0.009205162525177002, -4.69258451461792], [-0.43771854043006897, -1.0370680093765259], [-0.1429213583469391, -2.0160703659057617], [-1.9840680360794067, -0.14793017506599426], [-0.006994761060923338, -4.966097354888916], [-0.02742519974708557, -3.6099743843078613], [-0.16310559213161469, -1.8938020467758179], [-0.011648732237517834, -4.458381175994873], [-0.04824183136224747, -3.0555527210235596], [-0.17007344961166382, -1.8553566932678223], [-0.707303524017334, -0.6791884303092957], [-0.4541292190551758, -1.0078599452972412], [-0.03243452310562134, -3.4447052478790283], [-0.09213071316480637, -2.4302587509155273], [-0.0411863848567009, -3.2101690769195557], [-0.45847493410110474, -1.0003440380096436], [-0.4341345429420471, -1.0436272621154785], [-0.39232704043388367, -1.1254178285598755], [-0.11125261336565018, -2.2510621547698975], [-0.199049711227417, -1.7120753526687622], [-0.3939765691757202, -1.121993064880371], [-0.018420696258544922, -4.003474235534668], [-0.014669417403638363, -4.229312419891357], [-0.04963172227144241, -3.0278379917144775], [-0.3213546574115753, -1.2915880680084229], [-0.09963938593864441, -2.3556039333343506], [-0.05964432656764984, -2.849029541015625], [-0.23989273607730865, -1.545113205909729], [-0.15216097235679626, -1.9579323530197144], [-0.4484996199607849, -1.0177299976348877], [-0.38642820715904236, -1.1378090381622314], [-0.28337424993515015, -1.3993303775787354], [-0.1968451887369156, -1.7221461534500122], [-0.3753376305103302, -1.1617350578308105], [-0.204701766371727, -1.6868070363998413], [-0.5528016686439514, -0.8564562797546387], [-0.41882938146591187, -1.0724081993103027], [-0.187129944562912, -1.7680585384368896], [-0.23591084778308868, -1.5599390268325806], [-1.704089641571045, -0.2008170783519745], [-0.27244946360588074, -1.4334357976913452], [-0.15950427949428558, -1.9143770933151245], [-0.020310871303081512, -3.9067366123199463], [-0.41923877596855164, -1.071621298789978], [-0.6465187072753906, -0.7420567274093628], [-0.9859296083450317, -0.4669558107852936], [-0.4059896469116211, -1.0975641012191772], [-0.318652868270874, -1.2987521886825562], [-0.017768606543540955, -4.039194107055664], [-0.04714879393577576, -3.0779290199279785], [-0.19727236032485962, -1.7201850414276123], [-0.36973366141319275, -1.1741498708724976], [-0.5459094643592834, -0.8658702373504639], [-0.47036030888557434, -0.9802349805831909], [-0.11209677159786224, -2.24391770362854], [-1.046411395072937, -0.43262431025505066], [-0.20224180817604065, -1.697708249092102], [-0.1798848807811737, -1.804032802581787], [-0.2850465774536133, -1.3942426443099976], [-0.2758886218070984, -1.4225330352783203], [-0.05967644602060318, -2.8485074043273926], [-0.3852175772190094, -1.1403802633285522], [-0.15847806632518768, -1.9203319549560547], [-0.09194011986255646, -2.4322361946105957], [-0.06740453839302063, -2.7305567264556885], [-0.5919819474220276, -0.8057107925415039], [-0.10104083269834518, -2.342325210571289], [-0.06186150014400482, -2.813629388809204], [-0.24633251130580902, -1.521712064743042], [-0.05811195820569992, -2.8742992877960205], [-0.277151495218277, -1.41856849193573], [-0.4147889018058777, -1.08022141456604], [-0.2930392920970917, -1.3703927993774414], [-0.620052695274353, -0.7720088362693787], [-0.05535748600959778, -2.921495199203491], [-0.1358509510755539, -2.0633533000946045], [-0.2121029794216156, -1.6548610925674438], [-0.4962102770805359, -0.938622236251831], [-0.11855648458003998, -2.1910581588745117], [-0.26804882287979126, -1.4476187229156494], [-0.10061446577310562, -2.346344470977783], [-0.4372211694717407, -1.0379741191864014], [-0.060081105679273605, -2.841949939727783], [-0.008448455482721329, -4.777997016906738], [-0.14350120723247528, -2.0123045444488525], [-0.2194562554359436, -1.6243247985839844], [-0.4443371295928955, -1.0251271724700928], [-1.3103421926498413, -0.3143378794193268], [-0.3257061541080475, -1.2801963090896606], [-0.0452362559735775, -3.118389844894409], [-0.07025042176246643, -2.6906094551086426], [-0.6978089213371277, -0.688507080078125], [-0.06792805343866348, -2.7230780124664307], [-0.17739318311214447, -1.816772699356079], [-1.4428704977035522, -0.26951301097869873], [-0.12331902235746384, -2.154006242752075], [-0.07753963023424149, -2.595484972000122], [-0.005323045887053013, -5.238367557525635], [-0.20073124766349792, -1.7044755220413208], [-0.00399458222091198, -5.524819850921631], [-0.4308280348777771, -1.0497384071350098], [-0.045030124485492706, -3.1228537559509277], [-0.03177996352314949, -3.4647672176361084], [-0.028435146436095238, -3.574313163757324], [-0.9136533141136169, -0.5125877261161804], [-0.20261071622371674, -1.6960641145706177], [-0.5701289772987366, -0.8334501385688782], [-0.023274680599570274, -3.7720024585723877], [-0.032198838889598846, -3.4518799781799316], [-0.1449521780014038, -2.0029520988464355], [-2.113220453262329, -0.12879769504070282], [-0.22679924964904785, -1.594947338104248], [-0.23124340176582336, -1.577678918838501], [-0.1919495314359665, -1.7449625730514526], [-0.5173918604850769, -0.9065215587615967], [-0.2681661546230316, -1.4472370147705078], [-1.004819393157959, -0.4558810591697693], [-0.3095988631248474, -1.323286771774292], [-0.06976870447397232, -2.697251558303833], [-1.0723392963409424, -0.4188651144504547], [-0.02622346021234989, -3.654184341430664], [-0.4980578124523163, -0.9357534646987915], [-0.4642731845378876, -0.9904536008834839], [-0.18825212121009827, -1.7626230716705322], [-0.30689647793769836, -1.3307716846466064], [-0.48055964708328247, -0.9634796977043152], [-0.029943294823169708, -3.523383617401123], [-0.3149900734424591, -1.3085784912109375], [-0.21281291544437408, -1.6518619060516357], [-0.04672623798251152, -3.0867228507995605], [-0.11562349647283554, -2.214670419692993], [-0.48801684379577637, -0.9515100121498108], [-0.10593010485172272, -2.297473192214966], [-0.226495623588562, -1.5961408615112305], [-0.0007111880695447326, -7.248918056488037], [-0.543064296245575, -0.8698014616966248], [-1.3802056312561035, -0.28971993923187256], [-0.031832966953516006, -3.463127851486206], [-0.918465256690979, -0.5093786120414734], [-0.8285298347473145, -0.573926568031311], [-0.40858194231987, -1.0924078226089478], [-0.2560672461986542, -1.4876182079315186], [-0.16512982547283173, -1.8824526071548462], [-0.025688566267490387, -3.674527883529663], [-0.017947418615221977, -4.029267311096191], [-0.29949751496315, -1.3516629934310913], [-0.34567180275917053, -1.2301274538040161], [-0.5895155668258667, -0.8087732791900635], [-0.5041662454605103, -0.9263637065887451], [-0.17943446338176727, -1.8063215017318726], [-0.14468659460544586, -2.0046563148498535], [-0.6874151825904846, -0.6989123225212097], [-0.4213959872722626, -1.0674923658370972], [-0.13967858254909515, -2.037438154220581], [-0.11096886545419693, -2.2534773349761963], [-0.03473362699151039, -3.37736439704895], [-0.0692005455493927, -2.7051467895507812], [-0.0549115315079689, -2.929361581802368], [-0.1388181746006012, -2.0431969165802], [-0.10597416758537292, -2.297079086303711], [-0.04116155952215195, -3.2107605934143066], [-0.6450603604316711, -0.7436637282371521], [-0.19466689229011536, -1.7322204113006592], [-0.023571277037262917, -3.7594897747039795], [-0.3406616449356079, -1.2423655986785889], [-0.03298231586813927, -3.4282312393188477], [-0.07289784401655197, -2.654923677444458], [-0.058397162705659866, -2.8695437908172607], [-0.37947288155555725, -1.1527155637741089], [-1.5204797983169556, -0.24667704105377197], [-0.30198484659194946, -1.344573736190796], [-0.13551142811775208, -2.0656895637512207], [-0.5633480548858643, -0.8423430323600769], [-0.2830592095851898, -1.4002927541732788], [-0.39964205026626587, -1.1103609800338745], [-0.31849655508995056, -1.2991688251495361], [-0.5153971314430237, -0.9094724059104919], [-0.2585357129573822, -1.4792059659957886], [-0.37727832794189453, -1.157487392425537], [-0.07585911452770233, -2.6165671348571777], [-0.07554524391889572, -2.620558261871338], [-0.10296043753623962, -2.324448823928833], [-0.20401686429977417, -1.6898274421691895], [-0.036659326404333115, -3.3243610858917236], [-0.25619199872016907, -1.4871907234191895], [-1.9495986700057983, -0.15353727340698242], [-0.976861834526062, -0.4723917543888092], [-0.07845548540353775, -2.584195613861084], [-0.09237584471702576, -2.4277217388153076], [-0.06769222766160965, -2.726438283920288], [-0.044842980802059174, -3.126927137374878], [-0.5564531683921814, -0.8515303134918213], [-0.17596027255058289, -1.8241877555847168], [-0.018891528248786926, -3.9784719944000244], [-0.008497391827404499, -4.7722368240356445], [-0.4043930768966675, -1.1007596254348755], [-0.067318394780159, -2.7317914962768555], [-0.6898202300071716, -0.6964852809906006], [-0.01628747768700123, -4.125489711761475], [-0.05498397350311279, -2.9280805587768555], [-0.11962860077619553, -2.1825811862945557], [-0.3201444745063782, -1.2947883605957031], [-0.02365708351135254, -3.755899667739868], [-0.00871899351477623, -4.746602535247803], [-0.04737870767712593, -3.0731794834136963], [-0.02751508355140686, -3.6067469120025635], [-0.007056197617202997, -4.957380294799805], [-0.09066087007522583, -2.445617437362671], [-0.0027610058896243572, -5.8935227394104], [-0.15201209485530853, -1.9588383436203003], [-0.7132245302200317, -0.6734650135040283], [-0.28953441977500916, -1.3807579278945923], [-0.454315721988678, -1.0075353384017944], [-1.0741440057754517, -0.41792747378349304], [-0.21002380549907684, -1.663709044456482], [-0.17667943239212036, -1.8204574584960938], [-0.3205186426639557, -1.2937971353530884], [-0.4238862097263336, -1.0627578496932983], [-0.16663554310798645, -1.874107003211975], [-0.052086323499679565, -2.9807825088500977], [-0.41456425189971924, -1.0806589126586914], [-0.3312373459339142, -1.2659714221954346], [-0.49934107065200806, -0.933768630027771], [-0.03597061708569527, -3.342984199523926], [-0.4515421390533447, -1.0123767852783203], [-0.3205695152282715, -1.293662667274475], [-0.03268134593963623, -3.4372482299804688], [-0.5128907561302185, -0.913201093673706], [-0.6299942135810852, -0.7605588436126709], [-0.34301629662513733, -1.2365877628326416], [-1.2396901845932007, -0.3417496383190155], [-0.7229278683662415, -0.6642279028892517], [-0.04832520708441734, -3.053868532180786], [-0.2908227741718292, -1.3769311904907227], [-0.8545563220977783, -0.5542062520980835], [-0.18579329550266266, -1.774579405784607], [-0.5346353650093079, -0.8816063404083252], [-0.049811165779829025, -3.024317741394043], [-0.12043634057044983, -2.1762478351593018], [-0.02222289890050888, -3.817721366882324], [-0.49376940727233887, -0.9424333572387695], [-0.2875940203666687, -1.3865585327148438], [-0.5135635137557983, -0.9121978282928467], [-0.9548222422599792, -0.4859388470649719], [-0.05229971930384636, -2.9768011569976807], [-0.04722645878791809, -3.076322078704834], [-0.28428414463996887, -1.3965580463409424], [-0.08977334201335907, -2.4550178050994873], [-0.9020613431930542, -0.5204256772994995], [-0.33871451020240784, -1.2471791505813599], [-0.0073654530569911, -4.9146270751953125], [-0.03894129768013954, -3.265108823776245], [-0.07950758934020996, -2.5713930130004883], [-0.0255918949842453, -3.6782493591308594], [-0.6840470433235168, -0.7023307681083679], [-1.7095506191253662, -0.19960659742355347], [-0.35462501645088196, -1.2087724208831787], [-0.05225853621959686, -2.977566719055176], [-0.13999658823013306, -2.0353193283081055], [-0.29024800658226013, -1.3786358833312988], [-0.9725013971328735, -0.47503387928009033], [-0.0014691284159198403, -6.5238518714904785], [-0.01852484978735447, -3.997891664505005], [-0.004598400089889765, -5.3843536376953125], [-0.6541144847869873, -0.7337656021118164], [-0.17023533582687378, -1.8544838428497314], [-0.07559464871883392, -2.6199283599853516], [-0.1032506600022316, -2.321777105331421], [-0.22216039896011353, -1.6133801937103271], [-0.4783879220485687, -0.9670097827911377], [-0.02902519889175892, -3.554067611694336], [-0.522255539894104, -0.8993870615959167], [-0.08020404726266861, -2.5630156993865967], [-0.4928153157234192, -0.9439294338226318], [-0.6345524191856384, -0.7553901672363281], [-0.36105215549468994, -1.1938332319259644], [-0.09852681308984756, -2.366286039352417], [-0.09831830859184265, -2.3683009147644043], [-0.14347383379936218, -2.012481927871704], [-0.02781089022755623, -3.5961992740631104], [-1.2214142084121704, -0.349292129278183], [-0.36067789793014526, -1.1946946382522583], [-0.6315712332725525, -0.7587650418281555], [-0.22722655534744263, -1.5932705402374268], [-0.241387277841568, -1.5396195650100708], [-0.0962313711643219, -2.38873028755188], [-0.10035097599029541, -2.3488378524780273], [-0.2463974505662918, -1.521479845046997], [-0.016182150691747665, -4.131922721862793], [-0.39854496717453003, -1.112597942352295], [-0.028316721320152283, -3.5784265995025635], [-0.08345407992601395, -2.5248961448669434], [-0.029096528887748718, -3.5516507625579834], [-0.014456650242209435, -4.243817329406738], [-0.4443480968475342, -1.0251076221466064], [-0.12007071822881699, -2.1791093349456787], [-0.015399951487779617, -4.181079387664795], [-0.23967823386192322, -1.545904517173767], [-0.23156914114952087, -1.5764280557632446], [-0.4023893177509308, -1.1047923564910889], [-0.5374655723571777, -0.8776159286499023], [-0.011457477696239948, -4.474834442138672], [-0.07891673594713211, -2.5785603523254395], [-0.48971375823020935, -0.9488185048103333], [-0.0011644733604043722, -6.756065845489502], [-0.168501079082489, -1.8638806343078613], [-0.006052025128155947, -5.110382556915283], [-0.04178199917078018, -3.1961090564727783], [-0.8222167491912842, -0.5788482427597046], [-0.07093691825866699, -2.681222677230835], [-0.9092460870742798, -0.5155497789382935], [-0.15875466167926788, -1.9187225103378296], [-0.3536347448825836, -1.2111026048660278], [-0.02585272304713726, -3.6682395935058594], [-0.020062264055013657, -3.9189271926879883], [-0.3703842759132385, -1.1726969480514526], [-0.07645707577466965, -2.609011173248291], [-0.26248371601104736, -1.4659391641616821], [-0.04476535692811012, -3.128620147705078], [-0.010489922016859055, -4.562582969665527], [-0.4691554307937622, -0.9822445511817932], [-0.2655462622642517, -1.4558031558990479], [-0.260734498500824, -1.4717888832092285], [-0.07756511121988297, -2.59516978263855], [-0.002820563269779086, -5.87224817276001], [-0.49457627534866333, -0.9411708116531372], [-0.16542862355709076, -1.8807899951934814], [-0.09198741614818573, -2.431744337081909], [-0.020870130509138107, -3.8798537254333496], [-0.366127610206604, -1.1822580099105835], [-0.10672134160995483, -2.2904207706451416], [-0.05863473564386368, -2.8656020164489746], [-0.2244277149438858, -1.604317545890808], [-0.047345053404569626, -3.0738730430603027], [-0.8032041788101196, -0.5940107703208923], [-0.021775444969534874, -3.8378422260284424], [-1.096128225326538, -0.4067095220088959], [-1.3427248001098633, -0.3026375472545624], [-0.13113752007484436, -2.096360921859741], [-0.12853921949863434, -2.1151022911071777], [-0.023190470412373543, -3.7755846977233887], [-0.12043750286102295, -2.176239013671875], [-0.2449324131011963, -1.526740550994873], [-0.3606686592102051, -1.1947157382965088], [-0.22112812101840973, -1.6175405979156494], [-0.41373950242996216, -1.082265853881836], [-0.2946547269821167, -1.3656634092330933], [-0.37758931517601013, -1.1568093299865723], [-0.05344907566905022, -2.9556305408477783], [-0.218695268034935, -1.627431869506836], [-0.48618602752685547, -0.9544273614883423], [-0.20140495896339417, -1.7014505863189697], [-0.0721849650144577, -2.664398193359375], [-0.036611177027225494, -3.325651168823242], [-0.0491417795419693, -3.0375163555145264], [-0.048455026000738144, -3.051248788833618], [-0.3369671702384949, -1.2515268325805664], [-0.40986189246177673, -1.0898765325546265], [-0.3685515224933624, -1.1767973899841309], [-0.3602076768875122, -1.1957781314849854], [-0.16848143935203552, -1.8639878034591675], [-4.793344974517822, -0.008319247514009476], [-0.044139012694358826, -3.142399311065674], [-0.38595831394195557, -1.1388061046600342], [-0.09320643544197083, -2.419179677963257], [-0.1923697590827942, -1.7429795265197754], [-0.13766132295131683, -2.050999402999878], [-0.03984472528100014, -3.242621421813965], [-0.24433764815330505, -1.5288864374160767], [-0.5449284315109253, -0.867222785949707], [-0.007320839911699295, -4.920691967010498], [-0.4761671721935272, -0.9706405401229858], [-1.0061410665512085, -0.4551185369491577], [-0.02219654805958271, -3.8188974857330322], [-0.004029014613479376, -5.516237735748291], [-0.5333104133605957, -0.8834841251373291], [-0.1671244502067566, -1.871415138244629], [-0.32303914427757263, -1.2871571779251099], [-0.06955432891845703, -2.7002220153808594], [-0.0541379414498806, -2.943166971206665], [-0.41842904686927795, -1.0731778144836426], [-0.11860624700784683, -2.1906633377075195], [-0.06594864279031754, -2.7516720294952393], [-0.33585938811302185, -1.2542967796325684], [-0.10904940217733383, -2.2699832916259766], [-0.8158532977104187, -0.5838655829429626], [-0.05563570186495781, -2.916618585586548], [-0.27153173089027405, -1.436371922492981], [-0.5000609755516052, -0.9326580166816711], [-0.03283247724175453, -3.432708501815796], [-0.4423561096191406, -1.028678059577942], [-0.25102508068084717, -1.5050908327102661], [-0.09654087573289871, -2.3856706619262695], [-0.40083497762680054, -1.1079373359680176], [-0.6558055281639099, -0.7319374680519104], [-0.07330815494060516, -2.6495139598846436], [-0.3425232470035553, -1.2377935647964478], [-0.4079035520553589, -1.0937530994415283], [-0.45253440737724304, -1.0106403827667236], [-0.16241024434566498, -1.8977363109588623], [-0.21120543777942657, -1.6586687564849854], [-0.823951005935669, -0.5774906873703003], [-0.044406794011592865, -3.1364850997924805], [-0.8315879106521606, -0.5715623497962952], [-0.06705957651138306, -2.735515594482422], [-0.8126575350761414, -0.5864070653915405], [-0.2905067801475525, -1.3778676986694336], [-0.12304605543613434, -2.1560893058776855], [-0.3519796133041382, -1.215014934539795], [-0.041410353034734726, -3.2048583030700684], [-6.222341537475586, -0.001986555755138397], [-0.3455877900123596, -1.2303311824798584], [-0.12825551629066467, -2.117173194885254], [-1.1132287979125977, -0.3982361853122711], [-0.180766299366951, -1.799572229385376], [-0.17485402524471283, -1.8299572467803955], [-0.03050054796040058, -3.5052239894866943], [-0.14617498219013214, -1.9951483011245728], [-0.03302360698580742, -3.4270002841949463], [-1.2566442489624023, -0.33492395281791687], [-0.012398077175021172, -4.396406650543213], [-0.32254907488822937, -1.2884432077407837], [-0.25339508056640625, -1.4968290328979492], [-0.10207483172416687, -2.3326523303985596], [-1.7887473106384277, -0.1829250156879425], [-0.022936519235372543, -3.7864692211151123], [-0.264522522687912, -1.4591761827468872], [-0.4523668885231018, -1.0109329223632812], [-0.05955346301198006, -2.85050892829895], [-0.018527191132307053, -3.9977645874023438], [-0.23144620656967163, -1.576899766921997], [-0.45406651496887207, -1.0079689025878906], [-0.31401172280311584, -1.3112258911132812], [-0.041604310274124146, -3.2002809047698975], [-0.08639053255319595, -2.4917612075805664], [-0.47305142879486084, -0.9757700562477112], [-0.42958706617355347, -1.052046775817871], [-0.5707389116287231, -0.832656979560852], [-0.29715943336486816, -1.3583896160125732], [-0.14671795070171356, -1.9917054176330566], [-0.6373763084411621, -0.7522132396697998], [-0.3766125440597534, -1.158941626548767], [-0.1901596039533615, -1.753465175628662], [-0.1455904096364975, -1.9988703727722168], [-0.3416445851325989, -1.23994779586792], [-0.1639316976070404, -1.889151930809021], [-0.1198243573307991, -2.181041955947876], [-0.022802412509918213, -3.7922701835632324], [-0.1427665501832962, -2.0170788764953613], [-0.5033823251724243, -0.927560567855835], [-0.1728682667016983, -1.8404150009155273], [-0.10432297736406326, -2.311972141265869], [-0.07417067140340805, -2.638242721557617], [-1.2756922245025635, -0.3274456858634949], [-0.078152135014534, -2.5879197120666504], [-0.3772744834423065, -1.1574958562850952], [-0.10251230001449585, -2.3285908699035645], [-0.34913837909698486, -1.2217822074890137], [-0.0710281953215599, -2.6799817085266113], [-0.07599247992038727, -2.614877223968506], [-1.0013548135757446, -0.4578875005245209], [-0.3484979271888733, -1.2233169078826904], [-0.4675125777721405, -0.9849948883056641], [-0.04030603915452957, -3.2313392162323], [-0.05289926752448082, -2.9656994342803955], [-0.29593729972839355, -1.361930012702942], [-0.2846165597438812, -1.39554762840271], [-0.18827711045742035, -1.7625023126602173], [-3.986454725265503, -0.018739912658929825], [-0.322536826133728, -1.2884756326675415], [-0.02459314651787281, -3.7175610065460205], [-0.03296651318669319, -3.4287028312683105], [-0.5048832893371582, -0.9252707958221436], [-0.25573858618736267, -1.488745093345642], [-3.1984660625457764, -0.04168149456381798], [-0.010482844896614552, -4.563247203826904], [-0.08329439908266068, -2.5267324447631836], [-0.5335314869880676, -0.8831703662872314], [-0.39030030369758606, -1.1296497583389282], [-0.8568360805511475, -0.5525213479995728], [-0.4674118161201477, -0.9851639866828918], [-0.3943384289741516, -1.121244192123413], [-0.5873722434043884, -0.8114485740661621], [-0.1594918817281723, -1.9144483804702759], [-0.08374114334583282, -2.5216031074523926], [-2.3008673191070557, -0.10555151849985123], [-0.057989347726106644, -2.876350164413452], [-1.1365267038345337, -0.3870336711406708], [-0.08665084093809128, -2.4888806343078613], [-0.38122907280921936, -1.1489211320877075], [-0.2646147608757019, -1.458871841430664], [-0.40703871846199036, -1.0954725742340088], [-0.03886837512254715, -3.2669451236724854], [-0.14803597331047058, -1.983405351638794], [-0.04693031311035156, -3.0824661254882812], [-0.9963175058364868, -0.46082448959350586], [-0.09048774093389511, -2.4474432468414307], [-0.2412569224834442, -1.5400974750518799], [-1.150928258895874, -0.3802989721298218], [-2.938171148300171, -0.054416608065366745], [-0.3200026750564575, -1.2951639890670776], [-0.5496640801429749, -0.8607227206230164], [-0.5144179463386536, -0.9109262824058533], [-0.014408357441425323, -4.247146129608154], [-0.43778687715530396, -1.0369436740875244], [-0.13005998730659485, -2.1040842533111572], [-0.1455904096364975, -1.9988703727722168], [-0.20499731600284576, -1.6855064630508423], [-0.027343658730387688, -3.6129117012023926], [-0.17881427705287933, -1.8094829320907593], [-0.3268572986125946, -1.2772127389907837], [-0.035592664033174515, -3.353358268737793], [-0.34814855456352234, -1.224155068397522], [-0.35551172494888306, -1.2066924571990967], [-0.5659061074256897, -0.8389719128608704], [-0.17659950256347656, -1.8208717107772827], [-0.0890270322561264, -2.462998867034912], [-0.2844793498516083, -1.3959643840789795], [-0.4304513931274414, -1.0504380464553833], [-0.10335053503513336, -2.3208587169647217], [-0.40468883514404297, -1.1001667976379395], [-0.2186581939458847, -1.6275835037231445], [-1.2606136798858643, -0.33334916830062866], [-0.24721668660640717, -1.5185532569885254], [-2.8539886474609375, -0.059340376406908035], [-0.018311146646738052, -4.009385585784912], [-0.3431693911552429, -1.2362138032913208], [-0.384470134973526, -1.1419726610183716], [-1.006005048751831, -0.4551968574523926], [-0.16567087173461914, -1.8794443607330322], [-0.03151189908385277, -3.4731063842773438], [-0.544247031211853, -0.8681640625], [-0.40241682529449463, -1.1047368049621582], [-1.114209532737732, -0.39775681495666504], [-0.198032408952713, -1.716707468032837], [-0.07678733021020889, -2.6048641204833984], [-0.23161093890666962, -1.5762676000595093], [-0.09246094524860382, -2.4268436431884766], [-0.045883890241384506, -3.104494333267212], [-0.3058989346027374, -1.3335541486740112], [-0.25664225220680237, -1.4856501817703247], [-0.5707467794418335, -0.8326466679573059], [-0.17379185557365417, -1.8355345726013184], [-1.010385513305664, -0.4526802897453308], [-0.30710482597351074, -1.330191731452942], [-0.2708435654640198, -1.4385809898376465], [-0.5866374969482422, -0.8123685717582703], [-0.03182061389088631, -3.463510274887085], [-0.16862183809280396, -1.8632235527038574], [-0.09637146443128586, -2.3873443603515625], [-0.03916920721530914, -3.259385108947754], [-0.04814811423420906, -3.05745005607605], [-0.016227073967456818, -4.129175662994385], [-0.4094470143318176, -1.0906956195831299], [-0.023397428914904594, -3.7668027877807617], [-0.5455271601676941, -0.8663969039916992], [-0.23605027794837952, -1.5594151020050049], [-0.0256949570029974, -3.674281597137451], [-0.16220369935035706, -1.898908019065857], [-0.010582403279840946, -4.553844928741455], [-0.11603204160928726, -2.211343765258789], [-0.11684269458055496, -2.2047791481018066], [-0.4467875361442566, -1.0207622051239014], [-0.3877251446247101, -1.135064959526062], [-0.14967161417007446, -1.9732146263122559], [-0.15084612369537354, -1.9659699201583862], [-0.2928646206855774, -1.370905876159668], [-0.047405537217855453, -3.072624444961548], [-0.27546587586402893, -1.423864722251892], [-0.3267351984977722, -1.2775287628173828], [-0.1273750364780426, -2.123631477355957], [-0.35177385807037354, -1.2155029773712158], [-0.18161702156066895, -1.7952895164489746], [-0.31130078434944153, -1.3186115026474], [-0.42443323135375977, -1.0617223978042603], [-0.5045570135116577, -0.9257680177688599], [-0.05886225029826164, -2.861842632293701], [-0.3710058629512787, -1.171311855316162], [-0.3537054657936096, -1.2109360694885254], [-0.19625715911388397, -1.7248536348342896], [-0.28352129459381104, -1.3988813161849976], [-4.276629447937012, -0.013986782170832157], [-0.33280569314956665, -1.261988639831543], [-0.33571478724479675, -1.2546590566635132], [-0.005322452634572983, -5.23848819732666], [-0.4302225410938263, -1.0508636236190796], [-0.5489205718040466, -0.8617384433746338], [-0.0246160589158535, -3.716637372970581], [-0.36572059988975525, -1.1831790208816528], [-0.19469670951366425, -1.732081651687622], [-0.11471003293991089, -2.222154378890991], [-0.3815637528896332, -1.148200273513794], [-0.17866702377796173, -1.8102350234985352], [-0.3787256181240082, -1.15433669090271], [-0.05539042130112648, -2.9209165573120117], [-0.8461207151412964, -0.5604996085166931], [-0.3377356231212616, -1.249611496925354], [-0.5976748466491699, -0.7987058162689209], [-2.2532622814178467, -0.11099404096603394], [-0.4382115304470062, -1.0361709594726562], [-0.9352864623069763, -0.498359352350235], [-0.06250081211328506, -2.8036623001098633], [-1.187295913696289, -0.36390817165374756], [-0.1275755763053894, -2.1221563816070557], [-0.05964432656764984, -2.849029541015625], [-0.7015987038612366, -0.6847664713859558], [-0.217649444937706, -1.6317214965820312], [-0.11853615194559097, -2.1912200450897217], [-0.19362035393714905, -1.7371045351028442], [-0.49385255575180054, -0.9423031210899353], [-0.02848241850733757, -3.572674512863159], [-0.49635428190231323, -0.9383980631828308], [-0.06537774950265884, -2.7600841522216797], [-0.4771324396133423, -0.9690595865249634], [-0.3261694610118866, -1.278994083404541], [-3.148603677749634, -0.04385997727513313], [-0.26222631335258484, -1.466796875], [-0.35420238971710205, -1.209765911102295], [-0.1455904096364975, -1.9988703727722168], [-0.14995147287845612, -1.971482515335083], [-0.6693010330200195, -0.7175760269165039], [-1.6422703266143799, -0.2151011973619461], [-0.1973854899406433, -1.7196669578552246], [-0.1762133687734604, -1.8228726387023926], [-0.041543588042259216, -3.201711654663086], [-0.11014381796121597, -2.2605345249176025], [-0.017640013247728348, -4.046395778656006], [-0.15157721936702728, -1.961491346359253], [-0.1744525134563446, -1.832061529159546], [-0.01338990218937397, -4.319941520690918], [-0.526616632938385, -0.8930621147155762], [-0.4687877893447876, -0.9828588962554932], [-0.9127549529075623, -0.5131897926330566], [-0.14627426862716675, -1.9945178031921387], [-0.04078155755996704, -3.21984601020813], [-0.018726341426372528, -3.987170696258545], [-3.2708542346954346, -0.03871379420161247], [-0.6976790428161621, -0.6886358261108398], [-0.10022502392530441, -2.3500311374664307], [-0.07606451213359833, -2.6139655113220215], [-0.011225284077227116, -4.495193004608154], [-2.2238166332244873, -0.11450816690921783], [-0.16058386862277985, -1.9081568717956543], [-0.4607079029083252, -0.996516764163971], [-0.3563409745693207, -1.2047525644302368], [-0.8648327589035034, -0.5466635227203369], [-0.14863720536231995, -1.9796451330184937], [-0.6216620206832886, -0.7701386213302612], [-0.13685199618339539, -2.0565013885498047], [-0.030192120000720024, -3.5152323246002197], [-2.196536064147949, -0.117869071662426], [-0.10562338680028915, -2.300222158432007], [-0.008001298643648624, -4.832149505615234], [-0.11296482384204865, -2.2366294860839844], [-0.28915712237358093, -1.3818821907043457], [-0.039497800171375275, -3.251194477081299], [-1.1294944286346436, -0.3903745114803314], [-0.04724545031785965, -3.075928211212158], [-1.1033365726470947, -0.4031112790107727], [-0.008235424757003784, -4.803427219390869], [-0.3775317072868347, -1.1569347381591797], [-0.049313027411699295, -3.0341217517852783], [-0.05964432656764984, -2.849029541015625], [-0.9602224826812744, -0.48257458209991455], [-0.6556352376937866, -0.7321212291717529], [-0.016637155786156654, -4.104423522949219], [-0.05235368385910988, -2.9757964611053467], [-0.34263378381729126, -1.237523078918457], [-0.0018029639031738043, -6.319235324859619], [-0.08304022997617722, -2.529663562774658], [-0.024581165984272957, -3.7180392742156982], [-0.05379842594265938, -2.9492907524108887], [-0.1900005042552948, -1.7542253732681274], [-0.18811069428920746, -1.7633057832717896], [-1.0163649320602417, -0.44927290081977844], [-0.021722720935940742, -3.840240478515625], [-0.3723568022251129, -1.1683108806610107], [-0.004588076379150152, -5.386592388153076], [-0.03669414669275284, -3.3234286308288574], [-0.2942339777946472, -1.3668923377990723], [-0.020805099979043007, -3.8829407691955566], [-0.44082197546958923, -1.031441330909729], [-0.3228894770145416, -1.287549614906311], [-0.15767554938793182, -1.9250178337097168], [-0.3993780016899109, -1.110898733139038], [-0.16128626465797424, -1.904133677482605], [-0.22849714756011963, -1.5883055925369263], [-0.3948352634906769, -1.120217204093933], [-0.20371226966381073, -1.6911742687225342], [-0.04475680738687515, -3.1288061141967773], [-1.5202878713607788, -0.24673068523406982], [-0.11662153154611588, -2.2065656185150146], [-0.016946041956543922, -4.086184024810791], [-0.23336535692214966, -1.5695645809173584], [-0.5803025364875793, -0.8203648328781128], [-0.09733708947896957, -2.3778488636016846], [-0.002217930741608143, -6.112292766571045], [-0.30536508560180664, -1.3350474834442139], [-1.0603511333465576, -0.4251590967178345], [-0.2553296685218811, -1.490149736404419], [-0.04510829597711563, -3.1211583614349365], [-0.47302186489105225, -0.9758189916610718], [-0.17477485537528992, -1.8303714990615845], [-0.0446653850376606, -3.1308059692382812], [-0.25043562054634094, -1.5071593523025513], [-0.06606604158878326, -2.749950885772705], [-0.8423542976379395, -0.5633394718170166], [-0.2935449182987213, -1.368909239768982], [-0.15235640108585358, -1.9567439556121826], [-0.6346292495727539, -0.7553035020828247], [-0.21114598214626312, -1.6589213609695435], [-0.08660066872835159, -2.489436149597168], [-0.4472475051879883, -1.0199460983276367], [-0.492556631565094, -0.9443357586860657], [-0.13312120735645294, -2.08231782913208], [-0.009710339829325676, -4.6394147872924805], [-0.28416985273361206, -1.3969058990478516], [-0.7833300828933716, -0.6104285717010498], [-0.20961111783981323, -1.6654765605926514], [-0.03239874914288521, -3.4457921981811523], [-0.37899160385131836, -1.153759479522705], [-0.3446301519870758, -1.2326546907424927], [-0.006629970856010914, -5.019473075866699], [-0.6613025069236755, -0.7260393500328064], [-0.2648269832134247, -1.4581716060638428], [-0.4237879514694214, -1.0629441738128662], [-0.02760913409292698, -3.603379964828491], [-0.39926213026046753, -1.1111350059509277], [-0.4359731674194336, -1.0402538776397705], [-0.05964432656764984, -2.849029541015625], [-0.7221435308456421, -0.6649680733680725], [-0.7175759673118591, -0.66930091381073], [-0.45724862813949585, -1.0024559497833252], [-0.12671929597854614, -2.128471851348877], [-0.009491555392742157, -4.6620988845825195], [-0.3056747615337372, -1.3341808319091797], [-0.4925670325756073, -0.9443192481994629], [-0.010835029184818268, -4.530378818511963], [-0.5450822114944458, -0.8670105338096619], [-0.3990999460220337, -1.111465334892273], [-0.7215942740440369, -0.6654870510101318], [-1.326137900352478, -0.30856621265411377], [-0.5154274702072144, -0.9094275832176208], [-0.8847829103469849, -0.5323962569236755], [-0.5883045196533203, -0.810283362865448], [-1.4115142822265625, -0.2794148027896881], [-0.1647927165031433, -1.8843319416046143], [-0.09032699465751648, -2.4491424560546875], [-0.012893876992166042, -4.357444763183594], [-0.37672147154808044, -1.1587034463882446], [-0.07339733093976974, -2.648341655731201], [-0.18751396238803864, -1.7661943435668945], [-0.13445112109184265, -2.0730268955230713], [-0.029048359021544456, -3.553281307220459], [-0.05478164553642273, -2.931666612625122], [-0.9225893020629883, -0.5066484212875366], [-0.25278541445732117, -1.498946189880371], [-0.11179333180189133, -2.2464792728424072], [-0.2839081883430481, -1.3977022171020508], [-0.3717067837715149, -1.169752836227417], [-0.7765834927558899, -0.6161395311355591], [-0.00933697260916233, -4.678431987762451], [-0.02605355717241764, -3.6606009006500244], [-0.013991366140544415, -4.276301383972168], [-0.011963874101638794, -4.43184232711792], [-0.8384352922439575, -0.566314697265625], [-0.2535800039768219, -1.4961879253387451], [-0.13090328872203827, -2.098034620285034], [-0.5767687559127808, -0.8248754739761353], [-0.15437184274196625, -1.9445838928222656], [-0.021222177892923355, -3.8632988929748535], [-0.06977170705795288, -2.6972105503082275], [-0.8645328283309937, -0.5468818545341492], [-0.6927474141120911, -0.6935471892356873], [-0.029158474877476692, -3.5495522022247314], [-0.07850111275911331, -2.5836358070373535], [-0.33453941345214844, -1.2576113939285278], [-0.4367706775665283, -1.038796067237854], [-0.10559163242578506, -2.3005073070526123], [-0.4429093599319458, -1.0276844501495361], [-0.23303131759166718, -1.5708364248275757], [-0.07596253603696823, -2.615255355834961], [-0.05185013264417648, -2.9852101802825928], [-0.14582349359989166, -1.9973843097686768], [-0.36313343048095703, -1.189063310623169], [-0.11517419666051865, -2.218343734741211], [-0.20866207778453827, -1.6695564985275269], [-0.5209923982620239, -0.9012317657470703], [-0.12048812955617905, -2.1758437156677246], [-2.6056621074676514, -0.0767236277461052], [-0.022946655750274658, -3.786036968231201], [-0.07198742032051086, -2.667041063308716], [-0.20164965093135834, -1.700354814529419], [-0.038420967757701874, -3.278301954269409], [-0.030091023072600365, -3.5185353755950928], [-0.25898656249046326, -1.4776793718338013], [-0.10539071261882782, -2.3023135662078857], [-1.11423921585083, -0.39774224162101746], [-0.028315216302871704, -3.5784804821014404], [-0.09435845911502838, -2.4074630737304688], [-0.19092033803462982, -1.7498408555984497], [-0.4897404909133911, -0.9487762451171875], [-0.062301456928253174, -2.8067591190338135], [-0.1553339958190918, -1.9388396739959717], [-0.33423352241516113, -1.2583818435668945], [-0.27171453833580017, -1.4357863664627075], [-0.07741838693618774, -2.5969901084899902], [-4.613196849822998, -0.009969559498131275], [-0.13817289471626282, -2.0475406646728516], [-1.1352694034576416, -0.3876284062862396], [-0.04043598845601082, -3.228184938430786], [-0.9655150175094604, -0.4793059527873993], [-0.1357046216726303, -2.064359426498413], [-0.09675852209329605, -2.383526086807251], [-0.18865130841732025, -1.7606980800628662], [-0.5659696459770203, -0.8388882875442505], [-0.004008473828434944, -5.521352767944336], [-0.047280244529247284, -3.075209140777588], [-5.313731670379639, -0.0049356999807059765], [-0.22704048454761505, -1.5940005779266357], [-0.1408153772354126, -2.0298874378204346], [-0.33067071437835693, -1.2674157619476318], [-0.5938511490821838, -0.8034011125564575], [-0.707303524017334, -0.6791884303092957], [-0.004760360810905695, -5.3498215675354], [-0.08426658064126968, -2.5156073570251465], [-0.02198794297873974, -3.8282361030578613], [-0.6296290755271912, -0.7609750628471375], [-0.044597551226615906, -3.1322920322418213], [-0.7767124176025391, -0.6160297393798828], [-0.0650591179728508, -2.764812469482422], [-0.717533528804779, -0.6693414449691772], [-0.6648510098457336, -0.7222673892974854], [-0.03373682498931885, -3.405986785888672], [-0.06522420048713684, -2.762360095977783], [-0.6952444314956665, -0.6910542845726013], [-0.08004197478294373, -2.564957857131958], [-0.12718579173088074, -2.1250252723693848], [-0.04793030768632889, -3.0618765354156494], [-0.23395299911499023, -1.5673320293426514], [-0.129555344581604, -2.1077253818511963], [-0.27402788400650024, -1.428412675857544], [-0.14145326614379883, -2.0256786346435547], [-0.39914432168006897, -1.1113749742507935], [-0.42922139167785645, -1.0527286529541016], [-0.2664944529533386, -1.4526915550231934], [-0.10397569090127945, -2.315135955810547], [-0.34363532066345215, -1.2350764274597168], [-0.5690864324569702, -0.834808349609375], [-0.4373306334018707, -1.037774682044983], [-0.501991331577301, -0.9296902418136597], [-0.5493794083595276, -0.8611114025115967], [-0.19494973123073578, -1.730905294418335], [-4.017159461975098, -0.01816810667514801], [-1.0250389575958252, -0.44438666105270386], [-0.37783345580101013, -1.1562772989273071], [-0.7308028936386108, -0.6568580269813538], [-0.8376733660697937, -0.5668954849243164], [-0.8314712643623352, -0.5716522932052612], [-0.16563571989536285, -1.8796391487121582], [-0.13688993453979492, -2.0562422275543213], [-0.05400592088699341, -2.945542573928833], [-0.03008824773132801, -3.5186281204223633], [-0.3898877501487732, -1.13051438331604], [-0.057068731635808945, -2.8918986320495605], [-0.3900618255138397, -1.130149483680725], [-0.30047595500946045, -1.348866581916809], [-0.03483356535434723, -3.3745405673980713], [-0.07756809145212173, -2.5951321125030518], [-0.1532781571149826, -1.9511609077453613], [-0.5565652251243591, -0.8513797521591187], [-1.3647332191467285, -0.2949736714363098], [-0.010863802395761013, -4.527740955352783], [-0.057911500334739685, -2.8776559829711914], [-0.05964432656764984, -2.849029541015625], [-0.29816296696662903, -1.3554952144622803], [-0.031614236533641815, -3.4699151515960693], [-0.22933770716190338, -1.5850379467010498], [-0.5545526742935181, -0.8540887832641602], [-0.12952476739883423, -2.1079461574554443], [-0.3307669758796692, -1.2671701908111572], [-0.05964432656764984, -2.849029541015625], [-0.06311330199241638, -2.7942147254943848], [-0.368155300617218, -1.1776869297027588], [-0.0600040927529335, -2.8431951999664307], [-0.11566915363073349, -2.2142980098724365], [-0.7085469961166382, -0.677980899810791], [-0.09035378694534302, -2.4488589763641357], [-0.106316477060318, -2.29402232170105], [-0.0616309717297554, -2.817248582839966], [-0.08357075601816177, -2.5235555171966553], [-1.5503418445587158, -0.2384798228740692], [-0.803952693939209, -0.5934039950370789], [-0.6195688247680664, -0.7725723385810852], [-0.2947259247303009, -1.3654556274414062], [-0.016940532252192497, -4.086503505706787], [-0.08863478899002075, -2.4672210216522217], [-0.05964432656764984, -2.849029541015625], [-0.3095828592777252, -1.3233307600021362], [-0.7810615301132202, -0.612341046333313], [-0.3217335045337677, -1.2905892133712769], [-0.1873641312122345, -1.766921043395996], [-0.15195044875144958, -1.959214448928833], [-0.06822862476110458, -2.718810796737671], [-1.8979482650756836, -0.16237284243106842], [-0.29769837856292725, -1.356833577156067], [-0.09373311698436737, -2.4138035774230957], [-0.5311598181724548, -0.886544406414032], [-0.004510229919105768, -5.403656482696533], [-0.3457046151161194, -1.2300481796264648], [-0.05964432656764984, -2.849029541015625], [-0.05306026339530945, -2.962740182876587], [-0.3092115819454193, -1.3243547677993774], [-0.12114385515451431, -2.1707372665405273], [-0.18736116588115692, -1.7669352293014526], [-0.8635220527648926, -0.54761803150177], [-0.0017976091476157308, -6.322171211242676], [-0.1469365656375885, -1.9903231859207153], [-0.08789821714162827, -2.475203037261963], [-0.024504279717803, -3.721135139465332], [-0.019724301993846893, -3.935751438140869], [-0.09506232291460037, -2.400376796722412], [-0.4747564494609833, -0.9729576110839844], [-0.6911742687225342, -0.6951239705085754], [-0.3802037835121155, -1.1511340141296387], [-0.2235627919435501, -1.6077628135681152], [-1.0899893045425415, -0.4098045825958252], [-0.2035970240831375, -1.6916848421096802], [-0.09275868535041809, -2.4237747192382812], [-0.29253867268562317, -1.3718643188476562], [-0.08005297929048538, -2.564826726913452], [-0.014507056213915348, -4.240365028381348], [-0.06517460942268372, -2.763094902038574], [-0.11606579273939133, -2.211069345474243], [-0.17415519058704376, -1.833622694015503], [-0.39091041684150696, -1.1283730268478394], [-0.08496992290019989, -2.5076427459716797], [-0.54582279920578, -0.8659895658493042], [-0.3124297261238098, -1.3155269622802734], [-0.016105787828564644, -4.136616230010986], [-0.2336082011461258, -1.568641185760498], [-0.002906029811128974, -5.842438697814941], [-0.05589151754975319, -2.9121580123901367], [-0.36439427733421326, -1.1861894130706787], [-1.0205464363098145, -0.44690901041030884], [-0.6317048668861389, -0.758613109588623], [-0.35320693254470825, -1.2121119499206543], [-0.14919525384902954, -1.9761695861816406], [-0.33912578225135803, -1.2461597919464111], [-0.6079172492027283, -0.7863237261772156], [-0.4342235028743744, -1.0434635877609253], [-0.27027347683906555, -1.440415859222412], [-0.6519047021865845, -0.7361641526222229], [-0.2860832214355469, -1.391106367111206], [-0.12152639776468277, -2.167772054672241], [-0.31052708625793457, -1.3207330703735352], [-0.005714745726436377, -5.167557716369629], [-0.14856506884098053, -1.980095624923706], [-0.04487865790724754, -3.126147508621216], [-0.06502572447061539, -2.7653088569641113], [-0.4949670433998108, -0.9405604600906372], [-0.00582864647731185, -5.14789342880249], [-0.589335560798645, -0.808997631072998], [-0.07074179500341415, -2.6838817596435547], [-1.6298136711120605, -0.21811383962631226], [-0.386573851108551, -1.137500286102295], [-0.19383211433887482, -1.7361140251159668], [-0.6085031628608704, -0.7856239676475525], [-0.06397436559200287, -2.7810893058776855], [-0.19780980050563812, -1.7177245616912842], [-0.1803639531135559, -1.801605463027954], [-0.051904913038015366, -2.9841811656951904], [-0.16036932170391083, -1.9093893766403198], [-0.18839116394519806, -1.7619519233703613], [-0.19669997692108154, -1.7228143215179443], [-0.23096902668476105, -1.5787345170974731], [-0.2555871903896332, -1.4892648458480835], [-0.20025236904621124, -1.7066328525543213], [-0.1867707073688507, -1.769805669784546], [-0.17457544803619385, -1.8314164876937866], [-0.22224153578281403, -1.6130539178848267], [-0.11117283254861832, -2.2517411708831787], [-2.202871084213257, -0.11707950383424759], [-1.9300384521484375, -0.15682059526443481], [-0.09601112455129623, -2.3909130096435547], [-0.4030398428440094, -1.1034804582595825], [-0.4447614550590515, -1.024369239807129], [-1.1459461450576782, -0.3826126158237457], [-0.9699647426605225, -0.476579487323761], [-0.22760507464408875, -1.5917881727218628], [-0.03310122713446617, -3.4246907234191895], [-1.21753990650177, -0.35091638565063477], [-0.21028707921504974, -1.662583589553833], [-1.0067505836486816, -0.45476728677749634], [-0.05690613016486168, -2.894669532775879], [-0.04469889774918556, -3.130072832107544], [-0.08383586257696152, -2.520519971847534], [-0.31078818440437317, -1.3200163841247559], [-0.4467106759548187, -1.0208985805511475], [-0.15775954723358154, -1.9245266914367676], [-0.15163284540176392, -1.9611515998840332], [-0.022596146911382675, -3.801250457763672], [-0.4988881051540375, -0.9344685077667236], [-0.016235167160630226, -4.128681182861328], [-0.5190494656562805, -0.9040803909301758], [-0.08467477560043335, -2.5109763145446777], [-0.13408485054969788, -2.075576066970825], [-0.06162424385547638, -2.8173537254333496], [-0.37067899107933044, -1.1720397472381592], [-0.24673151969909668, -1.52028489112854], [-0.4219411611557007, -1.0664527416229248], [-2.1484181880950928, -0.12405481934547424], [-1.7057549953460693, -0.20044700801372528], [-0.29199856519699097, -1.37345552444458], [-0.34626737236976624, -1.2286869287490845], [-1.2955517768859863, -0.31985655426979065], [-0.06983918696641922, -2.6962759494781494], [-0.8717139363288879, -0.5416872501373291], [-0.05885528028011322, -2.861956834793091], [-0.4652966856956482, -0.9887238144874573], [-0.27444589138031006, -1.4270879030227661], [-0.004317249171435833, -5.4472808837890625], [-0.41291332244873047, -1.0838803052902222], [-0.018289843574166298, -4.010543346405029], [-0.19059014320373535, -1.7514121532440186], [-0.22738316655158997, -1.5926570892333984], [-0.06444782018661499, -2.7739505767822266], [-0.2939082980155945, -1.367844820022583], [-0.10140819847583771, -2.338876724243164], [-0.29366862773895264, -1.3685466051101685], [-0.09043928235769272, -2.447955846786499], [-0.3440015912055969, -1.2341840267181396], [-1.7700518369674683, -0.18672026693820953], [-0.08973824977874756, -2.455392360687256], [-0.2245725691318512, -1.603742241859436], [-0.05648542195558548, -2.9018819332122803], [-0.1480661928653717, -1.9832156896591187], [-0.5661196708679199, -0.8386915326118469], [-0.031719449907541275, -3.466644048690796], [-0.024583958089351654, -3.717925786972046], [-0.3719879686832428, -1.1691287755966187], [-1.4438897371292114, -0.269197940826416], [-2.9738214015960693, -0.05245990306138992], [-0.04550032690167427, -3.1127007007598877], [-0.5198516845703125, -0.9029027223587036], [-0.13368579745292664, -2.0783610343933105], [-0.11779077351093292, -2.1971628665924072], [-0.024487411603331566, -3.7218146324157715], [-0.10931703448295593, -2.2676632404327393], [-0.04881793260574341, -3.0439679622650146], [-0.1320732980966568, -2.0897083282470703], [-0.36146730184555054, -1.1928789615631104], [-0.5382318496704102, -0.8765402436256409], [-0.6628734469413757, -0.7243661284446716], [-0.11671508848667145, -2.2058095932006836], [-0.058616410940885544, -2.86590576171875], [-3.5176570415496826, -0.030117860063910484], [-0.1174178197979927, -2.200150966644287], [-0.04646146669983864, -3.092272996902466], [-0.9577474594116211, -0.48411285877227783], [-1.361043930053711, -0.2962426543235779], [-0.14985787868499756, -1.972061038017273], [-0.013892851769924164, -4.283318042755127], [-0.17782436311244965, -1.8145538568496704], [-0.3316175043582916, -1.26500403881073], [-0.017634976655244827, -4.046677112579346], [-0.4623488187789917, -0.9937189221382141], [-0.6074344515800476, -0.7869011759757996], [-1.1425501108169556, -0.3841995298862457], [-0.5626979470252991, -0.843203067779541], [-0.7497400641441345, -0.6395862698554993], [-0.3912629187107086, -1.127636432647705], [-0.04350770637392998, -3.1564927101135254], [-0.526054859161377, -0.8938731551170349], [-0.4644462466239929, -0.9901606440544128], [-0.06174304708838463, -2.8154869079589844], [-0.3018663823604584, -1.344909906387329], [-0.06446268409490585, -2.7737269401550293], [-0.6880772709846497, -0.6982429623603821], [-0.375143826007843, -1.162160873413086], [-0.06092481687664986, -2.828423023223877], [-0.017768491059541702, -4.0391998291015625], [-0.23337091505527496, -1.569543480873108], [-0.22701512277126312, -1.5940998792648315], [-0.5655719637870789, -0.8394110202789307], [-0.014202586375176907, -4.261423110961914], [-1.9159398078918457, -0.1592342108488083], [-1.0790205001831055, -0.41540685296058655], [-0.49163609743118286, -0.9457837343215942], [-0.017216281965374947, -4.070492267608643], [-0.06333667039871216, -2.7907917499542236], [-0.23368671536445618, -1.568342924118042], [-0.6492845416069031, -0.7390223741531372], [-0.28090962767601013, -1.4068915843963623], [-0.32594600319862366, -1.279573678970337], [-0.22526513040065765, -1.6009963750839233], [-0.3072114586830139, -1.329895257949829], [-0.3149900734424591, -1.3085784912109375], [-0.3530748784542084, -1.2124236822128296], [-0.011480930261313915, -4.472806930541992], [-0.24344222247600555, -1.5321283340454102], [-0.8409199714660645, -0.5644259452819824], [-0.23426492512226105, -1.5661495923995972], [-0.1426396369934082, -2.0179061889648438], [-0.42429783940315247, -1.0619786977767944], [-0.32148027420043945, -1.2912567853927612], [-0.08549745380878448, -2.501713275909424], [-0.7873250246047974, -0.607080340385437], [-0.5198466777801514, -0.902910053730011], [-0.18865594267845154, -1.7606756687164307], [-0.1759725660085678, -1.8241236209869385], [-0.017900697886943817, -4.031851291656494], [-4.384532451629639, -0.012547126039862633], [-0.3955097496509552, -1.1188254356384277], [-0.1455904096364975, -1.9988703727722168], [-0.09974156320095062, -2.354628562927246], [-0.3034861087799072, -1.3403279781341553], [-0.09658611565828323, -2.3852243423461914], [-0.15349812805652618, -1.9498343467712402], [-0.4108828604221344, -1.0878639221191406], [-0.2280021458864212, -1.5902363061904907], [-0.2601079046726227, -1.4738951921463013], [-0.32743701338768005, -1.275714635848999], [-0.5521445870399475, -0.8573470711708069], [-0.7599103450775146, -0.6305636763572693], [-0.33668363094329834, -1.2522348165512085], [-0.024395044893026352, -3.7255465984344482], [-0.1680842936038971, -1.866154670715332], [-0.09632545709609985, -2.38779878616333], [-0.014735200442373753, -4.224870681762695], [-0.044545333832502365, -3.1334381103515625], [-0.35359087586402893, -1.211206316947937], [-0.056857701390981674, -2.8954977989196777], [-0.5746047496795654, -0.8276558518409729], [-1.000955581665039, -0.4581194519996643], [-1.467726230621338, -0.2619479298591614], [-0.6519075632095337, -0.7361609935760498], [-0.23644287884235382, -1.5579417943954468], [-0.22621537744998932, -1.5972437858581543], [-0.23634444177150726, -1.5583109855651855], [-0.4199509024620056, -1.0702556371688843], [-0.6046947240829468, -0.7901895642280579], [-0.4080723822116852, -1.093418002128601], [-0.143663227558136, -2.0112547874450684], [-0.012680025771260262, -4.374060153961182], [-0.13385005295276642, -2.0772135257720947], [-0.27298158407211304, -1.4317388534545898], [-0.445862352848053, -1.0224066972732544], [-0.011374271474778652, -4.482081413269043], [-0.42495742440223694, -1.0607317686080933], [-2.7303307056427, -0.06742025166749954], [-0.07550998032093048, -2.6210083961486816], [-0.05008808895945549, -3.0189120769500732], [-0.24817803502082825, -1.5151327848434448], [-0.707303524017334, -0.6791884303092957], [-0.24191810190677643, -1.5376777648925781], [-0.15034499764442444, -1.9690537452697754], [-0.36324429512023926, -1.1888102293014526], [-0.6149224042892456, -0.7780143022537231], [-0.29089173674583435, -1.376726508140564], [-0.7320672273635864, -0.6556853652000427], [-0.042308125644922256, -3.1838552951812744], [-0.16890670359134674, -1.8616735935211182], [-0.38736921548843384, -1.135817050933838], [-0.0015562577173113823, -6.466261863708496], [-0.0050152926705777645, -5.297780990600586], [-0.271022766828537, -1.4380050897598267], [-0.25584280490875244, -1.4883877038955688], [-0.1792537122964859, -1.807241439819336], [-0.3616575598716736, -1.1924424171447754], [-0.138815775513649, -2.043212652206421], [-0.276751846075058, -1.4198205471038818], [-0.06982617825269699, -2.696455955505371], [-0.5530937910079956, -0.8560606241226196], [-0.3514605164527893, -1.2162466049194336], [-0.37884119153022766, -1.1540859937667847], [-0.369026243686676, -1.1757330894470215], [-0.2878880798816681, -1.385676622390747], [-0.09402451664209366, -2.4108433723449707], [-0.3460511565208435, -1.229209542274475], [-0.14040429890155792, -2.032609462738037], [-0.9942213892936707, -0.4620535969734192], [-0.571495532989502, -0.8316746950149536], [-0.6468760967254639, -0.7416636943817139], [-0.5049316883087158, -0.9251974821090698], [-0.5367891788482666, -0.8785670399665833], [-0.8548445701599121, -0.5539928078651428], [-0.18425846099853516, -1.7821310758590698], [-0.16712172329425812, -1.8714302778244019], [-0.5296532511711121, -0.8886975646018982], [-0.03244341164827347, -3.4444375038146973], [-0.21232618391513824, -1.6539169549942017], [-0.002333776792511344, -6.0614213943481445], [-0.0018979170126840472, -6.267975330352783], [-0.09995635598897934, -2.352583885192871], [-0.08469340205192566, -2.5107650756835938], [-0.2980114817619324, -1.355931043624878], [-0.6579822897911072, -0.729593813419342], [-0.9469791650772095, -0.4908776879310608], [-1.287979245185852, -0.3227258026599884], [-0.29966557025909424, -1.3511821031570435], [-0.3371793031692505, -1.2509974241256714], [-0.5749202370643616, -0.8272497653961182], [-0.4623628854751587, -0.9936950206756592], [-2.347245454788208, -0.10051917284727097], [-0.4530717432498932, -1.0097023248672485], [-0.11539355665445328, -2.216548442840576], [-0.10414456576108932, -2.3135952949523926], [-0.77823805809021, -0.6147323846817017], [-0.707303524017334, -0.6791884303092957], [-0.0072072274051606655, -4.936267375946045], [-0.12074615806341171, -2.173830509185791], [-0.3360905945301056, -1.2537178993225098], [-0.057262152433395386, -2.8886096477508545], [-0.12173835188150406, -2.166133165359497], [-1.030011534690857, -0.44161495566368103], [-0.22028407454490662, -1.6209584474563599], [-0.3182297646999359, -1.2998803853988647], [-0.0514095164835453, -2.99352765083313], [-1.5186351537704468, -0.24719369411468506], [-0.11410260945558548, -2.227165937423706], [-0.7474231719970703, -0.6416659951210022], [-0.006093377247452736, -5.103588581085205], [-0.9233837127685547, -0.50612473487854], [-0.24748189747333527, -1.5176080465316772], [-0.20232409238815308, -1.6973414421081543], [-0.06261537224054337, -2.801888942718506], [-1.3386540412902832, -0.30408021807670593], [-0.16027742624282837, -1.9099178314208984], [-0.3590308129787445, -1.1984974145889282], [-0.7210202813148499, -0.6660299897193909], [-0.004739954136312008, -5.35410737991333], [-0.46044737100601196, -0.9969620704650879], [-0.7658220529556274, -0.6253980398178101], [-0.020504528656601906, -3.8973464965820312], [-0.018998557701706886, -3.9728760719299316], [-1.4347275495529175, -0.2720452547073364], [-3.0177273750305176, -0.05014897510409355], [-0.29998451471328735, -1.3502700328826904], [-0.576971173286438, -0.8246161937713623], [-0.7160901427268982, -0.6707189083099365], [-0.16066142916679382, -1.907711148262024], [-0.01231388933956623, -4.403177738189697], [-0.22639277577400208, -1.596545696258545], [-0.28561654686927795, -1.3925164937973022], [-0.003093103179708123, -5.78010892868042], [-0.8735092282295227, -0.5403984785079956], [-0.012570316903293133, -4.382697582244873], [-0.13525864481925964, -2.0674338340759277], [-0.29007434844970703, -1.3791518211364746], [-0.7577798366546631, -0.6324394941329956], [-0.11709127575159073, -2.2027761936187744], [-0.006750043015927076, -5.001572608947754], [-0.017375392839312553, -4.061378002166748], [-0.0619148388504982, -2.812793254852295], [-1.3612209558486938, -0.2961815595626831], [-0.24768348038196564, -1.516890525817871], [-0.13830764591693878, -2.046631336212158], [-0.06664814054965973, -2.741467237472534], [-0.5369118452072144, -0.878394603729248], [-0.2155344933271408, -1.6404664516448975], [-0.0767388641834259, -2.605470657348633], [-0.9540866613388062, -0.4863993227481842], [-0.3374923765659332, -1.250217080116272], [-0.03874773904681206, -3.26999568939209], [-0.46243035793304443, -0.9935801029205322], [-2.45009183883667, -0.09023724496364594], [-0.5203405022621155, -0.9021860361099243], [-0.17490647733211517, -1.82968270778656], [-0.11349759250879288, -2.2321856021881104], [-0.005340120755136013, -5.235175609588623], [-0.9388051629066467, -0.4960927665233612], [-0.03588298335671425, -3.3453805446624756], [-0.1545116901397705, -1.94374680519104], [-1.1491382122039795, -0.3811282813549042], [-0.0786234438419342, -2.5821402072906494], [-0.16522471606731415, -1.881923794746399], [-0.052066635340452194, -2.981152057647705], [-0.015481649897992611, -4.175830364227295], [-0.16690927743911743, -1.872598648071289], [-0.3171124756336212, -1.3028684854507446], [-0.19305136799812317, -1.7397723197937012], [-0.01578127034008503, -4.1568098068237305], [-0.11633727699518204, -2.2088661193847656], [-0.10427851229906082, -2.312376022338867], [-1.7013450860977173, -0.20142853260040283], [-0.33757999539375305, -1.2499991655349731], [-3.884901523590088, -0.020763885229825974], [-0.22376582026481628, -1.6069529056549072], [-0.28339678049087524, -1.399261474609375], [-0.6206695437431335, -0.7712912559509277], [-0.005345456302165985, -5.234175205230713], [-0.2944071590900421, -1.3663862943649292], [-0.08755064010620117, -2.4789936542510986], [-0.4247923195362091, -1.061043620109558], [-0.3460511565208435, -1.229209542274475], [-0.5975461006164551, -0.7988632917404175], [-0.3260274827480316, -1.2793623208999634], [-0.017693771049380302, -4.043374061584473], [-0.2026524841785431, -1.6958783864974976], [-0.27376455068588257, -1.429248332977295], [-0.0352899432182312, -3.3617489337921143], [-0.15939980745315552, -1.9149813652038574], [-1.008728265762329, -0.45363038778305054], [-0.7901345491409302, -0.6047403216362], [-0.3903048038482666, -1.1296404600143433], [-0.19024111330509186, -1.753076195716858], [-0.15810003876686096, -1.9225358963012695], [-0.30298179388046265, -1.3417515754699707], [-0.006397363729774952, -5.055072784423828], [-0.1957109570503235, -1.7273764610290527], [-0.07336720079183578, -2.6487374305725098], [-0.12791119515895844, -2.1196932792663574], [-0.07319437712430954, -2.6510112285614014], [-0.897598385810852, -0.5234842300415039], [-0.16367758810520172, -1.8905792236328125], [-0.13565883040428162, -2.0646748542785645], [-0.8219393491744995, -0.5790657997131348], [-0.5608699321746826, -0.8456282019615173], [-0.3730130195617676, -1.1668578386306763], [-0.1968018114566803, -1.7223455905914307], [-0.10570801049470901, -2.2994632720947266], [-0.951489269733429, -0.4880298972129822], [-0.525496244430542, -0.8946807384490967], [-0.9402506351470947, -0.49516546726226807], [-0.02879508025944233, -3.561915397644043], [-0.1455904096364975, -1.9988703727722168], [-0.2087990790605545, -1.668966293334961], [-0.18533949553966522, -1.7768049240112305], [-0.5687410831451416, -0.8352588415145874], [-0.34174269437789917, -1.2397072315216064], [-1.3581509590148926, -0.2972419559955597], [-0.2794344425201416, -1.4114532470703125], [-0.43679672479629517, -1.0387487411499023], [-0.1516178846359253, -1.9612427949905396], [-0.3033936023712158, -1.3405888080596924], [-0.11976852267980576, -2.181480884552002], [-0.3254721164703369, -1.2808046340942383], [-0.09345564246177673, -2.4166324138641357], [-0.6162049770355225, -0.7765065431594849], [-1.204977035522461, -0.35624486207962036], [-0.41702505946159363, -1.0758857727050781], [-0.005217388737946749, -5.258364677429199], [-0.10079167038202286, -2.344672679901123], [-0.3082543611526489, -1.3270009756088257], [-0.06054854765534401, -2.834430694580078], [-0.08389867097139359, -2.5198020935058594], [-1.748895525932312, -0.1911192685365677], [-0.707303524017334, -0.6791884303092957], [-0.3149900734424591, -1.3085784912109375], [-0.1049804762005806, -2.30601167678833], [-0.2720348834991455, -1.4347606897354126], [-0.45169657468795776, -1.01210618019104], [-0.492695152759552, -0.9441180229187012], [-0.03910088539123535, -3.2610981464385986], [-0.5606125593185425, -0.8459703922271729], [-0.09331166744232178, -2.4181036949157715], [-1.669511079788208, -0.2086726278066635], [-0.6149410605430603, -0.7779923677444458], [-0.006408261135220528, -5.053377151489258], [-0.040198858827352524, -3.233949899673462], [-0.8166921734809875, -0.5832009315490723], [-0.055899519473314285, -2.9120194911956787], [-1.0620025396347046, -0.4242852032184601], [-0.03004486858844757, -3.5200469493865967], [-0.3260428011417389, -1.279322624206543], [-0.08174854516983032, -2.544703483581543], [-0.5551792979240417, -0.8532440662384033], [-0.2309613674879074, -1.5787639617919922], [-2.332702159881592, -0.1020694449543953], [-0.04766562581062317, -3.0672824382781982], [-0.10461699217557907, -2.3093013763427734], [-0.30361688137054443, -1.339958906173706], [-0.08293051272630692, -2.530930995941162], [-0.006082239560782909, -5.105416774749756], [-0.7223429083824158, -0.6647797226905823], [-0.3774423599243164, -1.1571297645568848], [-0.057189203798770905, -2.8898494243621826], [-0.5346653461456299, -0.8815640211105347], [-0.7252059578895569, -0.6620844006538391], [-0.12232238054275513, -2.161633253097534], [-0.01179494708776474, -4.445977687835693], [-0.3011282980442047, -1.3470072746276855], [-0.20629644393920898, -1.679816722869873], [-1.195382833480835, -0.3603791296482086], [-0.4283149838447571, -1.0544216632843018], [-0.13050955533981323, -2.1008543968200684], [-0.12440225481987, -2.1457912921905518], [-0.17748922109603882, -1.8162779808044434], [-0.10186092555522919, -2.3346445560455322], [-0.1542949080467224, -1.9450452327728271], [-0.5164264440536499, -0.9079478979110718], [-0.05544568598270416, -2.9199461936950684], [-0.5830171704292297, -0.8169242143630981], [-0.37417498230934143, -1.1642924547195435], [-0.2777065336704254, -1.4168323278427124], [-0.16320452094078064, -1.893243670463562], [-0.5037818551063538, -0.9269505143165588], [-0.03432318568229675, -3.3890466690063477], [-0.7641458511352539, -0.6268569231033325], [-0.0024880189448595047, -5.997520446777344], [-0.4002060890197754, -1.1092140674591064], [-0.3003202974796295, -1.3493105173110962], [-0.2729322910308838, -1.4318959712982178], [-0.03957732394337654, -3.2492220401763916], [-0.10648217052221298, -2.292546033859253], [-0.17214395105838776, -1.8442621231079102], [-0.8230565786361694, -0.5781903266906738], [-0.19784961640834808, -1.717542290687561], [-0.09410372376441956, -2.4100403785705566], [-0.3016648590564728, -1.3454821109771729], [-0.37546226382255554, -1.1614614725112915], [-0.35904520750045776, -1.1984639167785645], [-0.0035761946346610785, -5.635254383087158], [-0.17762546241283417, -1.8155766725540161], [-0.00849703699350357, -4.772287368774414], [-0.08133629709482193, -2.5495545864105225], [-0.37411069869995117, -1.1644341945648193], [-0.010494759306311607, -4.562121391296387], [-0.05279580503702164, -2.967604637145996], [-0.029036547988653183, -3.553684949874878], [-0.0884123146533966, -2.4696247577667236], [-0.03322150558233261, -3.421124219894409], [-0.05847474932670593, -2.868256092071533], [-1.5123049020767212, -0.24897611141204834], [-0.011578621342778206, -4.464383125305176], [-0.49561822414398193, -0.9395444393157959], [-0.11099446564912796, -2.2532594203948975], [-0.2902008295059204, -1.3787758350372314], [-0.22397632896900177, -1.6061139106750488], [-0.016686394810676575, -4.101491451263428], [-0.18252412974834442, -1.7907472848892212], [-0.08152937144041061, -2.5472800731658936], [-4.387695789337158, -0.01250721700489521], [-0.3477465808391571, -1.2251209020614624], [-0.3303266167640686, -1.268294095993042], [-0.22631539404392242, -1.5968499183654785], [-0.18268005549907684, -1.7899690866470337], [-0.08916334062814713, -2.4615354537963867], [-0.08756790310144424, -2.4788055419921875], [-0.004969625733792782, -5.306896209716797], [-0.33670634031295776, -1.2521779537200928], [-0.2557432949542999, -1.4887292385101318], [-0.08880922198295593, -2.4653408527374268], [-0.0032726561184972525, -5.723788261413574], [-0.029803181067109108, -3.528003692626953], [-0.05925196036696434, -2.855435848236084], [-0.0579451359808445, -2.8770923614501953], [-0.7412428259849548, -0.6472590565681458], [-1.1261844635009766, -0.39195898175239563], [-0.027763700112700462, -3.597876787185669], [-0.8200708627700806, -0.5805338025093079], [-0.629469633102417, -0.7611570358276367], [-0.08481277525424957, -2.509416341781616], [-0.03615160658955574, -3.3380539417266846], [-0.05090809613466263, -3.003079414367676], [-0.11524803191423416, -2.2177391052246094], [-0.12424539774656296, -2.1469759941101074], [-0.006388598587363958, -5.056426048278809], [-0.056040871888399124, -2.909562587738037], [-0.07653426378965378, -2.6080403327941895], [-0.439730167388916, -1.0334153175354004], [-0.02981209009885788, -3.5277099609375], [-0.44625505805015564, -1.021708369255066], [-0.016031414270401, -4.141206741333008], [-1.6517541408538818, -0.21283844113349915], [-0.12870903313159943, -2.113865375518799], [-0.2662356197834015, -1.4535398483276367], [-0.10060109943151474, -2.346470832824707], [-0.43573203682899475, -1.040695309638977], [-0.029261400923132896, -3.5460798740386963], [-0.6025297045707703, -0.7928017973899841], [-0.7686172723770142, -0.6229753494262695], [-0.08594255894422531, -2.496739625930786], [-0.17089451849460602, -1.850939154624939], [-0.15723079442977905, -1.927626132965088], [-0.5122802257537842, -0.9141127467155457], [-0.04423470422625542, -3.14028263092041], [-0.4609864354133606, -0.9960408806800842], [-0.7496233582496643, -0.6396907567977905], [-0.6358240842819214, -0.753957211971283], [-0.9213876724243164, -0.5074419975280762], [-0.45014697313308716, -1.0148259401321411], [-0.5267959833145142, -0.892803430557251], [-0.07859181612730026, -2.582526683807373], [-1.0220612287521362, -0.446056604385376], [-0.14981478452682495, -1.9723281860351562], [-0.0062719183042645454, -5.074798107147217], [-0.15143562853336334, -1.9623569250106812], [-0.3909676671028137, -1.12825345993042], [-0.7393156290054321, -0.6490166783332825], [-0.03288242593407631, -3.4312124252319336], [-0.4535447955131531, -1.0088773965835571], [-0.7482516765594482, -0.6409212946891785], [-0.357454389333725, -1.2021565437316895], [-0.06706436723470688, -2.735447645187378], [-0.5146018266677856, -0.9106531143188477], [-0.27715083956718445, -1.4185702800750732], [-0.1415458768606186, -2.0250699520111084], [-0.05302216485142708, -2.9634385108947754], [-0.033727604895830154, -3.4062538146972656], [-0.6196192502975464, -0.7725136280059814], [-0.08349213004112244, -2.524458169937134], [-0.12691324949264526, -2.127037525177002], [-1.5992785692214966, -0.2256995588541031], [-0.16418574750423431, -1.8877265453338623], [-0.42679664492607117, -1.0572675466537476], [-0.0517398826777935, -2.9872844219207764], [-1.1834521293640137, -0.36560001969337463], [-0.12918351590633392, -2.1104183197021484], [-0.3385949432849884, -1.2474758625030518], [-0.39311957359313965, -1.1237702369689941], [-0.22224870324134827, -1.613025188446045], [-0.17126332223415375, -1.848962664604187], [-0.03316396102309227, -3.4228293895721436], [-0.5009599924087524, -0.9312741756439209], [-0.044379767030477524, -3.137078285217285], [-0.4032541811466217, -1.1030486822128296], [-0.43632030487060547, -1.039618968963623], [-2.029265880584717, -0.14090929925441742], [-0.004236770328134298, -5.466067790985107], [-0.06834208220243454, -2.717205286026001], [-0.06050579622387886, -2.8351173400878906], [-0.2503930330276489, -1.507308840751648], [-0.21867850422859192, -1.627500295639038], [-0.8760026693344116, -0.5386154651641846], [-0.00997132994234562, -4.613017559051514], [-0.04893917590379715, -3.04154634475708], [-0.2641740143299103, -1.4603278636932373], [-0.41805148124694824, -1.073905110359192], [-0.07612306624650955, -2.613224506378174], [-0.35304707288742065, -1.212489366531372], [-0.573000967502594, -0.8297251462936401], [-0.3014327883720398, -1.3461415767669678], [-0.411965012550354, -1.085737943649292], [-1.4562039375305176, -0.26542431116104126], [-0.07124191522598267, -2.6770834922790527], [-0.2199210524559021, -1.6224329471588135], [-0.1620674580335617, -1.8996820449829102], [-0.5330421924591064, -0.8838648796081543], [-0.6346834897994995, -0.7552421689033508], [-0.6439021229743958, -0.7449434399604797], [-0.17145033180713654, -1.8479626178741455], [-0.1110631674528122, -2.2526743412017822], [-0.019247079268097878, -3.9600069522857666], [-0.06255993992090225, -2.8027470111846924], [-0.7552104592323303, -0.6347116231918335], [-0.37872716784477234, -1.1543333530426025], [-0.10776853561401367, -2.281169891357422], [-0.24124839901924133, -1.5401285886764526], [-0.40245428681373596, -1.1046613454818726], [-0.0030579257290810347, -5.79154634475708], [-0.4003840684890747, -1.1088523864746094], [-0.23228013515472412, -1.5737041234970093], [-0.7162224054336548, -0.6705926060676575], [-0.10000532865524292, -2.3521177768707275], [-0.20722311735153198, -1.6757819652557373], [-0.4936721920967102, -0.9425854682922363], [-0.05406961962580681, -2.944395065307617], [-0.21306109428405762, -1.6508162021636963], [-2.0114078521728516, -0.1436396837234497], [-0.05964432656764984, -2.849029541015625], [-0.17656762897968292, -1.821036458015442], [-2.4741177558898926, -0.08799800276756287], [-0.30163222551345825, -1.3455750942230225], [-0.12210369110107422, -2.1633152961730957], [-0.2042383849620819, -1.6888493299484253], [-0.17047080397605896, -1.8532161712646484], [-0.057980459183454514, -2.8764986991882324], [-0.3741416037082672, -1.1643658876419067], [-0.10774841904640198, -2.2813472747802734], [-0.6482031345367432, -0.7402066588401794], [-0.15303903818130493, -1.952605962753296], [-0.13995222747325897, -2.035614490509033], [-0.22839488089084625, -1.588704228401184], [-0.7342267036437988, -0.6536888480186462], [-0.4839015603065491, -0.9580867290496826], [-0.015779277309775352, -4.156938552856445], [-0.17995278537273407, -1.803688406944275], [-0.11741802841424942, -2.2001492977142334], [-0.5936859846115112, -0.8036047220230103], [-0.11498167365789413, -2.2199230194091797], [-0.014639578759670258, -4.231337070465088], [-0.17357683181762695, -1.8366680145263672], [-0.34300529956817627, -1.23661470413208], [-0.09934055060148239, -2.3584601879119873], [-0.04161551967263222, -3.200018882751465], [-0.3852796256542206, -1.1402482986450195], [-0.1228020042181015, -2.1579549312591553], [-0.23136703670024872, -1.5772039890289307], [-0.12843574583530426, -2.1158571243286133], [-0.02947833389043808, -3.5388009548187256], [-0.17187345027923584, -1.8457030057907104], [-0.5172640085220337, -0.906710147857666], [-0.7104831337928772, -0.6761066913604736], [-0.19178520143032074, -1.7457398176193237], [-0.23139560222625732, -1.5770941972732544], [-0.378091424703598, -1.1557157039642334], [-0.20805492997169495, -1.6721774339675903], [-1.509289026260376, -0.24983029067516327], [-0.14983992278575897, -1.972172498703003], [-0.3052699565887451, -1.3353137969970703], [-0.14608794450759888, -1.9957010746002197], [-0.3197486698627472, -1.2958381175994873], [-0.3211131989955902, -1.2922253608703613], [-0.422749787569046, -1.0649142265319824], [-0.15840420126914978, -1.9207621812820435], [-1.2001533508300781, -0.3583163619041443], [-0.15852832794189453, -1.920039176940918], [-0.19213221967220306, -1.7440999746322632], [-0.005558036733418703, -5.195293426513672], [-0.2554969787597656, -1.489574909210205], [-0.09232910722494125, -2.4282054901123047], [-0.07901136577129364, -2.577408790588379], [-0.05171860381960869, -2.9876863956451416], [-0.021560685709118843, -3.8476428985595703], [-0.40791431069374084, -1.0937317609786987], [-0.7133519053459167, -0.6733426451683044], [-0.07732857763767242, -2.59810733795166], [-2.7139248847961426, -0.06857451796531677], [-0.3177407383918762, -1.3011868000030518], [-1.2859466075897217, -0.3235010802745819], [-0.06984785944223404, -2.6961557865142822], [-0.5430821776390076, -0.869776725769043], [-0.019805297255516052, -3.931689500808716], [-0.07984255999326706, -2.5673537254333496], [-0.7731343507766724, -0.619086742401123], [-0.1783696562051773, -1.8117564916610718], [-0.05277545005083084, -2.9679813385009766], [-0.09900632500648499, -2.361666440963745], [-0.02805224619805813, -3.587679862976074], [-0.4870433807373047, -0.9530594944953918], [-0.7188314199447632, -0.6681060791015625], [-0.05670486390590668, -2.8981144428253174], [-0.5776994228363037, -0.82368403673172], [-1.776172161102295, -0.18546833097934723], [-2.2359166145324707, -0.11305010318756104], [-0.6476824879646301, -0.7407777905464172], [-0.013851821422576904, -4.286255836486816], [-0.43723317980766296, -1.0379524230957031], [-0.060966651886701584, -2.82775616645813], [-0.02401595003902912, -3.7410225868225098], [-0.17121098935604095, -1.8492428064346313], [-0.07644558697938919, -2.6091558933258057], [-0.006731334142386913, -5.00435209274292], [-0.0072626154869794846, -4.9286394119262695], [-0.22024284303188324, -1.62112557888031], [-0.6899362802505493, -0.6963684558868408], [-0.2640829384326935, -1.4606294631958008], [-0.7260060906410217, -0.6613336801528931], [-3.7675490379333496, -0.023379843682050705], [-1.1285929679870605, -0.39080527424812317], [-0.04242090508341789, -3.181248188018799], [-0.07099044322967529, -2.680494785308838], [-2.051142692565918, -0.13764023780822754]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = test_model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "ZFDhokdIoLCV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_y = test_y.reshape(20000,)\n",
        "test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qTLIqXYONKf",
        "outputId": "4c010ec7-24c7-4617-ebb2-da49ab6a21d4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20000])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y1 = test_y[:6366]\n",
        "test_y1 = test_y1.reshape(6366)\n",
        "test_y1 = np.asarray(test_y1)\n",
        "test_y1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHRWOA0boUso",
        "outputId": "10bca965-1a1a-40f8-b75e-f3f5c2c9f761"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6366,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "precision_, recall_, proba = precision_recall_curve(test_y1,preds[:,-1])\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "#plot precision-recall curve\n",
        "plt.plot(recall_, precision_, marker='.', label='BERT-model')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# optimal_proba_cutoff = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
        "# preds = [1 if i >= optimal_proba_cutoff else 0 for i in preds[:, -1]]\n",
        "\n",
        "mcc = matthews_corrcoef(test_y1, preds)\n",
        "tn, fp, fn, tp = confusion_matrix(test_y1, preds).ravel()\n",
        "precision = precision_score(test_y1, preds)\n",
        "recall = recall_score(test_y1, preds)\n",
        "f1 = f1_score(test_y1, preds, average='weighted')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Matthews Corr Coef:\", mcc)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"f-1 score:\", f1)\n",
        "\n",
        "print(classification_report(test_y1, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "uW9ac7MMAJeY",
        "outputId": "2cfb343c-ccb8-4dc4-9d06-8e72c0c4daa0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matthews Corr Coef: 0.0029601077916492856\n",
            "Precision: 0.8236686390532545\n",
            "Recall: 0.13320574162679427\n",
            "f-1 score: 0.2415991544843082\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.87      0.30      1141\n",
            "           1       0.82      0.13      0.23      5225\n",
            "\n",
            "    accuracy                           0.27      6366\n",
            "   macro avg       0.50      0.50      0.26      6366\n",
            "weighted avg       0.71      0.27      0.24      6366\n",
            "\n"
          ]
        }
      ]
    }
  ]
}